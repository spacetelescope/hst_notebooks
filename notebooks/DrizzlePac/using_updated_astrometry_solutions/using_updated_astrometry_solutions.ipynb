{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Improving Astrometry Using Alternate WCS Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\" > <b> This notebook requires creating and activating a virtual environment using the requirements file in this notebook's repository. Please also review the README file before using the notebook.</b> <br> </div>\n",
    "\n",
    "## Table of Contents\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "[Introduction](#intro) <br>\n",
    "[Import Packages](#import) <br>\n",
    "\n",
    " 0. [Example Data Download](#0.-Example-Data-Download)\n",
    " 1. [New Extensions on FITS Files](#1.-New-extensions-on-fits-files)\n",
    " 2. [Exploring different solutions](#2.-Exploring-different-solutions)\n",
    " 3. [Applying a headerlet to the science extensions](#3.-Applying-a-headerlet-to-the-science-extensions)\n",
    " 4. [Changing to alternate WCS solutions](#4.-Changing-to-alternate-WCS-solutions)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.1 [FIT-REL Gaia eDR3 solution](#4.1-FIT-REL-Gaia-eDR3-solution)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.2 [\"a priori\" solution](#4.2-\"a-priori\"-solution)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.3 [\"distortion-only\" solution](#4.3-\"distortion-only\"-solution)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.4 [FIT-SVM Gaia DR2 solution](#4.4-FIT-SVM-Gaia-DR2-solution)<br>\n",
    " 5. [Using downloaded SVM headerlets](#5.-Using-downloaded-SVM-headerlets)\n",
    " 6. [Running AstroDrizzle](#6.-Running-AstroDrizzle)\n",
    "\n",
    "[Conclusions](#conclude) <br>\n",
    "[About this Notebook](#about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "<a id=\"intro\"></a>\n",
    "\n",
    "Starting in December 2019, improved astrometric solutions for ACS and WFC3 images are available in the World Coordinate System (WCS) of the exposure file (`flt.fits` and `flc.fits`) FITS headers, with alternate WCS solutions appended as additional headerlet extensions. These solutions are also available as separate [headerlet](https://stwcs.readthedocs.io/en/latest/headerlet.html) FITS files which may be downloaded and applied to the FITS images. <br> \n",
    "<br>\n",
    "<b>This notebook shows how to examine different WCS solutions contained in the FITS images and how to improve the relative alignment of exposures in the F225W and F336W filters which were taken in the same visit but which have different active WCS solutions.</b>\n",
    "\n",
    "During the calibration portion of the pipeline processing, the drizzlepac software calls the [updatewcs](https://stwcs.readthedocs.io/en/latest/astrometry_utils.html#usage) module to populate the WCS headerlet extensions in the FITS images and then sets the 'bestSolutionID' as the active WCS.  The astrometry database captures every unique WCS solution for a given dataset cataloged by 'ipppssoot' and includes WCS's derived from standard (HST) and Hubble Advanced Products (HAP). This gives us a complete  history of the active WCS over time and these solutions can change as the alignment software is improved, as new  distortion reference files are delivered, and/or as new reference catalogs become available.  (A re-alignment is performed ONLY when there is a new distortion solution or absolute reference catalog.)\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NOTE:</b> While some datasets may have WCS solutions which are aligned to an external reference catalog, such as Gaia eDR3, GSC v2.4.2 or 2MASS, other datasets (even in the same visit) may not! Thus, it is crucial to check which WCS solution is active for all of the exposures. The easiest way to do this is to examine the WCSNAME keyword in the header of the SCI extensions. <br>  \n",
    "<br>    \n",
    "<b>Alternatively, a more accurate WCS solution may be available in the HAP Single Visit Mosaic (SVM) products created by MAST. In this workflow, the pipeline first aligns all of the images in a given visit and second aligns the entire group to an external reference catalog.<b>  Here, we show how to download the SVM headerlets and apply them to the FITS data to improve the relative aligment prior to running AstroDrizzle.\n",
    "</div>\n",
    "\n",
    "For more information alternate WCS solutions, see [Section 4.5](https://hst-docs.stsci.edu/drizzpac/chapter-4-astrometric-information-in-the-header/4-5-absolute-astrometry) of the Drizzlepac Handbook. For more details on the Hubble Advanced Products and Single Visit Mosaics (SVMs), see the following [MAST Newsletter Article](https://archive.stsci.edu/contents/newsletters/december-2020/hap-single-visit-mosaics-now-available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "## Import Packages\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "***\n",
    "\n",
    "The following Python packages are required to run the Jupyter Notebook:\n",
    " - [**os**](https://docs.python.org/3/library/os.html) - change and make directories\n",
    " - [**glob**](https://docs.python.org/3/library/glob.html) - gather lists of filenames\n",
    " - [**shutil**](https://docs.python.org/3/library/shutil.html#module-shutil) - remove directories and files\n",
    " - [**numpy**](https://numpy.org) - math and array functions\n",
    " - [**matplotlib**](https://matplotlib.org/stable/tutorials/pyplot.html) - make figures and graphics\n",
    " - [**astropy**](https://www.astropy.org) - file handling, tables, units, WCS, statistics\n",
    " - [**astroquery**](https://astroquery.readthedocs.io/en/latest/) - download data and query databases\n",
    " - [**drizzlepac**](https://www.stsci.edu/scientific-community/software/drizzlepac) - align and combine HST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ZScaleInterval\n",
    "from astroquery.mast import Observations\n",
    "from stwcs.wcsutil import headerlet\n",
    "from drizzlepac import astrodrizzle\n",
    "from drizzlepac.processInput import getMdriztabPars\n",
    "from collections import defaultdict\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # Improves the resolution of figures rendered in notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some steps in this notebook require access to HST reference files, so we will create a temporary 'iref' directory for these reference files after download. This step is typically done by defining the 'iref' path in your bash profile so that all reference files for all datasets can be in one static location, but for the portability of this notebook we will create a directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CRDS_SERVER_URL'] = 'https://hst-crds.stsci.edu'\n",
    "os.environ['CRDS_SERVER'] = 'https://hst-crds.stsci.edu'\n",
    "os.environ['CRDS_PATH'] = './crds_cache'\n",
    "os.environ['iref'] = './crds_cache/references/hst/wfc3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Example Data Download\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "---\n",
    "MAST queries may be done using <a href=\"https://astroquery.readthedocs.io/en/latest/mast/mast_obsquery.html#observation-criteria-queries\"> `query_criteria`</a>, where we specify: <br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$\\rightarrow$ obs_id, proposal_id, and filters \n",
    "\n",
    "MAST data products may be downloaded by using <a href=\"https://astroquery.readthedocs.io/en/latest/mast/mast_obsquery.html#downloading-data\"> `download_products`</a>, where we specify:<br> \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$\\rightarrow$ products = calibrated (FLT, FLC) or drizzled (DRZ, DRC) files\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$\\rightarrow$ type = standard products (CALxxx) or advanced products (HAP-SVM)\n",
    "____\n",
    "\n",
    "Let's find some example HST data from MAST and download it. The example used here is from visit 14 of program [16801](http://www.stsci.edu/cgi-bin/get-proposal-info?id=16801&observatory=HST). The associations IEPW14030 and IEPW14040 each contain two FLC images in the F336W and F225W filters and a single DRC combined image for each filter.  Here we download the FLC, DRC, and ASN files using `astroquery`.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"color:black\" >  Depending on your connection speed this cell may take a few minutes to execute. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ids = ['IEPW14030', 'IEPW14040']\n",
    "\n",
    "obsTable = Observations.query_criteria(obs_id=obs_ids)\n",
    "products = Observations.get_product_list(obsTable)\n",
    "\n",
    "data_prod = ['FLC', 'ASN', 'DRC'] # ['FLC', 'FLT', 'DRC', 'DRZ']\n",
    "data_type = ['CALWF3'] # ['CALACS', 'CALWF3', 'CALWP2', 'HAP-SVM']\n",
    "\n",
    "Observations.download_products(products, productSubGroupDescription=data_prod, project=data_type, cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we retrieve the Hubble Advanced Product (HAP) headerlets, which we will use to change between different WCS solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observations.download_products(products, productSubGroupDescription=['HLET'], project=['HAP-SVM'], cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to make the paths easier to work with, we move those files from their default download location into the notebook directory. In addition, we add one to the headerlet extension numbers because lists are zero indexed while the EXTVER's extensions are unity based. We do this by defining a small `correct_hdrlet_extvers()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fits_file in glob.glob('./mastDownload/HST/*/*.fits'):\n",
    "    fits_name = os.path.basename(fits_file)\n",
    "    os.rename(fits_file, fits_name)\n",
    "    \n",
    "if os.path.exists('mastDownload'):\n",
    "    shutil.rmtree('mastDownload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_hdrlet_extvers(filename):\n",
    "    \"\"\"Correctly renumbers hdrlet EXTVER values\"\"\"\n",
    "    with fits.open(filename, mode='update') as hdulist:\n",
    "        hdrlet_count = 0\n",
    "        for i, ext in enumerate(hdulist):\n",
    "            if ext.name == 'HDRLET':\n",
    "                hdrlet_count += 1\n",
    "                hdulist[i].header['EXTVER'] = hdrlet_count\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flc_file in sorted(glob.glob('*flc.fits')):\n",
    "    correct_hdrlet_extvers(flc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the active WCS solution in the image header. If the image is aligned to a catalog, we list the number of matches and the fit RMS converted from milliarcseconds to pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_0_keywords = ['DETECTOR', 'EXPTIME', 'FILTER'] # extension 0 keywords.\n",
    "ext_1_keywords = ['WCSNAME', 'NMATCHES', 'RMS_RA', 'RMS_DEC'] # extension 1 keywords.\n",
    "\n",
    "# Define the detector plate scales in arcsec per pixel.\n",
    "DETECTOR_SCALES = {\n",
    "  'IR': 0.1283, \n",
    "  'UVIS': 0.0396, \n",
    "  'WFC': 0.05\n",
    "}\n",
    "\n",
    "formatted_data = {}\n",
    "column_data = defaultdict(list)\n",
    "\n",
    "for fits_file in sorted(glob.glob('*fl?.fits')):\n",
    "    column_data['filename'].append(fits_file)\n",
    "    header0 = fits.getheader(fits_file, 0)\n",
    "    header1 = fits.getheader(fits_file, 1)\n",
    "    \n",
    "    for keyword in ext_0_keywords:\n",
    "        column_data[keyword].append(header0[keyword])\n",
    "    for keyword in ext_1_keywords:\n",
    "        if keyword in header1:\n",
    "            if 'RMS' in keyword:\n",
    "                value = np.around(header1[keyword], decimals=1)\n",
    "            else:\n",
    "                value = header1[keyword]\n",
    "            column_data[keyword].append(value)\n",
    "        else:\n",
    "            column_data[keyword].append(np.nan)\n",
    "            \n",
    "    for keyword in ['RMS_RA', 'RMS_DEC']:\n",
    "        if keyword in header1:\n",
    "            rms_value = header1[keyword] / 1000 / DETECTOR_SCALES[header0['DETECTOR']]\n",
    "            column_data[f'{keyword}_pix'].append(np.round(rms_value, decimals=2))\n",
    "        else:\n",
    "            column_data[f'{keyword}_pix'].append(np.nan)\n",
    "\n",
    "wcstable = Table(column_data)\n",
    "wcstable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the first two exposures (F336W) have a fit to 'Gaia eDR3' with 46 matches and a fit RMS of ~0.3 pixels.  The next two exposures (F225W) do not have a catalog fit and use the 'a priori' correction to the Guide Star Catalog v2.4.  In section 5, we show how to apply the SVM headerlet to align the F225W filter to Gaia eDR3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. New extensions on FITS files\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "Using `fits.info` prints basic information about the extensions in a FITS file.  In the following examples, we show operations for one F336W `flc.fits` file, though the same operations can be repeated in a loop for multiple files. The updated solutions should then show up as extra `HDRLET` extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'iepw14g4q_flc.fits'\n",
    "\n",
    "fits.info(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, there are new `HDRLET` extensions in the FITS files (as compared to the pre-2019.3 products. These extensions each contain information used to construct a World Coordinate System (WCS), which is used to transform image coordinates into physical (sky) coordinates.  Each WCS represents a uniquely derived astrometric solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring different solutions\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "Each HDRLET extension contains information describing the solution used in its creation. To investigate this we first obtain the extension numbers of the HDRLETs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_indices = headerlet.find_headerlet_HDUs(filename, strict=False)\n",
    "\n",
    "print(ext_indices) # To show it's consistent with the fits.info from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then loop through these extensions to see what WCS solutions are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(filename) as hdu:\n",
    "    print('Ext\\tWCSNAME')\n",
    "\n",
    "    for ext_ind in ext_indices:\n",
    "        print(ext_ind, '\\t', hdu[ext_ind].header['WCSNAME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the `get_headerlet_kw_names()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcsnames = headerlet.get_headerlet_kw_names(filename, kw='WCSNAME')\n",
    "new_wcsnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write this into a convenience function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hdrlet_wcsnames(filename):\n",
    "\n",
    "    \"\"\"Print and return list of WCS names in HDRLET extensions of fits file\"\"\"\n",
    "\n",
    "    with fits.open(filename) as hdu:\n",
    "        ext_indices = headerlet.find_headerlet_HDUs(filename, strict=False)\n",
    "\n",
    "        print('Ext\\tWCSNAME')\n",
    "        new_wcsnames = []\n",
    "        for ext_ind in ext_indices:\n",
    "            name = hdu[ext_ind].header['WCSNAME']\n",
    "            print(ext_ind, '\\t', name)\n",
    "            new_wcsnames.append(name)\n",
    "\n",
    "    return new_wcsnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcsnames = get_hdrlet_wcsnames(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see which solution is the \"active\" solution (the one currently applied to the SCI extensions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nature of each solution is described here: https://drizzlepac.readthedocs.io/en/latest/mast_data_products/astrometry.html#interpreting-wcs-names. In some cases, single-visit mosaic (SVM) solution named FIT-SVM-GAIADR2 might be better than the default active solution of FIT-REL-GAIAeDR3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying a headerlet to the science extensions\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "To apply/activate one of the other solutions, we use the `restore_from_headerlet()` function.  This applies the WCS contained in a HDRLET extension to all SCI extensions of the image.  Doing this requires knowing which solution should be applied, which can be obtained in multiple ways. For instance, if the desired solution is `IDC_2731450pi-FIT_REL_GAIAeDR3`, we can find the `EXTVER` of the corresponding HDRLET from the list of wcs names we generated earlier.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "NOTE: This is especially useful in cases where some of the exposures in a visit will have solutions that are aligned to Gaia, but others won't.  This is true for grism images in the same visit as direct images, or shallow/deep exposure combinations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the index of list element with value 'IDC_2731450pi-GSC240'.\n",
    "# The index in this list + 1 is the same as the EXTVER of the corresponding HDRLET.\n",
    "# We need to add 1 because lists are 0-indexed, while EXTVER's are 1 indexed.\n",
    "\n",
    "chosen_ext = new_wcsnames.index('IDC_2731450pi-FIT_REL_GAIAeDR3')+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerlet.restore_from_headerlet(filename, hdrext=('HDRLET', chosen_ext), archive=False, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we set `archive` keyword argument to `False`.  Setting `archive` to True will preserve the currently active WCS as a new HDRLET extension on the file.  Since in our case the current solution already has a HDRLET, we do not need to archive it.  This may be useful in some cases, such as when the image has been manually aligned/transformed, and keeping a record of that solution is desired.\n",
    "\n",
    "We can check that the solution was applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply the solution via the HDRNAME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdrlet_hdrnames = headerlet.get_headerlet_kw_names(fits.open(filename), 'HDRNAME')\n",
    "desired_hdrname = hdrlet_hdrnames[new_wcsnames.index('IDC_2731450pi-GSC240')]\n",
    "print(desired_hdrname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerlet.restore_from_headerlet(filename, hdrname=desired_hdrname, archive=False, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply some logic to get the `hdrext` programatically.  For instance, if we only wanted the `IDC` (distortion calibrated) solution with the `GSC240` tag (indicating that this is a 'a priori' WCS where the guide star positions had been updated), we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, wcsname in enumerate(new_wcsnames):\n",
    "    if 'IDC' in wcsname and 'GSC240' in wcsname:\n",
    "        chosen_ext = i + 1 # Add one due to 0 indexing of enumerate vs 1 indexing of EXTVER\n",
    "        break\n",
    "\n",
    "print('The desired extension is:', ('HDRLET', chosen_ext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the solution this way can be easier, as it doesn't require a full typing out of the IDCTAB name.  However, in the future, if new IDCTABs are created, there may be multiple solutions matching the criteria above, and more sophisticated logic will need to be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Changing to alternate WCS solutions\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "Here we look at three WCS solutions and inspect which has the best alignment with respect to stars in the HST image.\n",
    "\n",
    "### 4.1 FIT-REL Gaia eDR3 solution\n",
    "\n",
    "When the WCS is `FIT_REL_eDR3`, the individual exposures are aligned to one another and then the entire association is aligned to Gaia eDR3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ext = new_wcsnames.index('IDC_2731450pi-FIT_REL_GAIAeDR3') + 1\n",
    "headerlet.restore_from_headerlet(filename, hdrext=('HDRLET', chosen_ext), archive=False, force=False)\n",
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 \"a priori\" solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the WCS does not have the string `FIT`, but is appended with either `GSC240 or HSC30`, this is known as an a priori solution which simply corrects the coordinates of the guide stars in use at the time of observation to the coordinates of those stars as determined by Gaia, applying a global offset to the WCS.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NOTE:</b> Data taken after October 2017 may not have an a priori solution, as the pointing information of the telescope was already calculated using GSC 2.4.0.  As such, the \"old\" solution may be of the same form as the a priori solution, i.e.: IDC_xxxxxxxxx-GSC240.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ext = new_wcsnames.index('IDC_2731450pi-GSC240') + 1\n",
    "headerlet.restore_from_headerlet(filename, hdrext=('HDRLET', chosen_ext), archive=False, force=False)\n",
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 \"distortion only\" solution\n",
    "\n",
    "If the original solution is desired, with no updates to the WCS and the original HST pointing information, it can be restored using the methods shown below, by replacing the WCSNAME simply with `IDC_2731450pi`, or whatever is the name of the IDCTAB reference file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ext = new_wcsnames.index('IDC_2731450pi') + 1\n",
    "headerlet.restore_from_headerlet(filename, hdrext=('HDRLET', chosen_ext), archive=False, force=False)\n",
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using downloaded SVM headerlets\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "In cases like the example provided here, images from the same visit may have different WCS solution types (i.e. F336W is `FIT-REL-GAIAeDR3` while the F225W is `GSC240`).  <br>\n",
    "<br>However, we can apply the SVM headerlet solutions, which are derived from first relatively aligning the HST images to each other, and then aligning the group to an absolute reference catalog.  Thus, they are often a better solution for datasets with a variety of filters/depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlet_files = sorted(glob.glob('*hlet.fits'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at WCS solutions in the headerlet for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_to_hlet_dict = {}\n",
    "for hlet in hlet_files:\n",
    "    dest_image = fits.getval(hlet, 'DESTIM')\n",
    "    root_to_hlet_dict[dest_image] = hlet\n",
    "    print(hlet, dest_image, fits.getval(hlet, 'WCSNAME', 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply have to match each SVM headerlet to its corresponding flc file, and apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flc in sorted(glob.glob('*flc.fits')):\n",
    "    root = fits.getval(flc, 'rootname')\n",
    "    headerlet.apply_headerlet_as_primary(flc, hdrlet=root_to_hlet_dict[root], attach=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Running `AstroDrizzle`\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "Because the drizzling process is directly affected by the WCS's of the input FITS images, the WCS of the drizzled image cannot be changed as simply as shown above for FLC images.  <b>To use an astrometric solution (other than the one  applied to the FLT/FLC at the time of drizzling), the images will have to be re-drizzled after activating the desired WCS</b>. \n",
    "\n",
    "Here we query the association ID of each of the input files and add it to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_dict = defaultdict(list)\n",
    "\n",
    "for flc in sorted(glob.glob('*flc.fits')):\n",
    "    asn_id = fits.getval(flc, 'asn_id')\n",
    "    if asn_id == 'NONE':\n",
    "        asn_id = fits.getval(flc, 'rootname')\n",
    "    asn_id = asn_id.lower()\n",
    "    asn_dict[asn_id].append(flc)\n",
    "asn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare to drizzle the data, and <b> we get some recommended values for drizzling from the MDRIZTAB reference file.</b>  The parameters in this file are different for each detector and are based on the number of input frames and the filter. These are a good starting point for drizzling and may be adjusted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images_f336w = sorted(glob.glob('iepw14g[46]q_flc.fits'))\n",
    "mdz = fits.getval(input_images_f336w[0], 'MDRIZTAB', ext=0).split('$')[1]\n",
    "print('Searching for the MDRIZTAB file:', mdz)\n",
    "get_mdriztab = os.system('crds sync --hst --files '+mdz+' --output-dir '+os.environ['iref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vals_from_mdriztab(input_images_f336w, kw_list=['driz_sep_bits', \n",
    "                                                        'combine_type', \n",
    "                                                        'driz_cr_snr', \n",
    "                                                        'driz_cr_scale', \n",
    "                                                        'final_bits']):\n",
    "    \n",
    "    '''Get only selected parameters from the MDRIZTAB.'''\n",
    "    mdriz_dict = getMdriztabPars(input_images_f336w)\n",
    "    \n",
    "    requested_params = {}\n",
    "    \n",
    "    print('Outputting the following parameters:')\n",
    "    for k in kw_list:\n",
    "        requested_params[k] = mdriz_dict[k]\n",
    "        print(k, mdriz_dict[k])\n",
    "    \n",
    "    return requested_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_params = get_vals_from_mdriztab(asn_dict['iepw14030'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the recommended parameters for 2 input FLC frames. These can be modified below by uncommenting the lines below, as needed for optimal cosmic-ray rejection. For details, see the notebook [Aligning Multiple Visits](https://spacetelescope.github.io/hst_notebooks/notebooks/DrizzlePac/align_multiple_visits/align_multiple_visits.html) in this notebook repository. \n",
    "\n",
    "In the cell below, we run `AstroDrizzle` once for each filter using the association ID dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for asn_id in asn_dict:\n",
    "    \n",
    "    input_images = asn_dict[asn_id]\n",
    "    \n",
    "    # To override any of the above values:\n",
    "    # selected_params['driz_sep_bits'] = '256, 64, 16'\n",
    "    # selected_params['final_bits']    = '256, 64, 16'\n",
    "    # selected_params['combine_type']  = 'median'\n",
    "    # selected_params['driz_cr_snr']   = '4.0 3.5'\n",
    "    # selected_params['driz_cr_scale'] = '1.2 1.0'\n",
    "\n",
    "    selected_params = get_vals_from_mdriztab(input_images)\n",
    "    \n",
    "    astrodrizzle.AstroDrizzle(input_images, \n",
    "                              output=f'{asn_id}_updated_wcs',\n",
    "                              preserve=False,\n",
    "                              clean=True, \n",
    "                              build=True,\n",
    "                              context=False,\n",
    "                              skymethod='match',\n",
    "                              in_memory=True,\n",
    "                              **selected_params)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will display the default pipeline drizzled (DRC) image retrieved from MAST to show the astrometric offset for a zoomed in region of the image. We define the center and scaling to be the same for both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = [10.0095776, 40.5014080]\n",
    "z = ZScaleInterval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the two science images and zoom in on an object to see the astrometric error.\n",
    "image1 = 'iepw14030_drc.fits'\n",
    "image2 = 'iepw14040_drc.fits'\n",
    "\n",
    "sci_image1 = fits.getdata(image1)\n",
    "sci_image2 = fits.getdata(image2)\n",
    "wcs_image1 = WCS(fits.getheader(image1, 1))\n",
    "wcs_image2 = WCS(fits.getheader(image2, 1))\n",
    "x1, y1 = wcs_image1.world_to_pixel_values([center])[0].astype(int)\n",
    "x2, y2 = wcs_image2.world_to_pixel_values([center])[0].astype(int)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=wcs_image1)\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection=wcs_image2)\n",
    "\n",
    "ax1.set_title('WCS: '+fits.getval(image1, 'WCSNAME', ext=('SCI', 1)))\n",
    "ax2.set_title('WCS: '+fits.getval(image2, 'WCSNAME', ext=('SCI', 1)))\n",
    "ax1.imshow(sci_image1, vmin=z.get_limits(sci_image1)[0], vmax=z.get_limits(sci_image1)[1]*5, cmap='Greys_r', origin='lower', interpolation='none')\n",
    "ax2.imshow(sci_image2, vmin=z.get_limits(sci_image2)[0], vmax=z.get_limits(sci_image2)[1]*5, cmap='Greys_r', origin='lower', interpolation='none')\n",
    "\n",
    "ax1.set_xlim(x1-50, x1+50)\n",
    "ax1.set_ylim(y1-50, y1+50)\n",
    "ax2.set_xlim(x2-50, x2+50)\n",
    "ax2.set_ylim(y2-50, y2+50)\n",
    "ax1.grid(lw=1, color='white', ls=':')\n",
    "ax2.grid(lw=1, color='white', ls=':')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a small misalignment between the two filters in the pipeline drizzled files which have different WCS solutions. <br>\n",
    "<br>\n",
    "Finally, we  display the redrizzled image which uses the improved FIT-SVM-GAIAeDR3 WCS, which restores the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the two science images and zoom in on an object to see the astrometric error.\n",
    "image1 = 'iepw14030_updated_wcs_drc.fits'\n",
    "image2 = 'iepw14040_updated_wcs_drc.fits'\n",
    "\n",
    "sci_image1 = fits.getdata(image1)\n",
    "sci_image2 = fits.getdata(image2)\n",
    "wcs_image1 = WCS(fits.getheader(image1, 1))\n",
    "wcs_image2 = WCS(fits.getheader(image2, 1))\n",
    "x1, y1 = wcs_image1.world_to_pixel_values([center])[0].astype(int)\n",
    "x2, y2 = wcs_image2.world_to_pixel_values([center])[0].astype(int)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=wcs_image1)\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection=wcs_image2)\n",
    "\n",
    "ax1.set_title('WCS: '+fits.getval(image1, 'WCSNAME', ext=('SCI', 1)))\n",
    "ax2.set_title('WCS: '+fits.getval(image2, 'WCSNAME', ext=('SCI', 1)))\n",
    "ax1.imshow(sci_image1, vmin=z.get_limits(sci_image1)[0], vmax=z.get_limits(sci_image1)[1]*5, cmap='Greys_r', origin='lower', interpolation='none')\n",
    "ax2.imshow(sci_image2, vmin=z.get_limits(sci_image2)[0], vmax=z.get_limits(sci_image2)[1]*5, cmap='Greys_r', origin='lower', interpolation='none')\n",
    "\n",
    "ax1.set_xlim(x1-50, x1+50)\n",
    "ax1.set_ylim(y1-50, y1+50)\n",
    "ax2.set_xlim(x2-50, x2+50)\n",
    "ax2.set_ylim(y2-50, y2+50)\n",
    "ax1.grid(lw=1, color='white', ls=':')\n",
    "ax2.grid(lw=1, color='white', ls=':')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclude\"></a>\n",
    "## Conclusions\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "This notebook demonstrates how to access and apply different WCS solutions from exposure and SVM headerlets. In general, it is always preferred to have consistent WCS solutions across exposures, especially from the same visit. Users can also custom align their exposures to one another, as well as to external catalogs such as SDSS and Gaia. This process is detailed in the [align_to_catalogs](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/DrizzlePac/align_to_catalogs/align_to_catalogs.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "## About this Notebook\n",
    "    \n",
    "    Created: 14 Dec 2018;     V. Bajaj\n",
    "    Updated: 31 May 2024;     M. Revalski, V. Bajaj, & J. Mack\n",
    "\n",
    "**Source:** GitHub [spacetelescope/hst_notebooks](https://github.com/spacetelescope/hst_notebooks)\n",
    "\n",
    "<a id=\"add\"></a>\n",
    "## Additional Resources\n",
    "\n",
    "Below are some additional resources that may be helpful. Please send any questions through the [HST Help Desk](https://stsci.service-now.com/hst), selecting the DrizzlePac category.\n",
    "\n",
    "- [WFC3 Website](https://www.stsci.edu/hst/instrumentation/wfc3)\n",
    "- [WFC3 Data Handbook](https://hst-docs.stsci.edu/wfc3dhb)\n",
    "- [WFC3 Instrument Handbook](https://hst-docs.stsci.edu/wfc3ihb)\n",
    "\n",
    "<a id=\"cite\"></a>\n",
    "## Citations\n",
    "If you use Python packages such as `astropy`, `astroquery`, `drizzlepac`, `matplotlib`, or `numpy` for published research, please cite the authors.\n",
    "\n",
    "Follow these links for more information about citing various packages:\n",
    "\n",
    "* [Citing `astropy`](https://www.astropy.org/acknowledging.html)\n",
    "* [Citing `astroquery`](https://github.com/astropy/astroquery/blob/main/astroquery/CITATION)\n",
    "* [Citing `drizzlepac`](https://zenodo.org/records/3743274)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/citing.html)\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/)\n",
    "***\n",
    "\n",
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
