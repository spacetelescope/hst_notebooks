{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Using Updated Astrometry Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\" > <b> This notebook requires creating and activating a virtual environment using the requirements file in this notebook's repository. Please also review the README file before using the notebook.</b> <br> </div>\n",
    "\n",
    "## Table of Contents\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "[Introduction](#intro) <br>\n",
    "[Import Packages](#import) <br>\n",
    "\n",
    " 0. [Example Data Download](#0.-Example-Data-Download)\n",
    " 1. [New Extensions on FITS Files](#1.-New-extensions-on-fits-files)\n",
    " 2. [Exploring different solutions](#2.-Exploring-different-solutions)\n",
    " 3. [Applying a headerlet to the science extensions](#3.-Applying-a-headerlet-to-the-science-extensions)\n",
    " 4. [Changing to alternate WCS solutions](#4.-Changing-to-alternate-WCS-solutions)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.1 [FIT-REL Gaia eDR3 solution](#4.1-FIT-REL-Gaia-eDR3-solution)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.2 [\"a priori\" solution](#4.2-\"a-priori\"-solution)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.3 [\"distortion-only\" solution](#4.3-\"distortion-only\"-solution)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.4 [FIT-SVM Gaia DR2 solution](#4.4-FIT-SVM-Gaia-DR2-solution)<br>\n",
    " 5. [Using downloaded SVM headerlets](#5.-Using-downloaded-SVM-headerlets)\n",
    " 6. [Running AstroDrizzle](#6.-Running-AstroDrizzle)\n",
    "\n",
    "[Conclusions](#conclude) <br>\n",
    "[About this Notebook](#about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "<a id=\"intro\"></a>\n",
    "\n",
    "As part of an effort to improve the absolute astrometry of HST images, STScI has created multiple new astrometric solutions for ACS and WFC3 images.  These solutions are contained in the World Coordinate System (WCS) of the images, as well as headerlet extensions and files.  This notebook provides an example workflow showing how to use different WCS solutions.\n",
    "\n",
    "The WCS solutions are contained in the exposure file (`flt.fits` and `flc.fits`) headers. However, these updates were implemented in December 2019 as a part of HST Data Processing version 2019.5.  If data were downloaded before that, they can either be redownloaded (and will contain the new solutions) from MAST or via astroquery, or can be updated by connecting to the database containing solutions (shown below), or downloading the headerlets (also shown below).\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NOTE:</b> The new solutions are used by default by the MAST pipeline! Some datasets may have certain solutions  such as fitting to Gaia eDR3, though other datasets (even in the same visit) may not! Thus, it is crucial to check which WCS solution is active. The easiest way to check this is to examine the WCSNAME keyword in the header of the SCI extensions. Alternatively, in many cases a solution may be available from the Single Visit Mosaic (SVM) products produced by MAST, which attempt to relatively align the images in a visit first, and then align them to Gaia or other external catalogs.  Getting the Single Visit Mosaic WCS solutions and applyign them to data is shown in Section 5.\n",
    "</div>\n",
    "\n",
    "For more information on Astrometry solutions, see [Section 4.5](https://hst-docs.stsci.edu/drizzpac/chapter-4-astrometric-information-in-the-header/4-5-absolute-astrometry) of the Drizzlepac Handbook. See the MAST webpage for more information on [Single Visit Mosaics (SVMs)](https://archive.stsci.edu/contents/newsletters/december-2020/hap-single-visit-mosaics-now-available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "## Import Packages\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "***\n",
    "\n",
    "The following Python packages are required to run the Jupyter Notebook:\n",
    " - [**os**](https://docs.python.org/3/library/os.html) - change and make directories\n",
    " - [**glob**](https://docs.python.org/3/library/glob.html) - gather lists of filenames\n",
    " - [**shutil**](https://docs.python.org/3/library/shutil.html#module-shutil) - remove directories and files\n",
    " - [**numpy**](https://numpy.org) - math and array functions\n",
    " - [**matplotlib**](https://matplotlib.org/stable/tutorials/pyplot.html) - make figures and graphics\n",
    " - [**astropy**](https://www.astropy.org) - file handling, tables, units, WCS, statistics\n",
    " - [**astroquery**](https://astroquery.readthedocs.io/en/latest/) - download data and query databases\n",
    " - [**drizzlepac**](https://www.stsci.edu/scientific-community/software/drizzlepac) - align and combine HST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ZScaleInterval\n",
    "from astroquery.mast import Observations\n",
    "from stwcs.wcsutil import headerlet\n",
    "from drizzlepac import astrodrizzle\n",
    "from drizzlepac.processInput import getMdriztabPars\n",
    "from collections import defaultdict\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # Greatly improves the resolution of figures rendered in notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some steps in this notebook require access to HST reference files, so we will create a temporary 'iref' directory for these reference files after download. This step is typically done by defining the 'iref' path in your bash profile so that all reference files for all datasets can be in one static location, but for the portability of this notebook we will create a directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CRDS_SERVER_URL'] = 'https://hst-crds.stsci.edu'\n",
    "os.environ['CRDS_SERVER'] = 'https://hst-crds.stsci.edu'\n",
    "os.environ['CRDS_PATH'] = './crds_cache'\n",
    "os.environ['iref'] = './crds_cache/references/hst/wfc3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Example Data Download\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "---\n",
    "MAST queries may be done using <a href=\"https://astroquery.readthedocs.io/en/latest/mast/mast_obsquery.html#observation-criteria-queries\"> `query_criteria`</a>, where we specify: <br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$\\rightarrow$ obs_id, proposal_id, and filters \n",
    "\n",
    "MAST data products may be downloaded by using <a href=\"https://astroquery.readthedocs.io/en/latest/mast/mast_obsquery.html#downloading-data\"> `download_products`</a>, where we specify:<br> \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$\\rightarrow$ products = calibrated (FLT, FLC) or drizzled (DRZ, DRC) files\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$\\rightarrow$ type = standard products (CALxxx) or advanced products (HAP-SVM)\n",
    "____\n",
    "\n",
    "Let's find some example HST data from MAST and download it. The example used here is from visit 07 of program [14689](http://www.stsci.edu/cgi-bin/get-proposal-info?id=14689&observatory=HST). The association id7307030 contains four FLC images that have been processed by the HST WFC3 pipeline (calwf3), which includes bias subtraction, dark current correction, CTE-correction, cosmic-ray rejection, and flat-fielding. \n",
    "\n",
    "            id7307xfq_flc.fits\n",
    "            id7307xhq_flc.fits\n",
    "            id7307xlq_flc.fits\n",
    "            id7307xpq_flc.fits\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"color:black\" >  Depending on your connection speed this cell may take a few minutes to execute. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ids = ['IEPW14030', 'IEPW14040']\n",
    "\n",
    "obsTable = Observations.query_criteria(obs_id=obs_ids)\n",
    "products = Observations.get_product_list(obsTable)\n",
    "\n",
    "data_prod = ['FLC', 'ASN', 'DRC'] # ['FLC', 'FLT', 'DRC', 'DRZ']\n",
    "data_type = ['CALWF3'] # ['CALACS', 'CALWF3', 'CALWP2', 'HAP-SVM']\n",
    "\n",
    "Observations.download_products(products, productSubGroupDescription=data_prod, project=data_type, cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we retrieve the Hubble Advanced Product (HAP) headerlets, which we will use to change between different WCS solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observations.download_products(products, productSubGroupDescription=['HLET'], project=['HAP-SVM'], cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to make the paths easier to work with, we move those files from their default download location into the notebook directory. In addition, we add one to the headerlet extension numbers because lists are zero indexed while the EXTVER's extensions are unity based. We do this by defining a small `correct_hdrlet_extvers()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fits_file in glob.glob('./mastDownload/HST/*/*.fits'):\n",
    "    fits_name = os.path.basename(fits_file)\n",
    "    os.rename(fits_file, fits_name)\n",
    "    \n",
    "if os.path.exists('mastDownload'):\n",
    "    shutil.rmtree('mastDownload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_hdrlet_extvers(filename):\n",
    "    \"\"\"Correctly renumbers hdrlet EXTVER values\"\"\"\n",
    "    hdulist = fits.open(filename, mode='update')\n",
    "    hdrlet_count = 0\n",
    "    for i, ext in enumerate(hdulist):\n",
    "        if ext.name == 'HDRLET':\n",
    "            hdrlet_count += 1\n",
    "            hdulist[i].header['EXTVER'] = hdrlet_count\n",
    "        else:\n",
    "            continue\n",
    "    hdulist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flc_file in sorted(glob.glob('*flc.fits')):\n",
    "    correct_hdrlet_extvers(flc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the active WCS solution in the image header. If the image is aligned to a catalog, we list the number of matches and the fit RMS converted from milliarcseconds to pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_0_keywords = ['DETECTOR', 'EXPTIME'] # extension 0 keywords.\n",
    "ext_1_keywords = ['WCSNAME', 'NMATCHES', 'RMS_RA', 'RMS_DEC'] # extension 1 keywords.\n",
    "\n",
    "# Define the detector plate scales in arcsec per pixel.\n",
    "DETECTOR_SCALES = {\n",
    "  'IR': 0.1283, \n",
    "  'UVIS': 0.0396, \n",
    "  'WFC': 0.05\n",
    "}\n",
    "\n",
    "formatted_data = {}\n",
    "column_data = defaultdict(list)\n",
    "\n",
    "for fits_file in sorted(glob.glob('*fl?.fits')):\n",
    "    column_data['filename'].append(fits_file)\n",
    "    header0 = fits.getheader(fits_file, 0)\n",
    "    header1 = fits.getheader(fits_file, 1)\n",
    "    \n",
    "    for keyword in ext_0_keywords:\n",
    "        column_data[keyword].append(header0[keyword])\n",
    "    for keyword in ext_1_keywords:\n",
    "        if keyword in header1:\n",
    "            if 'RMS' in keyword:\n",
    "                value = np.around(header1[keyword], decimals=1)\n",
    "            else:\n",
    "                value = header1[keyword]\n",
    "            column_data[keyword].append(value)\n",
    "        else:\n",
    "            column_data[keyword].append(np.nan)\n",
    "            \n",
    "    for keyword in ['RMS_RA', 'RMS_DEC']:\n",
    "        if keyword in header1:\n",
    "            rms_value = header1[keyword] / 1000 / DETECTOR_SCALES[header0['DETECTOR']]\n",
    "            column_data[f'{keyword}_pix'].append(np.round(rms_value, decimals=2))\n",
    "        else:\n",
    "            column_data[f'{keyword}_pix'].append(np.nan)\n",
    "\n",
    "wcstable = Table(column_data)\n",
    "wcstable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. New extensions on FITS files\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "Using `fits.info` prints basic information about the extensions in a FITS file.  In the following examples, we show operations for one file, though the same operations can be repeated in a loop for multiple files. The updated solutions should then show up as extra `HDRLET` extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'iepw14g4q_flc.fits'\n",
    "\n",
    "fits.info(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, there are new `HDRLET` extensions in the FITS files (as compared to the pre-2019.3 products. These extensions each contain information used to construct a World Coordinate System (WCS), which is used to transform image coordinates into physical (sky) coordinates.  Each WCS represents a uniquely derived astrometric solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring different solutions\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "Each HDRLET extension contains information describing the solution used in its creation. To investigate this we first obtain the extension numbers of the HDRLETs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_indices = headerlet.find_headerlet_HDUs(filename, strict=False)\n",
    "\n",
    "print(ext_indices) # To show it's consistent with the fits.info from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then loop through these extensions to see what WCS solutions are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.open(filename)\n",
    "print('Ext\\tWCSNAME')\n",
    "\n",
    "for ext_ind in ext_indices:\n",
    "    print(ext_ind, '\\t', hdu[ext_ind].header['WCSNAME'])\n",
    "\n",
    "hdu.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the `get_headerlet_kw_names()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcsnames = headerlet.get_headerlet_kw_names(filename, kw='WCSNAME')\n",
    "new_wcsnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write this into a convenience function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hdrlet_wcsnames(filename):\n",
    "    \n",
    "    \"\"\"Print and return list of WCS names in HDRLET extensions of fits file\"\"\"\n",
    "    \n",
    "    hdu = fits.open(filename)\n",
    "    ext_indices = headerlet.find_headerlet_HDUs(filename, strict=False)\n",
    "\n",
    "    print('Ext\\tWCSNAME')\n",
    "    new_wcsnames = []\n",
    "    for ext_ind in ext_indices:\n",
    "        name = hdu[ext_ind].header['WCSNAME']\n",
    "        print(ext_ind, '\\t', name)\n",
    "        new_wcsnames.append(name)\n",
    "        \n",
    "    hdu.close()\n",
    "    \n",
    "    return new_wcsnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcsnames = get_hdrlet_wcsnames(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see which solution is the \"active\" solution (the one currently applied to the SCI extensions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nature of each solution is described here: https://drizzlepac.readthedocs.io/en/latest/mast_data_products/astrometry.html#interpreting-wcs-names. In some cases, single-visit mosaic (SVM) solution named FIT-SVM-GAIADR2 might be better than the default active solution of FIT-REL-GAIAeDR3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying a headerlet to the science extensions\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "To apply/activate one of the other solutions, we use the `restore_from_headerlet()` function.  This applies the WCS contained in a HDRLET extension to all SCI extensions of the image.  Doing this requires knowing which solution should be applied, which can be obtained in multiple ways. For instance, if the desired solution is `IDC_2731450pi-FIT_REL_GAIAeDR3`, we can find the `EXTVER` of the corresponding HDRLET from the list of wcs names we generated earlier.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "NOTE: This is especially useful in cases where some of the exposures in a visit will have solutions that are aligned to Gaia, but others won't.  This is true for grism images in the same visit as direct images, or shallow/deep exposure combinations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the index of list element with value 'IDC_2731450pi-GSC240'.\n",
    "# The index in this list + 1 is the same as the EXTVER of the corresponding HDRLET.\n",
    "# We need to add 1 because lists are 0-indexed, while EXTVER's are 1 indexed.\n",
    "\n",
    "chosen_ext = new_wcsnames.index('IDC_2731450pi-FIT_REL_GAIAeDR3')+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerlet.restore_from_headerlet(filename, hdrext=('HDRLET', chosen_ext), archive=False, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we set `archive` keyword argument to `False`.  Setting `archive` to True will preserve the currently active WCS as a new HDRLET extension on the file.  Since in our case the current solution already has a HDRLET, we do not need to archive it.  This may be useful in some cases, such as when the image has been manually aligned/transformed, and keeping a record of that solution is desired.\n",
    "\n",
    "We can check that the solution was applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply the solution via the HDRNAME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdrlet_hdrnames = headerlet.get_headerlet_kw_names(fits.open(filename), 'HDRNAME')\n",
    "desired_hdrname = hdrlet_hdrnames[new_wcsnames.index('IDC_2731450pi-GSC240')]\n",
    "print(desired_hdrname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerlet.restore_from_headerlet(filename, hdrname=desired_hdrname, archive=False, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply some logic to get the `hdrext` programatically.  For instance, if we only wanted the `IDC` (distortion calibrated) solution with the `GSC240` tag (indicating that the guide star positions had been updated), we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, wcsname in enumerate(new_wcsnames):\n",
    "    if 'IDC' in wcsname and 'GSC240' in wcsname:\n",
    "        chosen_ext = i + 1 # Add one due to 0 indexing of enumerate vs 1 indexing of EXTVER\n",
    "        break\n",
    "\n",
    "print('The desired extension is:', ('HDRLET', chosen_ext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the solution this way can be easier, as it doesn't require a full typing out of the IDCTAB name.  However, in the future, if new IDCTABs are created, there may be multiple solutions matching the criteria above, and more sophisticated logic will need to be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Changing to alternate WCS solutions\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "Here we look at four WCS solutions and inspect which has the best alignment with respect to stars in the HST image.\n",
    "\n",
    "### 4.1 FIT-REL Gaia eDR3 solution\n",
    "\n",
    "The entire association is aligned as a group with repect to Gaia when the WCS is FIT-REL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ext = new_wcsnames.index('IDC_2731450pi-FIT_REL_GAIAeDR3') + 1\n",
    "headerlet.restore_from_headerlet(filename, hdrext=('HDRLET', chosen_ext), archive=False, force=False)\n",
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the original solution is desired, it can be restored using the methods shown above, by replacing the WCSNAME simply with `IDC_2731450pi`, or whatever the name of the IDCTAB for that file is.  To get that name, the following procedure can be done:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 \"a priori\" solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ext = new_wcsnames.index('IDC_2731450pi-GSC240') + 1\n",
    "headerlet.restore_from_headerlet(filename, hdrext=('HDRLET', chosen_ext), archive=False, force=False)\n",
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 \"distortion only\" solution\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NOTE:</b> Data taken after October 2017 may not have a solution of the form IDC_xxxxxxxxx, as the pointing information of the telescope was already calculated using GSC 2.4.0.  As such, the \"old\" solution may be of the same form as the a priori solution, i.e.: IDC_xxxxxxxxx-GSC240.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ext = new_wcsnames.index('IDC_2731450pi') + 1\n",
    "headerlet.restore_from_headerlet(filename, hdrext=('HDRLET', chosen_ext), archive=False, force=False)\n",
    "current_wcs = fits.getval(filename, 'WCSNAME', ext=('SCI', 1))\n",
    "print(current_wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using downloaded SVM headerlets\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "In cases like the example provided here, images from the same visit may have different WCS solution types (i.e. some are `FIT-REL-GAIAeDR3` and others are `GSC240`).  This may lead to images not being aligned, especially if some images use a Gaia based solutions and others don't.  However, we can apply the solutions used in the SVM images, which are derived from first relatively aligning the data to each other, and then aligning the group of images to an absolute reference catalog.  Thus, they are often a better solution for datasets with a variety of filters/depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlet_files = sorted(glob.glob('*hlet.fits'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at WCS solutions in the headerlet for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_to_hlet_dict = {}\n",
    "for hlet in hlet_files:\n",
    "    dest_image = fits.getval(hlet, 'DESTIM')\n",
    "    root_to_hlet_dict[dest_image] = hlet\n",
    "    print(hlet, dest_image, fits.getval(hlet, 'WCSNAME', 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply have to match each headerlet to its corresponding flc file, and apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flc in sorted(glob.glob('*flc.fits')):\n",
    "    root = fits.getval(flc, 'rootname')\n",
    "    headerlet.apply_headerlet_as_primary(flc, hdrlet=root_to_hlet_dict[root], attach=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Running `AstroDrizzle`\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "Because the drizzling process is directly affected by the WCS's of the input images, the WCS of the drizzled image cannot be changed as simply as shown above for FLC images.  To use an astrometric solution (other than the one  applied to the FLT/FLC at the time of drizzling), the images will have to be re-drizzled after activating the desired WCS in the FLT/FLC images. Here we want to set the WCS solution for all of the input FLC files to be the FIT-SVM-GAIAeDR3 solution (see section 5).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NOTE:</b> The images input to astrodrizzle should use the same WCS solution, or the drizzling process will produce poor results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_dict = defaultdict(list)\n",
    "\n",
    "for flc in sorted(glob.glob('*flc.fits')):\n",
    "    asn_id = fits.getval(flc, 'asn_id')\n",
    "    if asn_id == 'NONE':\n",
    "        asn_id = fits.getval(flc, 'rootname')\n",
    "    asn_id = asn_id.lower()\n",
    "    asn_dict[asn_id].append(flc)\n",
    "asn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get some recommended values for drizzling from the MDRIZTAB reference file.  The parameters in this file are different for each detector and are based on the number of input frames. These are a good starting point for drizzling and may be adjusted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = sorted(glob.glob('*flc.fits'))\n",
    "mdz = fits.getval(input_images[0], 'MDRIZTAB', ext=0).split('$')[1]\n",
    "print('Searching for the MDRIZTAB file:', mdz)\n",
    "get_mdriztab = os.system('crds sync --hst --files '+mdz+' --output-dir '+os.environ['iref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vals_from_mdriztab(input_images, kw_list=['driz_sep_bits', \n",
    "                                                  'combine_type', \n",
    "                                                  'driz_cr_snr', \n",
    "                                                  'driz_cr_scale', \n",
    "                                                  'final_bits']):\n",
    "    \n",
    "    '''Get only selected parameters from the MDRIZTAB.'''\n",
    "    mdriz_dict = getMdriztabPars(input_images)\n",
    "    \n",
    "    requested_params = {}\n",
    "    \n",
    "    print('Outputting the following parameters:')\n",
    "    for k in kw_list:\n",
    "        requested_params[k] = mdriz_dict[k]\n",
    "        print(k, mdriz_dict[k])\n",
    "    \n",
    "    return requested_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_params = get_vals_from_mdriztab(asn_dict['iepw14030'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for asn_id in asn_dict:\n",
    "    \n",
    "    input_images = asn_dict[asn_id]\n",
    "    \n",
    "    # To override any of the above values:\n",
    "    # selected_params['driz_sep_bits'] = '64, 32'\n",
    "    # selected_params['final_bits']    = '64, 32'\n",
    "    # selected_params['combine_type']  = 'minmed'\n",
    "    # selected_params['driz_cr_snr']   = '4.0 3.5'\n",
    "    # selected_params['driz_cr_scale'] = '1.5 1.2'\n",
    "\n",
    "    selected_params = get_vals_from_mdriztab(input_images)\n",
    "    \n",
    "    astrodrizzle.AstroDrizzle(input_images, \n",
    "                              output=f'{asn_id}_updated_wcs',\n",
    "                              preserve=False,\n",
    "                              clean=True, \n",
    "                              build=True,\n",
    "                              context=False,\n",
    "                              skymethod='match',\n",
    "                              in_memory=True,\n",
    "                              **selected_params)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will display the default pipeline DRC image retrieved from MAST to show the astrometric offset. We define the center and scaling to be the same for both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = [10.0095776, 40.5014080]\n",
    "z = ZScaleInterval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the two science images and zoom in on an object to see the astrometric error.\n",
    "image1 = 'iepw14030_drc.fits'\n",
    "image2 = 'iepw14040_drc.fits'\n",
    "\n",
    "sci_image1 = fits.getdata(image1)\n",
    "sci_image2 = fits.getdata(image2)\n",
    "wcs_image1 = WCS(fits.getheader(image1, 1))\n",
    "wcs_image2 = WCS(fits.getheader(image2, 1))\n",
    "x1, y1 = wcs_image1.world_to_pixel_values([center])[0].astype(int)\n",
    "x2, y2 = wcs_image2.world_to_pixel_values([center])[0].astype(int)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=wcs_image1)\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection=wcs_image2)\n",
    "\n",
    "ax1.set_title('WCS: '+fits.getval(image1, 'WCSNAME', ext=('SCI', 1)))\n",
    "ax2.set_title('WCS: '+fits.getval(image2, 'WCSNAME', ext=('SCI', 1)))\n",
    "ax1.imshow(sci_image1, vmin=z.get_limits(sci_image1)[0], vmax=z.get_limits(sci_image1)[1]*5, cmap='Greys_r', origin='lower', interpolation='none')\n",
    "ax2.imshow(sci_image2, vmin=z.get_limits(sci_image2)[0], vmax=z.get_limits(sci_image2)[1]*5, cmap='Greys_r', origin='lower', interpolation='none')\n",
    "\n",
    "ax1.set_xlim(x1-50, x1+50)\n",
    "ax1.set_ylim(y1-50, y1+50)\n",
    "ax2.set_xlim(x2-50, x2+50)\n",
    "ax2.set_ylim(y2-50, y2+50)\n",
    "ax1.grid(lw=1, color='white', ls=':')\n",
    "ax2.grid(lw=1, color='white', ls=':')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will display the redrizzled image which used the FIT-SVM-GAIAeDR3 WCS, which restores the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the two science images and zoom in on an object to see the astrometric error.\n",
    "image1 = 'iepw14030_updated_wcs_drc.fits'\n",
    "image2 = 'iepw14040_updated_wcs_drc.fits'\n",
    "\n",
    "sci_image1 = fits.getdata(image1)\n",
    "sci_image2 = fits.getdata(image2)\n",
    "wcs_image1 = WCS(fits.getheader(image1, 1))\n",
    "wcs_image2 = WCS(fits.getheader(image2, 1))\n",
    "x1, y1 = wcs_image1.world_to_pixel_values([center])[0].astype(int)\n",
    "x2, y2 = wcs_image2.world_to_pixel_values([center])[0].astype(int)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=wcs_image1)\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection=wcs_image2)\n",
    "\n",
    "ax1.set_title('WCS: '+fits.getval(image1, 'WCSNAME', ext=('SCI', 1)))\n",
    "ax2.set_title('WCS: '+fits.getval(image2, 'WCSNAME', ext=('SCI', 1)))\n",
    "ax1.imshow(sci_image1, vmin=z.get_limits(sci_image1)[0], vmax=z.get_limits(sci_image1)[1]*5, cmap='Greys_r', origin='lower', interpolation='none')\n",
    "ax2.imshow(sci_image2, vmin=z.get_limits(sci_image2)[0], vmax=z.get_limits(sci_image2)[1]*5, cmap='Greys_r', origin='lower', interpolation='none')\n",
    "\n",
    "ax1.set_xlim(x1-50, x1+50)\n",
    "ax1.set_ylim(y1-50, y1+50)\n",
    "ax2.set_xlim(x2-50, x2+50)\n",
    "ax2.set_ylim(y2-50, y2+50)\n",
    "ax1.grid(lw=1, color='white', ls=':')\n",
    "ax2.grid(lw=1, color='white', ls=':')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclude\"></a>\n",
    "## Conclusions\n",
    "\n",
    "[Table of Contents](#toc)\n",
    "\n",
    "This notebook demonstrates how to access and apply different WCS solutions from exposure and SVM headerlets. In general, it is always preferred to have consistent WCS solutions across exposures, especially from the same visit. Users can also custom align their exposures to one another, as well as to external catalogs such as SDSS and Gaia. This process is detailed in the [align_to_catalogs](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/DrizzlePac/align_to_catalogs/align_to_catalogs.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "## About this Notebook\n",
    "    \n",
    "    Created: 14 Dec 2018;     V. Bajaj\n",
    "    Updated: 23 May 2024;     M. Revalski, V. Bajaj, & J. Mack\n",
    "\n",
    "**Source:** GitHub [spacetelescope/hst_notebooks](https://github.com/spacetelescope/hst_notebooks)\n",
    "\n",
    "<a id=\"add\"></a>\n",
    "## Additional Resources\n",
    "\n",
    "Below are some additional resources that may be helpful. Please send any questions through the [HST Help Desk](https://stsci.service-now.com/hst), selecting the DrizzlePac category.\n",
    "\n",
    "- [WFC3 Website](https://www.stsci.edu/hst/instrumentation/wfc3)\n",
    "- [WFC3 Data Handbook](https://hst-docs.stsci.edu/wfc3dhb)\n",
    "- [WFC3 Instrument Handbook](https://hst-docs.stsci.edu/wfc3ihb)\n",
    "\n",
    "<a id=\"cite\"></a>\n",
    "## Citations\n",
    "If you use Python packages such as `astropy`, `astroquery`, `drizzlepac`, `matplotlib`, or `numpy` for published research, please cite the authors.\n",
    "\n",
    "Follow these links for more information about citing various packages:\n",
    "\n",
    "* [Citing `astropy`](https://www.astropy.org/acknowledging.html)\n",
    "* [Citing `astroquery`](https://github.com/astropy/astroquery/blob/main/astroquery/CITATION)\n",
    "* [Citing `drizzlepac`](https://zenodo.org/records/3743274)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/citing.html)\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/)\n",
    "***\n",
    "\n",
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
