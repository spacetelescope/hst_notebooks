{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sky Matching for HST Mosaics <a id=\"top\"></a>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\" > <b> This notebook assumes you have created and activated a virtual environment using the requirements file in this notebook's repository. Please make sure you have read the contents of the README file before continuing the notebook. Note that the GIF file \"sky_matching_comparison.gif\" is one of the downloads needed for this notebook: </b>  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals:\n",
    "In this tutorial we explore different options for handling the background sky with [`AstroDrizzle`](https://drizzlepac.readthedocs.io/en/latest/drizzlepac_api/astrodrizzle.html). <br>\n",
    "By the end of this notebook you will:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;• Download data with [`astroquery`](https://astroquery.readthedocs.io/en/latest/index.html)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;• Align data with [`TweakReg`](https://drizzlepac.readthedocs.io/en/latest/user_reprocessing/tweakreg_api.html)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;• Compare background sky options using the [`AstroDrizzle`](https://drizzlepac.readthedocs.io/en/latest/drizzlepac_api/astrodrizzle.html) parameter `skymethod`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Introduction](#intro) <br>\n",
    "\n",
    "[1. Download the Observations with `astroquery`](#download) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.1 Check image header data](#check_keywords) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.2 Inspect the alignment](#check_wcs) <br>\n",
    "[2. Align the visit-level drizzled data with `TweakReg`](#align) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.1 Create a catalog of Gaia DR3 sources](#cat) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2 Create a catalog of Gaia DR3 sources with Proper Motion Data](#cat_pm) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3 Run `Tweakreg`](#tweak) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.4 Inspect the shift file and fit quality](#fit_quality) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.5 Overplot matched sources and inspect fit residuals](#overplot) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.6 Rerun `TweakReg` and update the header WCS](#updatehdr) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.7 Run `TweakBack` to propogate the WCS to the FLT files](#tweakback) <br>\n",
    "[3. Compare `skymethod` options in `AstroDrizzle`](#compare) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[3.1 `skymethod = 'localmin'`](#localmin) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[3.2 `skymethod = 'match'`](#match) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[3.3 `skymethod = 'globalmin+match'`](#globalminmatch) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[3.4 `skymethod = 'globalmin'`](#globalmin) <br>\n",
    "[4. Compare the MDRIZSKY values for each method](#mdrizsky) <br>\n",
    "[5. Display the 'sky matched' science mosaic and weight image](#display) <br>\n",
    "[6. Conclusion](#conclusion) <br>\n",
    "\n",
    "[Additional Resources](#resources) <br>\n",
    "[About this notebook](#about) <br>\n",
    "[Citations](#citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id=\"intro\"></a>\n",
    "\n",
    "When creating an image mosaic, `AstroDrizzle` has the ability to compute the sky and then either subtract or equalize the background in input images. Users may select the algorithm used for the sky subtraction via the `skymethod` parameter.\n",
    "\n",
    "There are four methods available in sky matching: `localmin`, `match`, `globalmin`, and `globalmin+match`.\n",
    "\n",
    "By applying `drizzlepac.sky.sky()`, or using the `skymethod` parameter in the call to `drizzlepac.astrodrizzle.AstroDrizzle()`, AstroDrizzle will update the keyword `MDRIZSKY` in the headers of the input files but it will not change the science data. \n",
    "\n",
    "For images of sparse fields with few astronomical sources, the default `skymethod = 'localmin'` may be used, although this method can slightly oversubtract the background.  For images with complicated backgrounds, such as nebulae and large host galaxies, `skymethod = 'match'` is recommended.\n",
    "\n",
    "For more information on the specifics of this function, please refer to the documentation [here](https://drizzlepac.readthedocs.io/en/latest/drizzlepac_api/sky.html#drizzlepac.sky.sky)\n",
    "\n",
    "Below, each of the four methods is demonstrated using a single example dataset, and differences between the methods is highlighted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports needed through out this notebook are included at the beginning. \n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output \n",
    "import glob\n",
    "import os\n",
    "import shutil \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import ascii, fits\n",
    "from astropy.table import Table\n",
    "from astropy.units import Quantity\n",
    "import astropy.units as u\n",
    "from astroquery.gaia import Gaia\n",
    "from astroquery.mast import Observations\n",
    "from drizzlepac import astrodrizzle, tweakback, tweakreg \n",
    "from drizzlepac.haputils.astrometric_utils import create_astrometric_catalog\n",
    "\n",
    "\n",
    "Gaia.MAIN_GAIA_TABLE = 'gaiadr3.gaia_source'   # Change if different data release is desired\n",
    "Gaia.ROW_LIMIT = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the Observations with `astroquery` <a id=\"download\"></a>\n",
    "\n",
    "MAST queries may be done using <a href=\"https://astroquery.readthedocs.io/en/latest/mast/mast_obsquery.html#observation-criteria-queries\"> `query_criteria`</a>, where we specify: <br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;--> obs_id, proposal_id, and filters \n",
    "\n",
    "MAST data products may be downloaded by using <a href=\"https://astroquery.readthedocs.io/en/latest/mast/mast_obsquery.html#downloading-data\"> `download_products`</a>, where we specify:<br> \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;--> products = calibrated (FLT, FLC) or drizzled (DRZ, DRC) files\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;--> type = standard products (CALxxx) or advanced products (HAP-SVM)\n",
    "\n",
    "<br>\n",
    "\n",
    "WFC3/IR observations of the Horsehead Nebula in the F160W filter obtained in HST proposal\n",
    "program [12812](https://www.stsci.edu/hst-program-info/program/?program=12812)\n",
    "will be used for this demonstration. \n",
    "\n",
    "Nine visits were acquired in a 3x3 mosaic pattern on the sky, with two dither positions per visit in two IR filters. [High level science products](https://archive.stsci.edu/prepds/heritage/horsehead/readme_HLSP_v3.txt) for these datasets were delivered to MAST in 2013, and this notebook is based on that user tutorial but has been updated to align these data to Gaia.\n",
    "\n",
    "The 18 FLT images <b>ibxl5*_flt.fits</b> have been processed by the HST WFC3 pipeline (calwf3), which includes bias subtraction, dark current correction, cosmic-ray rejection, and flatfielding. The 9 DRZ files <b>ibxl5*_drz.fits</b> have been processed with `AstroDrizzle` to remove distortion and to combine the 2 dithered FLT frames by filter for each vist.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\" >  THIS IS A LARGE DOWNLOAD (~400 MB). Depending on your connection speed, the next cell may take a few minutes to execute. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ids = ['ibxl5*']\n",
    "props = ['12812']\n",
    "filts = ['F160W']\n",
    "\n",
    "obsTable = Observations.query_criteria(obs_id=obs_ids, proposal_id=props, filters=filts)\n",
    "products = Observations.get_product_list(obsTable)\n",
    "\n",
    "data_prod = ['FLT', 'DRZ']     # ['FLC','FLT','DRC','DRZ']                  \n",
    "data_type = ['CALWF3']         # ['CALACS','CALWF3','CALWP2','HAP-SVM']    \n",
    "\n",
    "Observations.download_products(products, download_dir='./science',\n",
    "                               productSubGroupDescription=data_prod, \n",
    "                               project=data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the files to the local working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(os.curdir, 'science', 'mastDownload', 'HST', '*', '*fits'))\n",
    "for im in files:\n",
    "    root = os.path.basename(im)\n",
    "    os.rename(im, './' + root)\n",
    "    \n",
    "if os.path.exists('./science'):\n",
    "    shutil.rmtree('science/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Check image header data <a id=\"check_keywords\"></a>\n",
    "\n",
    "Here we will look at important keywords in the image headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('*fl?.fits'))\n",
    "keywords_ext0 = [\"ROOTNAME\", \"ASN_ID\", \"TARGNAME\", \"DETECTOR\", \"FILTER\", \"EXPTIME\", \n",
    "                 \"RA_TARG\", \"DEC_TARG\", \"POSTARG1\", \"POSTARG2\", \"DATE-OBS\"]\n",
    "keywords_ext1 = [\"ORIENTAT\"]\n",
    "data = []\n",
    "\n",
    "for file in files:\n",
    "    path_data = []\n",
    "    for keyword in keywords_ext0:\n",
    "        path_data.append(fits.getval(file, keyword, ext=0))\n",
    "    for keyword in keywords_ext1:\n",
    "        path_data.append(fits.getval(file, keyword, ext=1))\n",
    "    data.append(path_data)\n",
    "    \n",
    "keywords = keywords_ext0 + keywords_ext1\n",
    "table = Table(np.array(data), names=keywords, dtype=['str', 'str', 'str', 'str', 'str', 'f8', 'f8', 'f8', 'f8', 'f8', 'str', 'f8'])\n",
    "table['EXPTIME'].format = '7.1f' \n",
    "table['RA_TARG'].format = table['DEC_TARG'].format = '7.4f'\n",
    "table['POSTARG1'].format = table['POSTARG2'].format = '7.3f' \n",
    "table['ORIENTAT'].format = '7.2f'\n",
    "table.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inspect the Alignment <a id=\"check_wcs\"></a>\n",
    "\n",
    "Check the active WCS solution in the image header. If the image is aligned to a catalog, list the number of matches and the fit RMS in mas. <br> \n",
    "Convert the fit RMS values to pixels for comparison with the alignment results performed later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_0_kws = ['DETECTOR']\n",
    "ext_1_kws = ['WCSNAME', 'NMATCHES', 'RMS_RA', 'RMS_DEC']\n",
    "\n",
    "det_scale = {'IR': 0.1283, 'UVIS': 0.0396, 'WFC': 0.05}                  # plate scale (arcsec/pixel)\n",
    "\n",
    "format_dict = {}\n",
    "col_dict = defaultdict(list)\n",
    "\n",
    "for f in sorted(glob.glob('*dr?.fits')):\n",
    "    col_dict['FILENAME'].append(f)\n",
    "    hdr0 = fits.getheader(f, 0)\n",
    "    hdr1 = fits.getheader(f, 1)\n",
    "    \n",
    "    for kw in ext_0_kws:                                                # extension 0 keywords\n",
    "        col_dict[kw].append(hdr0[kw])\n",
    "    for kw in ext_1_kws:                                                # extension 1 keywords\n",
    "        if 'RMS' in kw:\n",
    "            val = np.around(hdr1[kw], 1)\n",
    "        else: \n",
    "            val = hdr1[kw]\n",
    "        col_dict[kw].append(val)\n",
    "        \n",
    "    for kw in ['RMS_RA', 'RMS_DEC']:\n",
    "        val = np.round(hdr1[kw]/1000./det_scale[hdr0['DETECTOR']], 2)  # convert RMS from mas to pixels\n",
    "        col_dict[f'{kw}_pix'].append(val)\n",
    "\n",
    "wcstable = Table(col_dict)\n",
    "wcstable.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\" > <b> Note that there are different WCS solutions for each visit, with Gaia eDR3 as the reference catalog for all but two which were fit to GSC v2.4.2 and which have a much larger fit rms values (>0.5 pixels). Since the WCS solutions are inconsistent for this target, we wish to realign the data to use a common reference catalog.</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Align the visit-level drizzled data with `TweakReg` <a id=\"align\"></a>\n",
    "\n",
    "Here we will use `TweakReg` to align the DRZ files to Gaia DR3 and then use `TweakBack` to propagate those solutions back to the FLT image headers prior to combining with `AstroDrizzle`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create a catalog of Gaia DR3 sources  <a id=\"cat\"></a>\n",
    "\n",
    "This method uses the RA/Dec of the first image and a radius of 5'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RA = table['RA_TARG'][0]\n",
    "Dec = table['DEC_TARG'][0]\n",
    "\n",
    "coord = SkyCoord(ra=RA, dec=Dec, unit=(u.deg, u.deg))\n",
    "radius = Quantity(5., u.arcmin)\n",
    "\n",
    "gaia_query = Gaia.query_object_async(coordinate=coord, radius=radius)\n",
    "gaia_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_query = gaia_query['ra', 'dec', 'phot_g_mean_mag']\n",
    "reduced_query.write('gaia_no_pm.cat', format='ascii.commented_header', overwrite=True)\n",
    "reduced_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create a catalog of Gaia DR3 sources with Proper Motion Data  <a id=\"cat_pm\"></a>\n",
    "\n",
    "This method uses the image FLT footprints and gives 161 sources, compared to 183 with the prior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_cat = create_astrometric_catalog(sorted(glob.glob('*flt.fits')))\n",
    "pm_cat.write('gaia_pm.cat', overwrite=True, format='ascii.no_header')\n",
    "len(pm_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Run `TweakReg` <a id=\"tweak\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run `TweakReg` on the visit-level drizzled (DRZ) images and align to the Gaia catalog with proper motion data. \n",
    "\n",
    "Because the fit RMS values for the MAST products were large for some visits, we allow for a larger than usual search radius of 1\". We also set the `conv_width` value slightly higher than the recommended value of 2.5 for WFC3/IR data in order to use barely resolved sources for alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refcat = 'gaia_pm.cat'                    # Use the catalog with proper motion data\n",
    "\n",
    "drz_files = sorted(glob.glob('*drz.fits'))\n",
    "\n",
    "tweakreg.TweakReg(drz_files, \n",
    "                  imagefindcfg={'threshold': 4, 'conv_width': 4.5}, \n",
    "                  minobj=3,\n",
    "                  shiftfile=True, \n",
    "                  outshifts='shift_drz.txt',\n",
    "                  refcat=refcat,\n",
    "                  searchrad=1,\n",
    "                  ylimit=0.4, \n",
    "                  nclip=1,\n",
    "                  updatehdr=False,       # change later when you verify the alignment works\n",
    "                  interactive=False)\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the alignment is unsuccessful, stop the notebook\n",
    "with open('shift_drz.txt', 'r') as shift:\n",
    "    for line_number, line in enumerate(shift, start=1):\n",
    "        if \"nan\" in line:\n",
    "            raise ValueError(f'nan found in line {line_number} in shift file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Inspect the shift file and fit quality <a id=\"fit_quality\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the shift file just created by tweakreg\n",
    "# There are 7 columns including: filename, x-shift, y-shift, rotation, scale, x-RMS, and y-RMS\n",
    "shift_table = Table.read('shift_drz.txt',\n",
    "                         format='ascii.no_header', \n",
    "                         names=['file', 'dx', 'dy', 'rot', 'scale', 'xrms', 'yrms'])\n",
    "\n",
    "# Define the format for each column (excluding 'file').\n",
    "formats = ['.2f', '.2f', '.3f', '.5f', '.2f', '.2f']\n",
    "\n",
    "# Iterate over the columns 'dx', 'dy', 'rot', 'scale', 'xrms', 'yrms'\n",
    "for i, col in enumerate(shift_table.colnames[1:]):\n",
    "    # Apply the format to the current column \n",
    "    shift_table[col].format = formats[i]\n",
    "    \n",
    "# Display the table in the notebook\n",
    "shift_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are large residual rotation and scale terms in the shift file for several visits in the MAST data products.  These will be corrected when we run `TweakReg` an additional time and update the WCS in Section 2.6 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_files = sorted(glob.glob('*_drz_catalog_fit.match'))\n",
    "for f in match_files:\n",
    "    input = ascii.read(f)\n",
    "    print(f'Number of matches for {f} {len(input)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compare with the MAST WCS solutions, number of matches and fit RMS values. Since there are only 5 Gaia sources in Visits 53 and 56, these did not have a successful Gaia fit during MAST processing and instead were aligned to the next catalog in the priority list, GSC v2.4.2. (Currently the minimum number of matches for a successful fit is 6, but this will updated to 10 in summer 2024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcstable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Overplot matched sources and inspect fit residuals <a id=\"overplot\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we overplot the HST sources which were successfully matched with Gaia eDR3 and we look at the astrometric fit residual PNG plots.\n",
    "\n",
    "While we inspect only two visits (52 and 53) at a time, and additional visits may be uncommented in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rootnames for the two FITS files to be compared\n",
    "# Uncomment the pairs you want to use\n",
    "\n",
    "# rootname_A = 'ibxl50030'\n",
    "# rootname_B = 'ibxl51030'\n",
    "rootname_A = 'ibxl52030'\n",
    "rootname_B = 'ibxl53030'\n",
    "# rootname_A = 'ibxl54030'\n",
    "# rootname_B = 'ibxl55030'\n",
    "# rootname_A = 'ibxl56030'\n",
    "# rootname_B = 'ibxl57030'\n",
    "# rootname_A = 'ibxl57030'\n",
    "# rootname_B = 'ibxl58030'\n",
    "\n",
    "# Create subplots with 1 row and 2 columns\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(13, 10))\n",
    "\n",
    "# Open the FITS files and extract the data from the 'SCI' extension\n",
    "data_a = fits.open(rootname_A+'_drz.fits')['SCI', 1].data\n",
    "data_b = fits.open(rootname_B+'_drz.fits')['SCI', 1].data\n",
    "\n",
    "# Display the images in grayscale with a stretch from 0 to 2 \n",
    "ax1.imshow(data_a, cmap='Greys', origin='lower', vmin=0, vmax=2)\n",
    "ax2.imshow(data_b, cmap='Greys', origin='lower', vmin=0, vmax=2)\n",
    "\n",
    "# Read the matching catalog files for both rootnames\n",
    "match_tab_a = ascii.read(rootname_A+'_drz_catalog_fit.match')\n",
    "match_tab_b = ascii.read(rootname_B+'_drz_catalog_fit.match')\n",
    "\n",
    "# Extract x and y coordinates from the matching catalogs\n",
    "x_coord_a, y_coord_a = match_tab_a['col11'], match_tab_a['col12']\n",
    "x_coord_b, y_coord_b = match_tab_b['col11'], match_tab_b['col12']\n",
    "\n",
    "# Plot the coordinates on the images with red circles\n",
    "ax1.scatter(x_coord_a, y_coord_a, s=30, edgecolor='r', facecolor='None')\n",
    "ax2.scatter(x_coord_b, y_coord_b, s=30, edgecolor='r', facecolor='None')\n",
    "\n",
    "# Set the titles for the subplots, including the number of matches\n",
    "ax1.set_title(rootname_A+f'  N = {len(match_tab_a)}  Gaia Matches', fontsize=20)\n",
    "ax2.set_title(rootname_B+f'  N = {len(match_tab_b)}  Gaia Matches', fontsize=20)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Load, display, and inspect fit residual PNG files\n",
    "img_A = mpimg.imread(f'residuals_{rootname_A}_drz.png')\n",
    "img_B = mpimg.imread(f'residuals_{rootname_B}_drz.png')\n",
    "\n",
    "# Create subplots for the residual images\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), dpi=200)\n",
    "axs[0].imshow(img_A)\n",
    "axs[1].imshow(img_B)\n",
    "\n",
    "# Remove unnecessary axis from the residual images\n",
    "axs[0].axis('off') \n",
    "axs[1].axis('off')\n",
    "\n",
    "# Adjust layout to minimize margins and display plots\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Rerun `TweakReg` and update the header WCS <a id=\"updatehdr\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are happy with the alignment, we run `TweakReg` again with the same parameters but with the `updatehdr=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refcat = 'gaia_pm.cat'    # Use the catalog with proper motion data\n",
    "\n",
    "tweakreg.TweakReg(drz_files, \n",
    "                  imagefindcfg={'threshold': 4, 'conv_width': 4.5}, \n",
    "                  minobj=4,\n",
    "                  shiftfile=False, \n",
    "                  refcat=refcat,\n",
    "                  searchrad=1,\n",
    "                  ylimit=0.4, \n",
    "                  nclip=1,\n",
    "                  updatehdr=True,       # update header\n",
    "                  interactive=False)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Run `TweakBack` to propogate the WCS to the FLT files <a id=\"tweakback\"></a>\n",
    "\n",
    "Finally, we run `Tweakback` on the aligned DRZ files to propogate the updated WCS information back to the FLT files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in drz_files:\n",
    "    tb_input = f+'[sci,1]'\n",
    "    with fits.open(f) as hdu:\n",
    "        tweakback.apply_tweak(tb_input, orig_wcs_name=hdu[1].header['WCSNAME'])\n",
    "    \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare  `skymethod` options in AstroDrizzle <a id=\"compare\"></a>\n",
    "\n",
    "Now that the FLT files contain the updated WCS solutions, we explore different algorithms for estimating the sky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 `skymethod = 'localmin'` <a id=\"localmin\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `AstroDrizzle` to compute the sky in each frame, 'localmin' will compute a common sky value for all chips of a given exposure, using the minimum sky value from all chips. This process is repeated for each input image. This algorithm is recommended when images are dominated by blank sky instead of extended, diffuse sources.\n",
    "\n",
    "See [readthedocs](https://drizzlepac.readthedocs.io/en/deployment/sky.html#drizzlepac.sky.sky) for more details on sky subtraction options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the command below, the aligned FLT frames are sky subtracted and drizzled together. \n",
    "\n",
    "Because the WFC3/IR data products are already cleaned of cosmic rays during calwf3 processing, cosmic-ray rejection is turned off in AstroDrizzle by setting the parameters `driz_separate`, `median`, `blot`, and `driz_cr` to 'False'. Note that `final_bits=16` means only the stable hot pixels are treated as good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sky = 'localmin'\n",
    "astrodrizzle.AstroDrizzle('*flt.fits', \n",
    "                          output='f160w_localmin',\n",
    "                          preserve=False, \n",
    "                          context=False,\n",
    "                          skymethod=sky, \n",
    "                          driz_separate=False, median=False, blot=False, driz_cr=False, # CR-rej turned off\n",
    "                          final_bits='16',\n",
    "                          final_wcs=True, \n",
    "                          final_rot=257.)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 `skymethod = 'match'` <a id=\"match\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `skymethod` is set to ‘match’, differences in sky values between images in common sky regions will be computed. Thus, sky values will be relative (delta) to the sky computed in one of the input images whose sky value will be set to and reported as 0. This setting “equalizes” sky values between the images in large mosaics. \n",
    "\n",
    "This is the **recommended** setting for images containing diffuse sources (e.g., galaxies, nebulae) covering significant parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky = 'match'\n",
    "astrodrizzle.AstroDrizzle('*flt.fits', \n",
    "                          output='f160w_match',\n",
    "                          preserve=False, \n",
    "                          context=False,\n",
    "                          skymethod=sky, \n",
    "                          driz_separate=False, median=False, blot=False, driz_cr=False, # CRREJ=None\n",
    "                          final_bits='16',\n",
    "                          final_wcs=True, \n",
    "                          final_rot=257.)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 `skymethod = 'globalmin+match'` <a id=\"globalminmatch\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `skymethod` is set to ‘globalmin+match', AstroDrizzle will first find a minimum “global” sky value in all input images and then use the ‘match’ method to equalize sky values between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky = 'globalmin+match'\n",
    "astrodrizzle.AstroDrizzle('*flt.fits', \n",
    "                          output='f160w_globalmin_match',\n",
    "                          preserve=False, \n",
    "                          context=False,\n",
    "                          skymethod=sky, \n",
    "                          driz_separate=False, median=False, blot=False, driz_cr=False, # CRREJ=None\n",
    "                          final_bits='16',\n",
    "                          final_wcs=True, \n",
    "                          final_rot=257.)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 `skymethod = 'globalmin'` <a id=\"globalmin\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `skymethod` is set to ‘globalmin’, a common sky value will be computed for all exposures. AstroDrizzle will compute sky values for each chip/image extension, find the minimum sky value from all the exposures, and then subtract that minimum sky value from all chips in all images. \n",
    "\n",
    "This method may be useful when input images already have matched background values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sky = 'globalmin'\n",
    "astrodrizzle.AstroDrizzle('*flt.fits', \n",
    "                          output='f160w_globalmin',\n",
    "                          preserve=False, \n",
    "                          context=False,\n",
    "                          skymethod=sky, \n",
    "                          driz_separate=False, median=False, blot=False, driz_cr=False, # CRREJ=None\n",
    "                          final_bits='16',\n",
    "                          final_wcs=True, \n",
    "                          final_rot=257.)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare the MDRIZSKY values for each method <a id=\"mdrizsky\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we provide a gif comparing the upper portion of the final drizzled image. We cycle through three drizzled images produced using different `skymethod` algorithms:  \n",
    "\n",
    "![The top of the horsehead nebula is shown in grayscale with a stretch of about -0.4 to 2 and the animated gif transitions between displaying the \"localmin\", \"match\", and \"globalmin+match\" sky methods from astrodrizzle. Localmin looks the worst with unmatched backgrounds in the top left and right corners where the outline of separate pointings (dithers) are apparent.](labeled_local_globalmatch_match.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we print the sky values computed for each image using the four different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdrizsky_val = pandas.DataFrame({'rootname': fits.getdata('f160w_globalmin_drz_sci.fits', 1)['rootname'],\n",
    "                                 'local': fits.getdata('f160w_localmin_drz_sci.fits', 1)['mdrizsky'],\n",
    "                                 'globalmin': fits.getdata('f160w_globalmin_drz_sci.fits', 1)['mdrizsky'],\n",
    "                                 'globalmin_match': fits.getdata('f160w_globalmin_match_drz_sci.fits', 1)['mdrizsky'],\n",
    "                                 'match': fits.getdata('f160w_match_drz_sci.fits', 1)['mdrizsky']})\n",
    "mdrizsky_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These computed sky values can be visualized in the plot below. To reiterate, the MDRIZSKY keyword reports the value subtracted from each FLC image prior to drizzling, and not the sky level itself. Thus the values for `skymethod='match'` are close to zero. \n",
    "\n",
    "We also note that varying background levels across the individual tiles result in inaccurate sky background determination when `skymethod='localmin'` and thus a mismatched sky in the final mosaic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = mdrizsky_val.index.tolist()\n",
    "globalmin = list(mdrizsky_val['globalmin'])\n",
    "globalmin_match = list(mdrizsky_val['globalmin_match'])\n",
    "match = list(mdrizsky_val['match'])\n",
    "local = list(mdrizsky_val['local'])\n",
    "\n",
    "# Plotting code: \n",
    "fig = plt.figure(figsize=[7, 7])\n",
    "plt.scatter(index, globalmin_match, color='magenta', label='Globalmin + Match')\n",
    "plt.scatter(index, match, color='navy', label='Match')\n",
    "plt.scatter(index, local, color='olive', label='Local')\n",
    "plt.scatter(index, globalmin, color='orange', label='Globalmin')\n",
    "plt.xlabel('Individual Images')\n",
    "plt.ylabel('MDRIZSKY Value')\n",
    "plt.legend(loc='best')\n",
    "plt.xticks(index)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display the 'sky matched' science mosaic and weight image <a id=\"display\"></a>\n",
    "\n",
    "Finally, we display the science and weight images for the combined mosaic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci = fits.getdata('f160w_match_drz_sci.fits')\n",
    "fig = plt.figure(figsize=(10, 10), dpi=130)\n",
    "plt.imshow(sci, vmin=0.5, vmax=3, cmap='Greys_r', origin='lower')\n",
    "plt.colorbar(shrink=0.85, pad=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci = fits.getdata('f160w_match_drz_wht.fits')\n",
    "fig = plt.figure(figsize=(10, 10), dpi=130)\n",
    "plt.imshow(sci, vmin=0, vmax=4000, cmap='Greys_r', origin='lower')\n",
    "plt.colorbar(shrink=0.85, pad=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion <a id=\"conclusion\"></a>\n",
    "Thank you for going through this notebook. You should now have all the necessary tools for assessing the <br>\n",
    "appropriate `skymethod` parameter to use when combining images. After completing this notebook you <br>\n",
    "should be more familiar with:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;• How to effectively use `astroquery` to download FLT and DRZ files. <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;• Checking the WCS of images and aligning them to a reference catalog with `TweakReg`. <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;• Combining data with `AstroDrizzle` taking into account the `skymethod` <br>\n",
    "<br>\n",
    "**Congratulations, you have completed the notebook!**\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Additional Resources <a id=\"resources\"></a>\n",
    "\n",
    "* [DrizzlePac Handbook](https://hst-docs.stsci.edu/drizzpac)\n",
    "* [HST Help Desk](https://stsci.service-now.com/hst)\n",
    "* [Other DrizzlePac Notebooks](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/DrizzlePac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Notebook <a id=\"about\"></a>\n",
    "\n",
    "Created:  14 Dec 2018; C. Martlin & J. Mack <br>\n",
    "Updated:  16 Nov 2023; K. Huynh & J. Mack       <br>\n",
    "Updated:  23 Jul 2024; J. Mack & B. Kuhn   <br>\n",
    "\n",
    "**Source:** https://github.com/spacetelescope/hst_notebooks <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations <a id=\"citations\"></a>\n",
    "If you use Python packages for published research, please cite the authors. Follow these links for more <br>\n",
    "information about citing packages such as `astropy`, `astroquery`, `matplotlib`, `pandas`, etc.: <br>\n",
    "* [Citing `astropy`](https://www.astropy.org/acknowledging.html) <br>\n",
    "* [Citing `astroquery`](https://github.com/astropy/astroquery/blob/main/astroquery/CITATION) <br>\n",
    "* [Citing `drizzlepac`](https://zenodo.org/records/6325653)<br>\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/citing.html) <br>\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/) <br>\n",
    "* [Citing `pandas`](https://pandas.pydata.org/about/citing.html)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
