{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8346a078",
   "metadata": {},
   "source": [
    "# Scaling Flux while using the Hubble Advanced Spectral Products Script "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2e317b",
   "metadata": {},
   "source": [
    "### <span style=\"font-weight:normal\">This Notebook is designed to walk you through handling input spectra with differing fluxes with the **Hubble Advanced Spectral Products (HASP)** co-add script.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e97a32",
   "metadata": {},
   "source": [
    "## Learning Goals: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4bc17b",
   "metadata": {},
   "source": [
    "By the end of this tutorial, you will learn how to:\n",
    "- Use `astroquery.mast` to download STIS data\n",
    "\n",
    "- Determine whether the input data requires flux scaling\n",
    "\n",
    "- Implement flux scaling and prepare the spectra for use with the co-add script\n",
    "\n",
    "- Run the co-add script\n",
    "\n",
    "- Examine the co-added output\n",
    "\n",
    "- Repeat the process with COS data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d6e2e4",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "**0. [Introduction](#introduction)**\n",
    "\n",
    "**1. [Downloading HST Spectroscopic Data](#datadownload)**\n",
    "\n",
    "\\- 1.1 [Using `Astroquery` to Download STIS Data](#stisdownload)\n",
    "\n",
    "**2. [Running the Co-add Script without scaling](#runscript)**\n",
    "\n",
    "**3. [Checking input data for flux variance](#checkflux)**\n",
    "\n",
    "\\- 3.1 [Plot input spectra relative to each other to identify flux variations](#variance)\n",
    "\n",
    "**4. [Scaling Input Data](#scaledata)**\n",
    "\n",
    "\\- 4.1 [Determine Scaling Factors](#scaling)\n",
    "\n",
    "\\- 4.2 [Rescaling the Data](#package)\n",
    "\n",
    "\\- 4.3 [Re-running the co-add Script](#rerunning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ce7ef",
   "metadata": {},
   "source": [
    "<a id = introduction></a>\n",
    "## 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af9618",
   "metadata": {},
   "source": [
    "The [Hubble Advanced Spectral Products (HASP)](https://github.com/spacetelescope/hasp) code is a script that co-adds spectra within programs. It currently is able to co-add data from the [Space Telescope Imaging Spectrograph (STIS)](https://www.stsci.edu/hst/instrumentation/stis) and the [Cosmic Origins Spectrograph (COS)](https://www.stsci.edu/hst/instrumentation/cos) instruments onboard the [Hubble Space Telescope (HST)](https://www.stsci.edu/hst). The [Hubble Spectroscopic Legacy Archive (HSLA)](https://archive.stsci.edu/missions-and-data/hst/hasp) uses this script to co-add these instrumentsâ€™ data from the [The Mikulski Archive for Space Telescopes (MAST)](https://archive.stsci.edu/) archive to make high quality, wide wavelength UV spectra that is publicly available for the scientific community. These custom co-addition notebooks will instruct users on how produce their own co-adds in cases where the MAST archive data needs special processing or is rejected. \n",
    "\n",
    "The script first co-adds a program's observation set spectra for each grating, then it combines all gratings for the observation set. Finally, it co-adds the spectra of each observation set in the program to produce a fully co-added spectra for each target in a program. lease check out the [COS 2024-01 ISR](https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/cos/documentation/instrument-science-reports-isrs/_documents/ISR2024-01.pdf) for more information about HASP.\n",
    "\n",
    "In the process of co-adding data, the script will also check the flux of input data in each wavelength bin for a given mode against a first coadd that includes all of the input spectra. If the median flux of an input spectrum is lower than a given threshold against the co-add, it will be removed and the program iterates until no more spectra are rejected. This is to prevent data from failed observations from being co-added, but it will also impact sources  that are variable. Additionally for extended sources, the amount of light collected by the PSA on COS may be different from a STIS aperture, which could create flux offsets between gratings. Finally, some of the small apertures for STIS can be impacted by changes in observatory focus and create flux offsets. Similarly, extended sources that are observed at multiple orientations may have slight variations in flux. If a user's science case is not dependent on the accuracy of a dataset's absolute flux, scaling input spectra to be the same average or median flux may be desirable.\n",
    "\n",
    "This notebook will go into depth about checking for variability in a set of data, scaling data to a common median flux, running the co-add script, and inspecting the output by plotting flux as a function of wavelength. This notebook assumes that the user has very little experience with Python but is already familiar with the basic usage of the co-add script; users who are more experienced and would just like to learn how to run and download the script can checkout the [Setup.ipynb](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP/Setup) notebook in this repository. Less experienced users should first run the [CoaddTutorial.ipynb](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP/CoaddTutorial) notebook in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbdc832",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "We will be using multiple libraries to retrieve and analyze data. We will use: \n",
    "* `Path.pathlib` to create product and data directories \n",
    "* `astroquery.mast Observations` to download COS and STIS data\n",
    "* `shutil` to perform directory and file operations\n",
    "* `os` to interact with the operating system\n",
    "* `astropy.io fits` to work with FITS files\n",
    "* `matplotlib.pyplot` to plot abutted spectra\n",
    "* `glob` to work with multiple files in our directories\n",
    "* `numpy` to calculate median scale factors\n",
    "\n",
    "We recommend creating a HASP-specific `conda` environment when co-adding spectra. You can checkout our [Setup.ipynb](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP/Setup) notebook to create such an environment. Alternatively, you can also download the required dependencies to run this notebook with the terminal command: \n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "This will download the dependencies that are necessary to run this current notebook. Let's import all of our packages that we will use in this notebook and print our `conda` environment by running the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from astroquery.mast import Observations\n",
    "import shutil\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Currently active conda environment:\", os.environ.get(\"CONDA_PREFIX\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2dbfd",
   "metadata": {},
   "source": [
    "<a id = datadownload></a>\n",
    "## 1. Downloading HST Spectroscopic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdca358",
   "metadata": {},
   "source": [
    "We will download one STIS dataset using `Observations` from the Python module `astroquery.mast`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734b09c",
   "metadata": {},
   "source": [
    "<a id = stisdownload></a>\n",
    "### 1.1 Using `Astroquery` to Download STIS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361f8f3",
   "metadata": {},
   "source": [
    "We will be downloading STIS data for the white dwarf [G191-B2b](http://simbad.cds.unistra.fr/simbad/sim-basic?Ident=G191-B2b); this is an object that is commonly used as a standard. We will specifically download data from Program 8345, which has observations of G191-B2b using the gratings `E140M` and `E230M`.\n",
    "\n",
    "We can start with setting up our directory structure and querying the MAST database for the STIS program's data. This will give us a list of *all* observations for the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1dbe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data download directories for STIS\n",
    "stis_data_dir = Path(\"./stis_data/\")\n",
    "\n",
    "# Creating the products directory to hold the output\n",
    "stis_products_dir = Path(\"./stis_products/\")\n",
    "\n",
    "# Creating the scaled data directories STIS\n",
    "stis_scaled_data_dir = Path(\"./stis_scaled_data/\")\n",
    "\n",
    "# Creating the scaled products directory to hold the output\n",
    "stis_scaled_products_dir = Path(\"./stis_scaled_products/\")\n",
    "\n",
    "# If the directory doesn't exist, then create it\n",
    "stis_data_dir.mkdir(exist_ok=True)\n",
    "stis_products_dir.mkdir(exist_ok=True)\n",
    "stis_scaled_data_dir.mkdir(exist_ok=True)\n",
    "stis_scaled_products_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f71475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct the query\n",
    "g191_query = Observations.query_criteria(\n",
    "    proposal_id=8435,\n",
    "    target_name=\"G191B2B\",\n",
    "    dataproduct_type=\"SPECTRUM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a832e923",
   "metadata": {},
   "source": [
    "Now that we've queried the observations for Program 8345's data, we can get a list that contains the associated data products for the observations from the query. More details on downloading data are available in the [CoaddTutorial.ipynb](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP/CoaddTutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e229622",
   "metadata": {},
   "outputs": [],
   "source": [
    "g191_products = Observations.get_product_list(\n",
    "    g191_query\n",
    ")\n",
    "\n",
    "Observations.download_products(\n",
    "    g191_products,\n",
    "    download_dir=str(stis_data_dir),\n",
    "    productSubGroupDescription=[\"X1D\", \"SX1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbab7e9",
   "metadata": {},
   "source": [
    "To be able to run the HASP script, we now must move all STIS files to a single directory. When we download data using `astroquery`, it creates a directory `mastDownload/HST`. All sub-folders within that are each different dataset ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3409b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # The path to all obs_id folders\n",
    "    mast_path = f\"{stis_data_dir}/mastDownload/HST/\"\n",
    "\n",
    "    # Check if mastDownload exists\n",
    "    if not os.path.exists(mast_path):\n",
    "        print(f\"Directory {mast_path} doesn't exist.\")\n",
    "\n",
    "    # Getting a list of all obs_id folders. Each folder contains the FITS files\n",
    "    obs_id_dirs = os.listdir(mast_path)\n",
    "\n",
    "    # Iterating through sub-folders to change the path of each FITS file\n",
    "    for obs_id in obs_id_dirs:\n",
    "        # This is the path to each obs_id folder\n",
    "        obs_id_path = os.path.join(mast_path, obs_id)\n",
    "\n",
    "        # Getting list of FITS files in /mastDownload/HST/<obs_id> folder\n",
    "        stis_files = glob.glob(obs_id_path + \"/*fits\")\n",
    "\n",
    "        # Iterating through each of these files to change their path individually\n",
    "        # We will be moving them to /stis_data\n",
    "        for file in stis_files:\n",
    "            file_path = Path(file)\n",
    "            new_path = stis_data_dir / file_path.name\n",
    "            shutil.move(file, new_path)\n",
    "\n",
    "    # Now we can remove the mastDownload directory\n",
    "    if os.path.exists(mast_path):\n",
    "        shutil.rmtree(f\"{stis_data_dir}/mastDownload/\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6cbc4",
   "metadata": {},
   "source": [
    "<a id = runscript></a>\n",
    "## 2. Running the Co-add Script\n",
    "\n",
    "Now that we've downloaded the G191B2B STIS data, we can run the co-add script. \n",
    "\n",
    "In the terminal, run the script by using the next cell's command. Make sure that you are in the `hasp-env` `conda` environment that we created at the beginning of the notebook. It is also possible to run the command directly from the cell below.\n",
    "\n",
    "The `-i` parameter is the input directory (i.e, where the FITS files are located). `-o` is the directory that will contain the newly created co-added products. Note that if you want to exclude certain data files from the co-add, you can just remove them from the input directory.\n",
    "\n",
    "In this case, the code determines that there are significant differences between the `E140M` spectra and rejects any spectra fainter than a certain threshold. The details of the threshold calculation are given in [ISR COS 2024-01](https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/cos/documentation/instrument-science-reports-isrs/_documents/ISR2024-01.pdf). In the output text below, this is identified by phrases such as:\n",
    "\n",
    "`Removing file ./stis_data/o5jy03030_x1d.fits from product.`\n",
    "\n",
    "Dataset `o5jy04030_x1d.fits` is removed from the co-add. However, small STIS echelle apertures often are impacted by changes in observatory focus and do not reflect intrinsic changes to the object. Thus, we can scale the input spectra to a common flux level and improve signal-to-noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!swrapper -i ./stis_data -o ./stis_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5dae88",
   "metadata": {},
   "source": [
    "We can now change the flux scaling for the input spectra and re-run the co-add code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced371d0",
   "metadata": {},
   "source": [
    "<a id = checkflux></a>\n",
    "## 3. Checking Input Spectra for Flux Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae13cc",
   "metadata": {},
   "source": [
    "With the newly co-added files in the `./stis_products/output` directory, we can begin to inspect the data and determine why some of the data was excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e368a5c",
   "metadata": {},
   "source": [
    "Let's first enter the `./stis_products` directory to look at the files. Currently, the script outputs abutted products for a single program and its constituent visits, a file for each grating and a joining of all gratings. For the tutorial, `hst_8435_stis_g191b2b_e140m_o5jy_cspec.fits` is the `E140M` co-add product we will use to compare to our spectra.\n",
    "\n",
    "**Note: Check that this is the correct filename for the co-add; it is possible that the HASP script has been updated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coadd = \"hst_8435_stis_g191b2b_e140m_o5jy_cspec.fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab7fb7",
   "metadata": {},
   "source": [
    "<a id = variance></a>\n",
    "### 3.1 Plot Input Spectra Relative to Each to Other to Search for Variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f588944",
   "metadata": {},
   "source": [
    "We will create a plot of flux as a function of wavelength using `matplotlib.pyplot` to compare the input spectra to the co-add. We will see significant scaling offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2627f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths and filenames for our investigation\n",
    "files = [\"o5jy03010_x1d.fits\", \"o5jy03020_x1d.fits\", \"o5jy03030_x1d.fits\"]\n",
    "\n",
    "# Getting the co-add data\n",
    "coadd_hdul = fits.open(f\"{stis_products_dir}/{coadd}\")\n",
    "coadd_data = coadd_hdul[1].data\n",
    "\n",
    "# Getting the wavelength and flux data for the abutted file\n",
    "wavelength = coadd_data[\"WAVELENGTH\"]\n",
    "flux = coadd_data[\"FLUX\"]\n",
    "\n",
    "# Colors for plotting\n",
    "colors = [\"red\", \"blue\", \"orange\"]\n",
    "\n",
    "# Getting the input spectra\n",
    "for i, filename in enumerate(files):\n",
    "    gd191_hdul = fits.open(f\"{stis_data_dir}/{filename}\")\n",
    "    gd191_x1d = gd191_hdul[1].data\n",
    "\n",
    "    # Getting the flux and wavelength data\n",
    "    wave_x1d = gd191_x1d[\"WAVELENGTH\"]\n",
    "    flux_x1d = gd191_x1d[\"FLUX\"]\n",
    "\n",
    "    # Plotting flux vs wavelength for each X1D in our investigation\n",
    "    plt.scatter(wave_x1d, flux_x1d,\n",
    "                s=1,\n",
    "                label=filename,\n",
    "                color=colors[i])\n",
    "    \n",
    "    gd191_hdul.close()\n",
    "\n",
    "# Plot the coadd for comparison\n",
    "plt.scatter(wavelength, flux,\n",
    "            s=1,\n",
    "            label='coadd',\n",
    "            color='grey')\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title(\"Flux as function of Wavelength, STIS G191B2B\")\n",
    "plt.xlabel(\"Wavelength\")\n",
    "plt.ylabel(\"Flux\")\n",
    "\n",
    "plt.ylim(-2e-12, 1e-11)\n",
    "plt.xlim(1450, 1500)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Saving the figure to the ./stis_products_dir\n",
    "plt.savefig(f\"{stis_products_dir}/flux_vs_wavelength.png\")\n",
    "\n",
    "# Showing the plot below\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a018ff6",
   "metadata": {},
   "source": [
    "The co-add is grey, while the individual spectra are red, blue, and orange, respectively. The dataset that was removed (orange points) from the co-add is systematically lower than the co-add. We next calculate the scaling between the three input spectra and assume that the spectrum with the highest flux is most correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the SNR of co-add for comparison to improved custom co-add later\n",
    "SNR = coadd_data[\"SNR\"]\n",
    "\n",
    "plt.scatter(wavelength, SNR,\n",
    "            s=0.5)\n",
    "\n",
    "# Formatting the plot by adding titles\n",
    "plt.title(\"SNR as function of Wavelength, STIS G191B2B\")\n",
    "plt.xlabel(\"Wavelength\")\n",
    "plt.ylabel(\"SNR\")\n",
    "\n",
    "plt.xlim(1450, 1500)\n",
    "\n",
    "plt.savefig(f\"{stis_products_dir}/snr_vs_wavelength_prescaled.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Closing coadd HDUL\n",
    "coadd_hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea4691",
   "metadata": {},
   "source": [
    "For this particular dataset, a slight difference between the native wavelength bin size of the input co-adds and the output bins results in some bins receiving multiple measures of the flux which increase the SNR above other bins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1108149",
   "metadata": {},
   "source": [
    "<a id = scaleflux></a>\n",
    "## 4. Scaling Input Data\n",
    "\n",
    "We now determine scaling factors to apply to our input data. Using the scaling factors we determine, we re-scale the input spectra, save them as new input files, and re-run the co-add code on the modified datasets, improving the overall SNR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837936f2",
   "metadata": {},
   "source": [
    "<a id = scaling></a>\n",
    "### 4.1 Determine Scaling Factors\n",
    "First we calculate the scale factors needed by taking the median of each spectrum, then using the brightest spectrum median as the normalizing factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9709eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the fluxes of the files we're interested in\n",
    "hdul_010 = fits.open(f\"{stis_data_dir}/o5jy03010_x1d.fits\")\n",
    "flux_010 = hdul_010[1].data[\"FLUX\"]\n",
    "\n",
    "hdul_020 = fits.open(f\"{stis_data_dir}/o5jy03020_x1d.fits\")\n",
    "flux_020 = hdul_020[1].data[\"FLUX\"]\n",
    "\n",
    "hdul_030 = fits.open(f\"{stis_data_dir}/o5jy03030_x1d.fits\")\n",
    "flux_030 = hdul_030[1].data[\"FLUX\"]\n",
    "\n",
    "\n",
    "med_spec_010 = np.median(flux_010)\n",
    "med_spec_020 = np.median(flux_020)\n",
    "med_spec_030 = np.median(flux_030)\n",
    "\n",
    "# # Printing the median flux for each X1D file:\n",
    "print(f\"The median flux for file o5jy03010_x1d.fits is: {str(med_spec_010)}\")\n",
    "print(f\"The median flux for file o5jy03020_x1d.fits is: {str(med_spec_020)}\")\n",
    "print(f\"The median flux for file o5jy03030_x1d.fits is: {str(med_spec_030)}\\n\")\n",
    "\n",
    "print(\"The brightest spectrum is file o5jy03010_x1d.fits\")\n",
    "\n",
    "hdul_010.close()\n",
    "hdul_020.close()\n",
    "hdul_030.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3534c4",
   "metadata": {},
   "source": [
    "We can see that the first spectrum (`o5jy03010_x1d.fits`) is the brightest of the three, so we will use it as the normalizing factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = [1.0,\n",
    "                med_spec_010 / med_spec_020,\n",
    "                med_spec_010 / med_spec_030]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb96c7",
   "metadata": {},
   "source": [
    "<a id = package></a>\n",
    "### 4.2 Rescaling the Data \n",
    "Now that the input files for `E140M` have been rescaled, we create new input files and re-run the co-add script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(files):\n",
    "    g191_hdul = fits.open(f\"{stis_data_dir}/{filename}\")\n",
    "    g191_data = g191_hdul[1].data\n",
    "\n",
    "    # Getting the flux and wavelength data for the X1D files in our investigation\n",
    "    flux = g191_data[\"FLUX\"]\n",
    "    wavelength = g191_data[\"WAVELENGTH\"]\n",
    "\n",
    "    # Multiplying the current file's flux by the approproiate scaling factor\n",
    "    g191_data[\"FLUX\"] = flux * scale_factor[i]\n",
    "\n",
    "    # Writing this scaled data to data directory\n",
    "    g191_hdul.writeto(f\"{stis_scaled_data_dir}/{filename}\",\n",
    "                      overwrite=True)\n",
    "\n",
    "    # Plotting this flux vs wavelength\n",
    "    plt.scatter(wavelength, flux,\n",
    "                s=1,\n",
    "                alpha=0.5,\n",
    "                label=filename,\n",
    "                color=colors[i])\n",
    "    \n",
    "    g191_hdul.close()\n",
    "\n",
    "# Adding formatting\n",
    "plt.title(\"Scaled Flux as function of Wavelength, STIS G191B2B\")\n",
    "plt.xlabel(\"Wavelength\")\n",
    "plt.ylabel(\"Flux\")\n",
    "\n",
    "plt.ylim(-2e-12, 1e-11)\n",
    "plt.xlim(1450, 1500)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"./stis_scaled_data/scaled_flux_vs_wavelength.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ca797",
   "metadata": {},
   "source": [
    "<a id = rerunning></a>\n",
    "### 4.3 Re-running the co-add Script\n",
    "Now that the input files for `E140M` have been rescaled, we can re-run the co-add script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a298c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!swrapper -i ./stis_scaled_data -o ./stis_scaled_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89805b",
   "metadata": {},
   "source": [
    "We see in the output above that no spectra were rejected from the co-add script. Further, we have increased the SNR of the final co-add spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the co-add data\n",
    "gd191_scaled_hdul = fits.open(f\"{stis_scaled_products_dir}/{coadd}\")\n",
    "gd191_scaled = gd191_scaled_hdul[1].data\n",
    "\n",
    "# Getting the wavelength and flux data for the scaled file\n",
    "w_scaled = gd191_scaled[\"WAVELENGTH\"]\n",
    "f_scaled = gd191_scaled[\"FLUX\"]\n",
    "SNR_scaled = gd191_scaled[\"SNR\"]\n",
    "\n",
    "# Remove elements where original SNR = 0\n",
    "SNR_scaled_nonzero = SNR_scaled[np.nonzero(SNR)]\n",
    "SNR_nonzero = SNR[np.nonzero(SNR)]\n",
    "\n",
    "SNR_scaled = SNR_scaled_nonzero / SNR_nonzero\n",
    "\n",
    "w_scaled_nonzero = w_scaled[np.nonzero(SNR)]\n",
    "\n",
    "# Finally we check the SNR of the co-add for comparison to the original co-add\n",
    "plt.scatter(w_scaled_nonzero, SNR_scaled,\n",
    "            s=0.5)\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title(\"Relative SNR gain as function of Wavelength, STIS G191B2B\")\n",
    "plt.xlabel(\"Wavelength\")\n",
    "plt.ylabel(\"Scaled SNR/Original SNR\")\n",
    "\n",
    "plt.xlim(1200, 1700)\n",
    "plt.ylim(1, 1.4)\n",
    "\n",
    "plt.savefig(f\"{stis_scaled_products_dir}/scaled_rel_snr_vs_wavelength.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "gd191_scaled_hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85800c3",
   "metadata": {},
   "source": [
    "# Congrats on completing the notebook!\n",
    "\n",
    "### There are more tutorial notebooks for custom co-addition cases in [this notebooks repo](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP), check them out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c86c8",
   "metadata": {},
   "source": [
    "## About this Notebook\n",
    "**Authors:** John Debes (debes@stsci.edu), Sierra Gomez (sigomez@stsci.edu)\n",
    "\n",
    "**Updated on:** 01/29/2024\n",
    "\n",
    "*This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21e475",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "If you use `astropy`, `astroquery`, `numpy`, or `matplotlib`, for published research, please cite the authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `astropy`](https://docs.astropy.org/en/stable/index.html)\n",
    "\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/citing.html)\n",
    "\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f5842",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
