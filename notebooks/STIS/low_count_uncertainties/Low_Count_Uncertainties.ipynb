{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce8c543-a04b-4fc1-b1b0-a163fa29a8da",
   "metadata": {},
   "source": [
    "<a id=top></a>\n",
    "# Low Count Uncertainties in STIS <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2a09d-d669-414a-a828-0efa956b8661",
   "metadata": {},
   "source": [
    "<h2>Learning Goals<span class=\"tocSkip\"></span></h2>\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "- Understand how the `calstis` pipeline calculates uncertainties with the root-N approximation\n",
    "- Know in what situations this approximation breaks down (i.e., low counts)\n",
    "- Calculate more appropriate Poisson confidence intervals\n",
    "- Compare uncertainties with STIS to those calculated for COS\n",
    "- Know about a bug in the uncertainties calculated in `inttag` when making sub-exposures from TIME-TAG data\n",
    "\n",
    "<div class=\"toc\">\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"0-Introduction-0\">0 Introduction</a></span></li></ul>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Fetch-and-Read-In-Data\" data-toc-modified-id=\"1-Fetch-and-Read-In-Data-1\">1 Fetch and Read In Data</a></span></li></ul>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Pipeline-Uncertainties\" data-toc-modified-id=\"2-Pipeline-Uncertainties-2\">2 Pipeline Uncertainties</a></span></li></ul>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Poisson-Uncertainties\" data-toc-modified-id=\"3-Poisson-Uncertainties-3\">3 Poisson Uncertainties</a></span></li></ul>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Poisson-Uncertainties-Applied-to-STIS\" data-toc-modified-id=\"4-Poisson-Uncertainties-Applied-to-STIS-4\">4 Poisson Uncertainties Applied to STIS</a></span></li></ul>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#New-stistools-Functionality\" data-toc-modified-id=\"5-New-stistools-Functionality-5\">5 New stistools Functionality</a><span></li></ul>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Comparison-to-COS\" data-toc-modified-id=\"6-Comparison-to-COS-6\">6 Comparison to COS</a></span></li></ul>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Recommendations\" data-toc-modified-id=\"7-Recommendations-7\">7 Recommendations</a></span></li></ul>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Appendix:-INTTAG\" data-toc-modified-id=\"Appendix:-INTTAG\">Appendix: INTTAG</a></span></li></ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12bd0ce-fe69-4fb3-a0cf-c6f044d9219d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The root-N approximation for error calculation is ubiquitous in astronomy and is appropriate for a wide-range of observing scenarios. The root-N approximation means that the 1-$\\sigma$ uncertainty associated with any measurement of counts (i.e., electrons on a CCD detector) can be approximated by just taking the square root of the number of counts, $N$. However, this approximation *does* break down for low counts $\\lesssim10$ (inclusive of dark rate and read noise) sometimes seen in UV observations with instruments like HST/STIS and HST/COS.\n",
    "\n",
    "In this notebook, we will look at where and why the root-N approximation breaks down, how the calculate appropriate Poisson confidence intervals, and how to apply that to HST/STIS observations. Some of these issues have been address in the HST/COS pipeline, CalCOS, so we compare to that in Section 5 as well.\n",
    "\n",
    "For more information about calstis see:\n",
    "- [STIS Calibration in the STIS Data Handbook](https://hst-docs.stsci.edu/stisdhb/chapter-3-stis-calibration)\n",
    "- [the `stistools` package documentation](https://stistools.readthedocs.io/en/latest/calstis.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e9cb0-15f1-4c72-87b1-c2db908e31f6",
   "metadata": {},
   "source": [
    "### Import Necessary Packages\n",
    "- `astropy.io.fits` for accessing FITS files\n",
    "- `astroquery.mast.Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- `os`, `shutil`, & `pathlib` for managing system paths\n",
    "- `matplotlib` for plotting data\n",
    "- `numpy` to handle array functions\n",
    "- `stistools` for operations on STIS Data, including the new poisson_err.py\n",
    "- `astropy.stats` and `scipy.stats` for the Poisson confidence interval function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff5736-2646-4bee-a08f-b50b903dce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for: Reading in fits file\n",
    "from astropy.io import fits\n",
    "\n",
    "# Import for: Downloading necessary files\n",
    "# (Not necessary if you choose to collect data from MAST)\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# Import for: Managing system variables and paths\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Import for: Plotting and specifying plotting parameters\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import for: Operations on STIS Data\n",
    "import stistools\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import astropy and scipy stat stuff\n",
    "from astropy.stats import poisson_conf_interval\n",
    "from scipy.stats import norm, poisson\n",
    "\n",
    "# Import for image display\n",
    "from IPython.display import Image\n",
    "\n",
    "# Using a colorblind friendly style\n",
    "plt.style.use('tableau-colorblind10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4669e3ab-4b83-4204-96d6-a1f7b334aa37",
   "metadata": {},
   "source": [
    "## Fetch and Read In Data\n",
    "We're now going to fetch FUV observations to demonstrate where the root-N approximation breaks down. These observations are one orbit of a four-orbit transit time-series of HST/STIS/G140M that observed the Neptune-sized exoplanet GJ 436b transit across the disk of the M-dwarf host star, GJ 436. These observations were used to find hydrogen gas escaping from the planet's atmosphere in a comet-like tail ([Kulow et al. 2014](https://ui.adsabs.harvard.edu/abs/2014ApJ...786..132K/abstract), [Ehrenreich et al. 2015](https://ui.adsabs.harvard.edu/abs/2015Natur.522..459E/abstract))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede8a42-02e6-40db-8985-ae71171521b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove downlaod directory if it already exists\n",
    "if os.path.exists(\"./mastDownload\"):\n",
    "    shutil.rmtree(\"./mastDownload\")\n",
    "\n",
    "# Search target object by obs_id\n",
    "target_id = \"obgh07020\"\n",
    "target = Observations.query_criteria(obs_id=[target_id])\n",
    "\n",
    "# get a list of files assiciated with that target\n",
    "target_list = Observations.get_product_list(target)\n",
    "\n",
    "# download only the x1d file\n",
    "Observations.download_products(target_list, extension='x1d.fits')\n",
    "\n",
    "# get file path\n",
    "file_path_obgh07020 = os.path.join(\n",
    "                    'mastDownload', 'HST', target_id, f'{target_id}_x1d.fits')\n",
    "\n",
    "# read in x1d\n",
    "with fits.open(file_path_obgh07020) as hdu:\n",
    "    header = hdu[0].header\n",
    "    data = hdu[1].data\n",
    "    exptime = hdu[1].header['EXPTIME']\n",
    "    darkcount = hdu[1].header['MEANDARK']\n",
    "    extrsize = hdu[1].data['EXTRSIZE']\n",
    "    flux = hdu[1].data['FLUX'][0]\n",
    "    flux_err = hdu[1].data['ERROR'][0]\n",
    "    net = hdu[1].data['NET'][0]\n",
    "    net_err = hdu[1].data['NET_ERROR'][0]\n",
    "    gross = hdu[1].data['GROSS'][0]\n",
    "    bg = hdu[1].data['BACKGROUND'][0]\n",
    "    waves = hdu[1].data['WAVELENGTH'][0]\n",
    "\n",
    "# Print some relevant information for reference...\n",
    "print(hdu[0].header['TELESCOP'], hdu[0].header['INSTRUME'],\n",
    "      hdu[0].header['DETECTOR'], hdu[0].header['OPT_ELEM'],\n",
    "      hdu[0].header['APERTURE'])\n",
    "print(f\"Program: {hdu[0].header['PROPOSID']}\")\n",
    "print(f\"PI: {hdu[0].header['PR_INV_F']} {hdu[0].header['PR_INV_M']} \\\n",
    "      {hdu[0].header['PR_INV_L']}\")\n",
    "print(f\"Target: {hdu[0].header['TARGNAME']}\")\n",
    "print(f\"Time: {hdu[0].header['TDATEOBS']} {hdu[0].header['TTIMEOBS']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c34f3-43ed-48d9-b527-ae6487ffa048",
   "metadata": {},
   "source": [
    "## Pipeline Uncertainties\n",
    "\n",
    "Here, we will re-create the root-N approximated uncertainties calculated in the pipeline so that we can be sure of what the pipeline is doing. Let's first plot the data, just so we know what were dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14813e1b-e335-4343-a7a2-028477ec88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the flux to see what's going on\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(waves, gross*exptime, label='Gross')\n",
    "ax.plot(waves, net*exptime, label='Net')\n",
    "ax.plot(waves, bg*exptime, label='Background')\n",
    "\n",
    "ax.vlines(1215.67, -10, 2000, color='k', linestyles=':',\n",
    "          label='Ly-$\\\\alpha$')\n",
    "ax.set_xlim(1214.5, 1220)\n",
    "ax.set_ylim(-5, 450)\n",
    "\n",
    "ax.set_ylabel('Flux (Counts)', fontsize=12)\n",
    "ax.set_xlabel('Wavelength ($\\\\mathrm{\\\\AA}$)', fontsize=12)\n",
    "\n",
    "ax.legend(ncol=1, fontsize=11)\n",
    "ax.tick_params(labelsize=11)\n",
    "plt.title('GJ-436 with STIS/G140M')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c36000-b19a-4f57-836b-a97cba135794",
   "metadata": {},
   "source": [
    "You can see large flux from the star's Lyman-$\\alpha$ emission. The core of the line is getting absorbed by the interstellar medium, or \"ISM\", yet the wide wings of the line do show appreciable flux. This is an important indicator of chromospheric activity in low-mass stars. But if you look outside the line, you'll see almost no flux! This is because low-mass stars, like GJ436, will have very little UV-continuum, mostly because of their relatively cool temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c1745-2a53-4eb8-8d97-a503728ab63a",
   "metadata": {},
   "source": [
    "Now let's look at the uncertainties associated with these measurements. The error in the net counts (and subsequently the flux measurement) is initialized in `calstis`. For MAMA data such as this, the pipeline simply takes the square-root of the counts, $I$, as the error in the counts: $\\sigma = \\sqrt{I}$. For CCD data, we must also account for the gain and readnoise, such that $\\sigma = \\sqrt{\\frac{I-bias}{gain}+(\\frac{readnoise}{gain})^2}$. [See ISR 98-26](https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/stis/documentation/instrument-science-reports/_documents/199826.pdf). Note that the square-root must be taken on the *counts*, not the *count rate* or the *flux*.\n",
    "\n",
    "Below, we plot the pipeline uncertainty, as well as a re-creation of the uncertainties from the values in the X1D files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b37f03-d9e7-4151-9b5d-b70ce7bc0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate the errors by taking square root of counts...\n",
    "# Some of the low flux values may be negative\n",
    "# especially after dark subtraction,\n",
    "# so we place a min error at zero (as does the pipeline)\n",
    "# (Remember, we need to convert to counts, not just the count rate)\n",
    "count_err = np.sqrt(np.max([gross*exptime, np.zeros(len(gross))],\n",
    "                           axis=0))\n",
    "# Let's also calculate the counts with the mean dark subtracted\n",
    "# count added back in, because that will also contribute to error\n",
    "count_err_dark = np.sqrt(np.max([gross*exptime+darkcount*extrsize,\n",
    "                                 np.zeros(len(gross))], axis=0))\n",
    "\n",
    "\n",
    "# Let's plot the flux to see how we compare to the pipeline\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(waves, net_err*exptime, label='Net Error (Pipeline)', linewidth=2)\n",
    "ax.plot(waves, count_err, '--', label='Calc Error (Root-N)', linewidth=2)\n",
    "ax.plot(waves, count_err_dark, ':',\n",
    "        label='Calc Error (Root-N) plus Dark', linewidth=2)\n",
    "\n",
    "ax.set_xlim(1214.5, 1220)\n",
    "\n",
    "ax.set_ylabel('Error (Counts)', fontsize=12)\n",
    "ax.set_xlabel('Wavelength ($\\\\mathrm{\\\\AA}$)', fontsize=12)\n",
    "\n",
    "ax.legend(ncol=1, fontsize=11)\n",
    "plt.gca().tick_params(labelsize=11)\n",
    "plt.title('GJ-436 with STIS/G140M')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b62acd-858f-48cd-b62d-49550f12f98c",
   "metadata": {},
   "source": [
    "As you can see, the pipeline uncertainties are mostly just the square root of the counts. Error from dark subtraction is generally pretty small in the FUV; In our observations, the science header states the the mean dark count was 0.0184 counts per pixel (`hdu[1].header['MEANDARK']`) and that's over the whole 2,905 s exposure. In the extraction routines, the pipeline defaults to an extraction height of 11 pixels, so the dark rate is still adding less than a count per wavelength. In the NUV, however, dark rates can be as much as 0.002 counts per second per pixel, which can result in dozens of \"extra\" counts and thus do need to be taken into account in the errors. Errors in the flat-field division will also contribute minutely to the flux error. \n",
    "\n",
    "For this notebook, since we're looking at FUV data, we therefore assume the majority of our error comes from photon noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db0bf5-b7e4-4565-824c-dadcac643021",
   "metadata": {},
   "source": [
    "## Poisson Uncertainties\n",
    "\n",
    "Because we are measuring a discrete, positive number of counts when we read out an astronomical detector, our measurement comes from a Poisson disstribution. The uncertainty associated with a measurement of a variable described by a Poisson distribution is very often assumed to be the square-root of the value measured, as seen above. This is because the Poisson distribution is a univariate distrbution, defined only by its mean, $\\lambda$. The probability of $N$ events is defined as $\\frac{\\lambda^N*e^{-\\lambda}}{N!}$.\n",
    "\n",
    "\n",
    "The Poisson distribution has the special feature that its <u>variance</u> is also equal to $\\lambda$. Thus, we usually take the standard-deviation of a measurement to be $\\sqrt{\\lambda}$.\n",
    "\n",
    "However, the assumption of \"square-root N\" uncertainties is only valid for large $N$. In this large-$n$ regime, the Poisson distribution is relatively symmetric and well-approximated by a Gaussian distribution with standard deviation of $\\sqrt{N}$. At low-$N$, however, the discrete and positive nature of the Poisson distribution results in the distribution becoming highly asymmetric and the Gaussian approximation breaks down. This is demonstrated in the plot below for $\\lambda = 1$ and $\\lambda = 15$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a581ca1b-225a-4d02-848c-d20ea324eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color cycle that we'll be using\n",
    "# cs = ['#1f77b4', '#ff7f0e', '#d62728', '#2ca02c', '#9467bd',\n",
    "#      '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "# Tableau colorblind 10 color cycle\n",
    "cs = ['#006BA4', '#FF800E', '#ABABAB', '#595959',\n",
    "      '#5F9ED1', '#C85200', '#898989', '#A2C8EC',\n",
    "      '#FFBC79', '#CFCFCF']\n",
    "\n",
    "# Define figure\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Define contiuous and discrete N grids (xc and xd)\n",
    "xc = np.linspace(-2, 30, 1000)\n",
    "xd = range(30)\n",
    "\n",
    "# Define and draw our population mean for our first example, mu=lambda=1\n",
    "# as well as the Gaussian (i.e., root-N) 1-sigma bounds\n",
    "mu = 1\n",
    "plt.vlines(1, 0, 1.15, color='k', linestyle=':')\n",
    "plt.vlines(1+np.sqrt(1), 0, 1.15, color='k', linestyle=':', alpha=0.4)\n",
    "plt.vlines(1-np.sqrt(1), 0, 1.15, color='k', linestyle=':', alpha=0.4)\n",
    "\n",
    "plt.plot(xc, norm.pdf(xc, mu, np.sqrt(mu)) /\n",
    "         np.max(norm.pdf(xc, mu, np.sqrt(mu))),\n",
    "         color=cs[3], label='Gaussian, $\\\\lambda$=1, $\\\\sigma = \\\\sqrt{1}$',\n",
    "         linewidth=3)\n",
    "\n",
    "# Do the same for mu=15\n",
    "mu = 15\n",
    "plt.vlines(15, 0, 1.15, color='k', linestyle='--')\n",
    "plt.vlines(15+np.sqrt(15), 0, 1.15, color='k', linestyle='--', alpha=0.4)\n",
    "plt.vlines(15-np.sqrt(15), 0, 1.15, color='k', linestyle='--', alpha=0.4)\n",
    "\n",
    "plt.plot(xc, norm.pdf(xc, mu, np.sqrt(mu)) /\n",
    "         np.max(norm.pdf(xc, mu, np.sqrt(mu))),\n",
    "         color=cs[1], label='Gaussian, $\\\\lambda$=15, $\\\\sigma = \\\\sqrt{15}$',\n",
    "         linewidth=3)\n",
    "\n",
    "# Draw a limit at N=0 to make clear that Gaussian distribution goes beyond\n",
    "plt.vlines(0, 0, 1.15, color='k')\n",
    "\n",
    "# Now do the same for mu=1 and mu=15 but plotting the Poisson distribution\n",
    "mu = 1\n",
    "plt.plot(xd, poisson.pmf(xd, mu)/np.max(poisson.pmf(xd, mu)), 'o', color=cs[2],\n",
    "         label='Poisson, $\\\\lambda$=1', markersize=8)\n",
    "plt.plot(xd, poisson.pmf(xd, mu)/np.max(poisson.pmf(xd, mu)),\n",
    "         color=cs[2], alpha=0.9)\n",
    "mu = 15\n",
    "plt.plot(xd, poisson.pmf(xd, mu)/np.max(poisson.pmf(xd, mu)), 'o', color=cs[0],\n",
    "         label='Poisson, $\\\\lambda$=15', markersize=8)\n",
    "plt.plot(xd, poisson.pmf(xd, mu)/np.max(poisson.pmf(xd, mu)),\n",
    "         color=cs[0], alpha=0.9)\n",
    "\n",
    "plt.ylim(0, 1.15)\n",
    "plt.xlim(-2, 25)\n",
    "plt.legend(ncol=1, fontsize=12, loc='upper right')\n",
    "plt.gca().tick_params(labelsize=12)\n",
    "plt.ylabel('PDF/PMF (Normalized to Max=1)', fontsize=14)\n",
    "plt.xlabel('N', fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d6ec47-6839-46dd-9f55-497cf0fcfaae",
   "metadata": {},
   "source": [
    "The asymmetry in the Poisson distribution therefore implies we need a different approach to estimate our uncertainties. For that, we'll need to define an upper- and lower-limits on the confidence interval (CI). Formally, [Geherels (1986)](https://ui.adsabs.harvard.edu/abs/1986ApJ...303..336G/abstract) defines these, respectively, as:\n",
    "\n",
    "$\\sum_{x=0}^{N}\\frac{\\lambda_u^x e^{-\\lambda_u}}{x!} = 1 - CL$\n",
    "\n",
    "$\\sum_{x=0}^{N-1}\\frac{\\lambda_l^x e^{-\\lambda_l}}{x!} = CL $     $(n \\neq 0)$\n",
    "\n",
    "Unfortunately, there is no closed form solution to these for $\\lambda_u$ and $\\lambda_l$. To calculate $\\lambda_u$ and $\\lambda_l$, various analytic approximations have been developed based on numerical tabulations, as in [Gehrels (1986)](https://ui.adsabs.harvard.edu/abs/1986ApJ...303..336G/abstract). In that work, Neil Gehrels finds the following 1-$\\sigma$ limit approximations that we'll demonsrate here:\n",
    "\n",
    "$\\lambda_u = N + \\sqrt{N+\\frac{3}{4}} + 1 $\n",
    "\n",
    "$\\lambda_d = N (1 - \\frac{1}{9N} - \\frac{1}{3\\sqrt{N}})^3 $\n",
    "\n",
    "As $N \\to \\infty$, the approximation will approach the Gaussian $\\sqrt{N}$ approximation. Within astropy.stats, these approximations are implemented in \"poisson_conf_interval\". To get the correct confidence interval method, we choose \"frequentist-confidence\", which recreates these limits closely (confusingly, don't use the \"sherpagehrels\" method, which just uses the upper limit symmetrically).\n",
    "\n",
    "\n",
    "Let's see how this is done and compare to root-N estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c71132-4536-4a7c-bbd3-64f1c08c0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that gives us our 1-sigma Poisson\n",
    "# confidence interval and (subtracting off N)\n",
    "def gehrels_pci(ns):\n",
    "    up = 1+np.sqrt(ns+0.75)\n",
    "    lo = np.array([n-(n*(1-(1/(9*n))-(1/(3*np.sqrt(n))))**3)\n",
    "                   if n > 0 else 0.0 for n in ns])\n",
    "    return [lo, up]\n",
    "\n",
    "\n",
    "lw = 3\n",
    "ms = 9\n",
    "N = np.arange(10)\n",
    "plt.figure()\n",
    "plt.plot(N, np.sqrt(N), label='Root-N Approximation', linewidth=lw)\n",
    "plt.plot(N, N-poisson_conf_interval(N, interval='frequentist-confidence')[0],\n",
    "         '-', label='Astropy Lower PCI', linewidth=lw)\n",
    "plt.plot(N, poisson_conf_interval(N, interval='frequentist-confidence')[1]-N,\n",
    "         '-', label='Astropy Upper PCI', linewidth=lw)\n",
    "plt.plot(N, gehrels_pci(N)[1], 'o', label='Gehrels Upper PCI', markersize=ms)\n",
    "plt.plot(N, gehrels_pci(N)[0], 'o', label='Gehrels Lower PCI', markersize=ms)\n",
    "plt.legend(ncol=1, fontsize=12, loc='lower right')\n",
    "plt.gca().tick_params(labelsize=14)\n",
    "plt.ylabel('1-$\\\\sigma$ Uncertainties', fontsize=16)\n",
    "plt.xlabel('N', fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83863d6e-50d5-41aa-89c0-38044e142554",
   "metadata": {},
   "source": [
    "As you can see, the uncertainties calculated for a measurement from the Poisson distribution are not well-approximated by the Gaussian root-N approximation, especially for the upper bounds. This is because the upper bounds is basically the root-N approximation plus 1. Futhermore, and importantly, at N=0, the root-N approximation says that our uncertinaity goes to zero, which is clearly absurd! If we don't measure any counts on a pixel, we shouldn't somehow be inifintely sure there were no photons there. The Poisson distribution handles N=0 with an upper limit of 1.866 (while the lower limit does indeed go to zero; we cannot have negative counts!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555cfd6-b8bb-4876-b7d1-a079ed43a12c",
   "metadata": {},
   "source": [
    "## Poisson Uncertainties Applied to STIS\n",
    "As explained above in Section 2, there are some scenarios on STIS where count rates are low enough that the Gaussian approximation should break down. And in Section 3, we saw explicitly how it breaks down and how to properly apply Poisson Confidence Intervals might work. Here, we'll apply Poisson Confidence Intervals to the same FUV STIS data we saw above.\n",
    "\n",
    "Let's zoom into the wavelengths longward of Ly-$\\alpha$, where our signal is very, very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65b4a9-05dc-4435-ba8d-012c045bd4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our flux longward of Ly-A\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n",
    "ax[0].plot(waves, gross*exptime, label='Gross')\n",
    "ax[0].plot(waves, net*exptime, label='Net')\n",
    "ax[0].plot(waves, bg*exptime, label='Background')\n",
    "\n",
    "ax[0].set_xlim(1217, 1220)\n",
    "ax[0].set_ylim(-1, 5)\n",
    "\n",
    "ax[0].set_ylabel('Flux (Counts)', fontsize=12)\n",
    "\n",
    "ax[0].legend(ncol=1, fontsize=11)\n",
    "ax[0].tick_params(labelsize=11)\n",
    "plt.title('GJ-436 with STIS/G140M')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot errors in this low-count regime\n",
    "ax[1].plot(waves, net_err*exptime, label='Net Error (Pipeline)', linewidth=2)\n",
    "ax[1].plot(waves, count_err, '--', label='Calc Error (Root-N)', linewidth=2)\n",
    "ax[1].plot(waves, count_err_dark, ':',\n",
    "           label='Calc Error (Root-N) plus Dark', linewidth=2)\n",
    "\n",
    "ax[1].set_xlim(1217, 1220)\n",
    "ax[1].set_ylim(-0.2, 3.5)\n",
    "\n",
    "ax[1].set_ylabel('Error (Counts)', fontsize=12)\n",
    "ax[1].set_xlabel('Wavelength ($\\\\mathrm{\\\\AA}$)', fontsize=12)\n",
    "\n",
    "ax[1].legend(ncol=1, fontsize=11)\n",
    "ax[1].tick_params(labelsize=11)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ddb61-add4-47a9-9901-f6b58a0addf2",
   "metadata": {},
   "source": [
    "You can see just what we were warning about above at the end of Section 3: when the measured counts go to (or near) zero, our uncertainty now becomes infintesimal... or equivalently, our certainty becomes infinite! So let's see what the proper Poisson unceratinties are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c60f5b2-b58c-4a95-a5e3-bf93116d3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "ax.plot(waves, net_err*exptime, label='Net Error', linewidth=2)\n",
    "\n",
    "N = gross*exptime\n",
    "# need nan to num b/c some negative values...\n",
    "ax.plot(waves, np.nan_to_num(\n",
    "        N-poisson_conf_interval(N, interval='frequentist-confidence')[0]),\n",
    "        '-', label='Astropy Lower PCI', linewidth=lw)\n",
    "ax.plot(waves,\n",
    "        poisson_conf_interval(N, interval='frequentist-confidence')[1]-N,\n",
    "        '-', label='Astropy Upper PCI', linewidth=lw)\n",
    "\n",
    "ax.set_xlim(1217, 1220)\n",
    "ax.set_ylim(-0.2, 3.5)\n",
    "\n",
    "ax.set_ylabel('Error (Counts)', fontsize=12)\n",
    "ax.set_xlabel('Wavelength ($\\\\mathrm{\\\\AA}$)', fontsize=12)\n",
    "\n",
    "ax.legend(ncol=1, fontsize=11)\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c138b49-7d82-4e21-b021-8950eba1de41",
   "metadata": {},
   "source": [
    "When just assuming root-N errors, as the `calstis` pipeline currently does, we are therefore clearly underestimating the true Poisson uncertainty in this low-count regime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535cbe1-1c09-4e06-b278-47f20c32073a",
   "metadata": {},
   "source": [
    "## New `stistools` Functionality\n",
    "\n",
    "To address this concern, we have implemented a new function within `stistools` to calculate these Poisson confidence intervals for you. `stistools.poisson_err.poisson_err(x1dfile, output,  verbose=True)` takes in any _x1d.fits file, calculates the Poisson confidence interval, and adds new columns for the upper and lower error intervals for the net count rate (`NET_ERROR_PCI_UP` and `NET_ERROR_PCI_LOW`) and fluxes (`ERROR_PCI_UP` and `ERROR_PCI_LOW`). We have also added a `N_COUNTS` column with the number of counts used to calculate these errors with Astropy (N = (NET_ERROR*exptime)$^2$). By calculating the total counts from the net error, we can include the counts from the dark frame that were included in the noise calculation.\n",
    "\n",
    "Let's try it out on our file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03af70f-dc31-404a-bb4d-081ea95c16ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1dfile = 'mastDownload/HST/obgh07020/obgh07020_x1d.fits'\n",
    "output = 'mastDownload/HST/obgh07020/obgh07020_PCI_x1d.fits'\n",
    "\n",
    "try:\n",
    "    stistools.poisson_err.poisson_err(x1dfile, output)\n",
    "except AttributeError:\n",
    "    print('Need to install latest version of stistools (>=1.4.5)')\n",
    "\n",
    "with fits.open(output) as hdu:\n",
    "    new_header = hdu[0].header\n",
    "    new_exptime = hdu[1].header['EXPTIME']\n",
    "    new_extrsize = hdu[1].data['EXTRSIZE']\n",
    "    new_flux = hdu[1].data['FLUX'][0]\n",
    "    new_flux_err = hdu[1].data['ERROR'][0]\n",
    "    new_net = hdu[1].data['NET'][0]\n",
    "    new_net_err = hdu[1].data['NET_ERROR'][0]\n",
    "    new_net_err_pci_up = hdu[1].data['NET_ERROR_PCI_UP'][0]\n",
    "    new_net_err_pci_low = hdu[1].data['NET_ERROR_PCI_LOW'][0]\n",
    "    new_waves = hdu[1].data['WAVELENGTH'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519529a5-68f9-4d23-b6e7-449be8e13f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "ax.plot(waves, net_err*exptime, label='Net Error', linewidth=2)\n",
    "\n",
    "N = (net_err*exptime)**2\n",
    "# need nan to num b/c some negative values...\n",
    "ax.plot(waves, np.nan_to_num(\n",
    "        N-poisson_conf_interval(N, interval='frequentist-confidence')[0]),\n",
    "        '-', label='Manual Astropy Lower PCI', linewidth=lw)\n",
    "ax.plot(waves,\n",
    "        poisson_conf_interval(N, interval='frequentist-confidence')[1]-N,\n",
    "        '-', label='Manual Astropy Upper PCI', linewidth=lw)\n",
    "\n",
    "ax.plot(new_waves, new_net_err_pci_low*new_exptime,\n",
    "        '--', label='stistools Lower PCI', linewidth=lw)\n",
    "\n",
    "ax.plot(new_waves, new_net_err_pci_up*new_exptime,\n",
    "        '--', label='stistools Upper PCI', linewidth=lw)\n",
    "\n",
    "ax.set_xlim(1217, 1220)\n",
    "ax.set_ylim(-0.2, 3.5)\n",
    "\n",
    "ax.set_ylabel('Error (Counts)', fontsize=12)\n",
    "ax.set_xlabel('Wavelength ($\\\\mathrm{\\\\AA}$)', fontsize=12)\n",
    "\n",
    "ax.legend(ncol=1, fontsize=11)\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "fig.tight_layout()\n",
    "print(hdu[1].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faac0f20-3e7c-4953-b56f-3e9c9a87a9a6",
   "metadata": {},
   "source": [
    "As you can see, the stistools.poisson_err.poisson_err function re-creates our manual calculation of the Poisson confidence interval with Astropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e344fd-4987-4f5f-93a3-da924644540e",
   "metadata": {},
   "source": [
    "## Comparison to COS\n",
    "STIS is not the only FUV instrument on HST! The Cosmic Origins Spectrograph has similar UV channels where the regime of low-signal will be relevant. [COS ISR 2021-03](https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/cos/documentation/instrument-science-reports-isrs/_documents/COS_ISR_2021_03.pdf) describes updates to the HST/COS pipeline, [CalCOS](https://github.com/spacetelescope/calcos), that takes into account Poisson uncertainties.\n",
    "\n",
    "Let's take a look at COS observations of our now-favorite exoplanet system, GJ-436."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f4709-ad56-4d3a-8b66-35a6fb69d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a COS file for observations of GJ 436\n",
    "target_id = \"LD9M12010\"\n",
    "target = Observations.query_criteria(obs_id=[target_id])\n",
    "\n",
    "# get a list of files assiciated with that target\n",
    "target_list = Observations.get_product_list(target)\n",
    "\n",
    "# Download just the x1d file\n",
    "Observations.download_products(target_list, extension='ld9m12erq_x1d.fits')\n",
    "\n",
    "# get file path\n",
    "file_path_ld9m12erq = os.path.join('.', 'mastDownload',\n",
    "                                   'HST', 'ld9m12erq', 'ld9m12erq_x1d.fits')\n",
    "\n",
    "# read in x1d\n",
    "with fits.open(file_path_ld9m12erq) as hdu:\n",
    "    header = hdu[0].header\n",
    "    data = hdu[1].data\n",
    "    exptime = hdu[1].header['EXPTIME']\n",
    "    # no meandark calculated\n",
    "    # darkcount = hdu[1].header['MEANDARK']\n",
    "    # extrsize = hdu[1].data['EXTRSIZE']\n",
    "    flux = hdu[1].data['FLUX'][0]\n",
    "    flux_err_up = hdu[1].data['ERROR'][0]\n",
    "    flux_err_lo = hdu[1].data['ERROR_lower'][0]\n",
    "    net = hdu[1].data['NET'][0]\n",
    "    var_counts = hdu[1].data['VARIANCE_COUNTS'][0]\n",
    "    var_bkg = hdu[1].data['VARIANCE_BKG'][0]\n",
    "    var_flat = hdu[1].data['VARIANCE_FLAT'][0]\n",
    "    gross = hdu[1].data['GROSS'][0]\n",
    "    bg = hdu[1].data['BACKGROUND'][0]\n",
    "    waves = hdu[1].data['WAVELENGTH'][0]\n",
    "\n",
    "# Print some relevant information for reference...\n",
    "print(hdu[0].header['TELESCOP'], hdu[0].header['INSTRUME'],\n",
    "      hdu[0].header['DETECTOR'], hdu[0].header['OPT_ELEM'],\n",
    "      hdu[0].header['APERTURE'])\n",
    "print(f\"Program: {hdu[0].header['PROPOSID']}\")\n",
    "print(f\"PI: {hdu[0].header['PR_INV_F']} {hdu[0].header['PR_INV_M']}\\\n",
    "      {hdu[0].header['PR_INV_L']}\")\n",
    "print(f\"Target: {hdu[0].header['TARGNAME']}\")\n",
    "print(f\"Date: {hdu[0].header['DATE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d37e4-bba4-4333-b83f-30d0dfd78310",
   "metadata": {},
   "source": [
    "For COS, columns have been added to the to the processed files (see the list printed below), giving both the Poisson upper and lower errors as well as the equivalent counts from the flux, background, and flat-fields that contribute to the error. The \"equivalent counts\" are listed in the \"VARIANCE_*\" columns in the x1d files can be used to recreate the Poisson confidence interval calculated in the ERROR and ERROR_LOWER columns.\n",
    "\n",
    "Also printed below are the maximum and mean VARIANCE_BKG, VARIANCE_FLAT, and VARIANCE_COUNTS values. You can see that the equivalent counts and therefore the subsequent uncertainties are dominated by the measurement of the signal itself, not the background or flat-field reduction steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3e2c2-1743-49fe-8c47-5f14eee69b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "\n",
    "# Print some invo about the VARIANCE counts\n",
    "print('Max of VARIANCE_BKG, VARIANCE_FLAT, and VARIANCE_COUNTS:')\n",
    "print(np.max(var_bkg), np.max(var_flat), np.max(var_counts))\n",
    "\n",
    "print('Mean of VARIANCE_BKG, VARIANCE_FLAT, and VARIANCE_COUNTS:')\n",
    "print(np.mean(var_bkg), np.mean(var_flat), np.mean(var_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c966e-3bab-4518-925d-d5785a8b9118",
   "metadata": {},
   "source": [
    "Now, let's look at what the spectrum and errors look like. While we're looking at the same system, GJ 436, these COS observations are taken at a somewhat longer wavelength range, but otherwise the behavior is the similar to what is seen in STIS (i.e., some strong stellar emission lines surrounded by a very low-count FUV continuum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e5664-457f-4b16-b066-5b586ffa89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at what the spectrum and errors really look like\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(waves, gross*exptime, label='Gross Counts', zorder=999)\n",
    "ax.plot(waves, net*exptime, label='Net Counts', zorder=998)\n",
    "ax.plot(waves, var_counts, label='Var Counts', zorder=997)\n",
    "\n",
    "ax.set_xlim(1290, 1310)\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylabel('Flux (counts)', fontsize=12)\n",
    "ax.set_xlabel('Wavelength ($\\\\mathrm{\\\\AA}$)', fontsize=12)\n",
    "\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Zoom in on low_SNR region\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(waves, gross*exptime, label='Gross Counts', zorder=999)\n",
    "ax.plot(waves, net*exptime, label='Net Counts', zorder=998)\n",
    "ax.plot(waves, var_counts, label='Var Counts', zorder=997)\n",
    "\n",
    "ax.set_xlim(1380, 1390)\n",
    "ax.set_ylim(-0.5, 2.5)\n",
    "\n",
    "ax.set_ylabel('Flux (counts)', fontsize=12)\n",
    "ax.set_xlabel('Wavelength ($\\\\mathrm{\\\\AA}$)', fontsize=12)\n",
    "\n",
    "ax.tick_params(labelsize=11)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd5d8d-f554-419f-a1cb-d658df43bee2",
   "metadata": {},
   "source": [
    "You can see that outside of the emission lines seen between 1300 and 1307 Angstrom, counts are varying between 0, 1, or 2. This is the regime where the Gaussian root-N approximation breaks down. Below, we show how the pipeline Poisson Confidence Interval upper and lower limits compare to the root-N approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa90399-623c-40c2-afa2-51a7402709c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert flux errors to counts/s and then to counts\n",
    "# You'll get a RuntimeWarning here because some of the values of net and\n",
    "# flux are zero at the edges of the detector, so it is dividing by zero...\n",
    "sensitivity = net/flux  # counts per second per flux\n",
    "count_err_up = flux_err_up * exptime * sensitivity\n",
    "count_err_low = flux_err_lo * exptime * sensitivity\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(waves, np.sqrt(var_counts), label='Root-N')\n",
    "ax.plot(waves, count_err_up, label='COS Pipeline PCI Upper')\n",
    "ax.plot(waves, count_err_low, label='COS Pipeline PCI Lower')\n",
    "ax.legend()\n",
    "ax.set_xlim(1380, 1390)\n",
    "ax.set_ylim(-0.25, 2.75)\n",
    "\n",
    "plt.gca().set_ylabel('Error (counts)', fontsize=12)\n",
    "plt.gca().set_xlabel('Wavelength ($\\\\mathrm{\\\\AA}$)', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4fc7f-0df4-448a-b55b-09d81ffca6e8",
   "metadata": {},
   "source": [
    "You can see that the COS pipeline gives lower bound uncertainties lower than root-N, but the upper bound uncertainties are significantly higher than root-N (coming from the \"extra +1\" in the Poisson upper confidence interval, related to the \"continuity correction\" between the discrete Poisson and continuous Gaussian distributions). This is crucial for quantifying non-detections. For example, the sorts of upper limits you can place on something like the FUV continuum of an M-dwarf can come down to how you treat these sorts of uncertainties.\n",
    "\n",
    "Thus, the COS pipeline does indeed give the correct Poisson uncertainties. This must be kept in mind when comparing STIS and COS data, especially when taken directly from the pipelines. Make sure you're uncertainties are calculated in the way you expect/desire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f883e71-7715-4688-8765-17e0c6efea3f",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "As of 04/2025, the `calstis` pipeline calculates all errors according to the root-N approximation. We have therefore implemented a `stistools` function, `poisson_err.poisson_err` that calculates Poisson confidence intervals for STIS data. The function adds columns with the new errors to any x1d file.\n",
    "\n",
    "In the NUV, long exposures generally have enough dark counts to be in the regime where the Gaussian approximation is at least somewhat valid. For short exposures, however, measured counts may indeed be and users may want to opt for a Poisson confidence interval. Because the FUV dark rate is significantly lower than in the NUV, users will want to add the dark counts to the measured number of counts for NUV observations before calculating the Poisson confidence intervals, which is done in `poisson_err.poisson_err` by reconstructing the measured counts from the NET_ERROR, which will include the wavelength-specific dark counts as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b706da9-86eb-4f6b-b5a3-dd722223a870",
   "metadata": {},
   "source": [
    "## Appendix: INTTAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e3d0f-4908-4a3b-a61c-3e808bff4c29",
   "metadata": {},
   "source": [
    "There was recently a bug discovered in the procedure to split STIS TIME-TAG data into sub-exposures. That procedure is carried out with the [`inttag` task in stistools](https://stistools.readthedocs.io/_/downloads/en/doc_updates_rtd/pdf/). `inttag` takes the TIME-TAG table and splits them into sub-exposures with a user-defined duration (*increment* argument) or into a user-defined number of sub-exposures (*rcount* argument). The bug was resulting in errors that were significantly inflated, especially in regions of low flux.\n",
    "\n",
    "Let's download the TIME-TAG file that is associated with the STIS/G140L spectrum of GJ-436 we used above. Previously, we were just using the orbit-long exposure, but let's use the .tag file to split up the file into 3 subexposures using `inttag`.\n",
    "\n",
    "After we split the file up, we'll then run `calstis` to compare the new calibrated x1d file to the original, non-split x1d file. To do this, we'll need to set some paths for the CRDS reference files. You can read more about them here: https://hst-crds.stsci.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769f40d-7095-4ec8-8f18-e7caf69d4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's grab the tag file associated with the x1d STIS file\n",
    "# that we downloaded above\n",
    "target_id = \"obgh07020\"\n",
    "target = Observations.query_criteria(obs_id=[target_id])\n",
    "\n",
    "# get a list of files assiciated with that target\n",
    "target_list = Observations.get_product_list(target)\n",
    "\n",
    "# Download the tag file for this observation\n",
    "Observations.download_products(target_list, extension='tag.fits')\n",
    "\n",
    "# get file paths\n",
    "tag_file = os.path.join('.', 'mastDownload',\n",
    "                        'HST', target_id, f'{target_id}_tag.fits')\n",
    "raw_file = os.path.join('.', 'mastDownload',\n",
    "                        'HST', target_id, f'{target_id}_raw.fits')\n",
    "\n",
    "# Split up the time-tag file into 10 subexposures\n",
    "stistools.inttag.inttag(tag_file, raw_file, rcount=3)\n",
    "\n",
    "# We then want to re-reduced the raw data to get x1d files,\n",
    "# and then we'll compare:\n",
    "# To do this, we also need to download the *_wav.fits file for the wavcal\n",
    "Observations.download_products(target_list, extension='wav.fits')\n",
    "\n",
    "# Set up CRDS\n",
    "crds_path = os.path.expanduser(\"~\") + \"/crds_cache\"\n",
    "os.environ[\"CRDS_PATH\"] = crds_path\n",
    "os.environ[\"CRDS_SERVER_URL\"] = \"https://hst-crds.stsci.edu\"\n",
    "os.environ[\"oref\"] = os.path.join(crds_path, \"references/hst/oref/\")\n",
    "!crds bestrefs --update-bestrefs --sync-references=1 --files {raw_file}\n",
    "\n",
    "# We need to remove the x1d file we downloaded before\n",
    "# because we'll replace it with the inttag version\n",
    "inttag_path = os.path.join('.', 'mastDownload',\n",
    "                           'HST', target_id, 'inttag*.fits')\n",
    "inttag_files = glob.glob(inttag_path)\n",
    "for file in inttag_files:\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except OSError:\n",
    "        print('No need to remove...')\n",
    "\n",
    "# Now run calstis...\n",
    "wave_file = os.path.join('.', 'mastDownload',\n",
    "                         'HST', target_id, f'{target_id}_wav.fits')\n",
    "output_path = os.path.join('.', 'mastDownload',\n",
    "                           'HST', target_id, 'inttag')\n",
    "stistools.calstis.calstis(raw_file, wavecal=wave_file, verbose=False,\n",
    "                          outroot=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a823269-4ce8-4749-9882-f4142ed6933a",
   "metadata": {},
   "source": [
    "It was noticed that the uncertainties associated with the subexposures were higher than the root-N expectation. For example, if we plot the uncertainties in the extracted spectrum, the resulting uncertainties on those sub-exposures was far larger than just $\\sqrt{N_\\mathrm{frames}}$ times the uncertainty on the full exposure. We see this below. \n",
    "\n",
    "The top plot shows the errors from the new `inttag` script, while the bottom plot shows the errors from the former implimentation. As you can see, the former implementation was greatly overestimating the errors in the low-flux region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362f2aa-fd4a-4a29-9744-973088bdc259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the files\n",
    "hdu = fits.open(file_path_obgh07020)\n",
    "inttag_x1d_path = os.path.join('.', 'mastDownload',\n",
    "                               'HST', target_id, 'inttag_x1d.fits')\n",
    "hdu_int = fits.open(inttag_x1d_path)\n",
    "\n",
    "# Plot the files\n",
    "plt.figure()\n",
    "plt.plot(hdu[1].data['WAVELENGTH'][0],\n",
    "         hdu[1].data['NET_ERROR'][0],\n",
    "         label='Full exposure errors')\n",
    "plt.plot(hdu[1].data['WAVELENGTH'][0],\n",
    "         hdu[1].data['NET_ERROR'][0]*np.sqrt(3),\n",
    "         label='$\\\\sqrt{3}$ Sub-exposure expectation')\n",
    "\n",
    "plt.plot(hdu_int[2].data['WAVELENGTH'][0],\n",
    "         hdu_int[2].data['NET_ERROR'][0],\n",
    "         label='Sub-exposure pipeline error')\n",
    "plt.xlim(1210, 1220)\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().set_ylabel('Error (counts/s)', fontsize=12)\n",
    "plt.gca().set_xlabel('Wavelength ($\\\\mathrm{\\\\AA}$)', fontsize=12)\n",
    "plt.gca().set_title('New INTTAG Implementation', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb8f2b-a29b-453e-befc-cb6dbe9f42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"STIS_GJ436b_inttag.png\", width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2811e06-2524-4822-8fe9-b89fe9800f15",
   "metadata": {},
   "source": [
    "Upon further inspection, it was found that this bug was related to these Poisson confidence intervals! When `inttag` fills the error arrays for the sub-exposure, rather than taking the square-root of the counts (as the pipeline would normally do), *inttag* actually used to use Astropy's poisson_confidence_interval. Unfortunately, `inttag` uses the incorrect method, choosing \"sherpagehrels\" over the more correct \"frequentist-confidence\". As we explored above, \"sherpagehrels\" actually gives symmetric lower and upper bounds, fixed to the upper bound calculated in [Gehrels (1986)](https://ui.adsabs.harvard.edu/abs/1986ApJ...303..336G/abstract). This was probably originally done because there was only room for one value in the error array, so the more conservative upper confidence interval was chosen. \n",
    "\n",
    "Furthermore, the Poisson errors are calculated at the pixel level, rather than after spectral extraction where the counts have been added up along columns. In the root-N approximation, this doesn't matter, because adding the root-N errors in quadrature is equivalent to taking the square root of the summed column:\n",
    "\n",
    "$\\sqrt{\\sum_i{(\\sqrt{n_i})^2}} = \\sqrt{\\sum_i{n_i}} = \\sqrt{N}$,\n",
    "\n",
    "where $n_i$ is the count measured on the $i$th pixel of a column and $N$ is the count for the entire column. In other words, it doesn't matter how the counts are arranged on a pixel column, all that matters is their sum. **But this is not true for Poisson errors.** Whether all your counts are centered on one pixel or whether your counts are distributed evenly accross your extraction window will change what the uncertainty on your spectrum is! \n",
    "\n",
    "You can see that in the following example, where we have to scenarios for how the flux is distributed along a column: either all the flux is in one pixel or it is evenly distributed. We then calculate the uncertainty on the extracted flux using the root-N approximation, first adding the error of each pixel in quadrature and then by summing the column and *then* calculating the error. These two methods give the same answer in both scenarios.\n",
    "\n",
    "Then, we do the same thing but using Poisson confidence intervals with `astropy`. Now, when we calculate the errors pixel-by-pixel or on the extracted flux, we get different answers depending on how the counts are distributed and depending on how we add them up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c214f8-3ffa-4871-95e4-a302bfecf6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take two scenarios for how the counts are distributed across\n",
    "# a fictional extraction window (i.e., column)\n",
    "scenario1 = [0, 0, 10, 0, 0]\n",
    "scenario2 = [2, 2, 2, 2, 2]\n",
    "\n",
    "\n",
    "# define helper functions for the following print statements\n",
    "def quadrature(scenario):\n",
    "    return np.sqrt(np.sum([np.sqrt(i)**2 for i in scenario]))\n",
    "\n",
    "\n",
    "def sum_sq(scenario):\n",
    "    return np.sqrt(np.sum(scenario))\n",
    "\n",
    "\n",
    "def pixel_err(scenario):\n",
    "    return np.sqrt(np.sum(\n",
    "        [(poisson_conf_interval(i, interval='frequentist-confidence')[1]-i)**2\n",
    "         for i in scenario]))\n",
    "\n",
    "\n",
    "def upper_err(scenario):\n",
    "    return (poisson_conf_interval(\n",
    "            np.sum(scenario), interval='frequentist-confidence')[1]\n",
    "            - np.sum(scenario))\n",
    "\n",
    "\n",
    "# Print the errors calculated in the various scenarios\n",
    "print('Scenario 1: ', scenario1)\n",
    "print('Scenario 2: ', scenario2)\n",
    "print('---')\n",
    "print('Root-N Approximation')\n",
    "print('---')\n",
    "print('Scenario 1')\n",
    "print('---')\n",
    "print('Root-N approximation, add in quadrature: ', quadrature(scenario1))\n",
    "print('Root-N approximation, sum column, then take sqrt: ', sum_sq(scenario1))\n",
    "print('---')\n",
    "print('Poisson, pixel-by-pixel error calculation: ', pixel_err(scenario1))\n",
    "print('Poisson upper limit, sum column, then calculate error: ',\n",
    "      upper_err(scenario1))\n",
    "print('---')\n",
    "print('Scenario 2')\n",
    "print('---')\n",
    "print('Root-N approximation, add in quadrature: ', quadrature(scenario2))\n",
    "print('Root-N approximation, sum column, then take sqrt: ', sum_sq(scenario2))\n",
    "print('---')\n",
    "print('Poisson, pixel-by-pixel error calculation: ', pixel_err(scenario2))\n",
    "print('Poisson upper limit, sum column, then calculate error: ',\n",
    "      upper_err(scenario2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c966da-3dc5-40a3-9b31-843c40fedd9d",
   "metadata": {},
   "source": [
    "**Recommendation:** In the end, our recommendation is to use the Poisson confidence intervals, but not at the pixel level because measurements along a column are not independent events. You would therefore be justified in calculating the Poisson confidence interval on the summed flux at each wavelength/column.\n",
    "\n",
    "This bug has been fixed in `stistools.inttag` [here](https://github.com/spacetelescope/stistools/tree/sl_inttag-errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c5585-ba00-44a1-8bab-1acb2c9b8412",
   "metadata": {},
   "source": [
    "---\n",
    "## About this Notebook <a class=\"tocSkip\">\n",
    "**Author:** [Joshua Lothringer](jlothringer@stsci.edu) with help from [Leo dos Santos](ldsantos@stsci.edu)\n",
    "\n",
    "**Updated On:** 2025-04-10\n",
    "\n",
    "\n",
    "> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n",
    "## Citations <a class=\"tocSkip\">\n",
    "\n",
    "If you use `astropy`, `matplotlib`, `astroquery`, `scipy`, or `numpy` for published research, please cite the\n",
    "authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `scipy`](https://scipy.org/citing-scipy/)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/citing.html)\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/)\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "* [Citing `astropy`](https://www.astropy.org/acknowledging.html)\n",
    "\n",
    "---\n",
    "\n",
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334ba08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
