{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "detected-representation",
   "metadata": {},
   "source": [
    "<a id=\"topE\"></a>\n",
    "\n",
    "# Editing the extraction boxes in a spectral extraction file (`XTRACTAB`)\n",
    "\n",
    "# Learning Goals\n",
    "<font size=\"4 \"> This Notebook is designed to walk the user (<em>you</em>) through: <b>Altering the extraction box used to extract your spectrum from a COS `TIME-TAG` exposure file.</b></font>\n",
    "\n",
    "**1. [Investigating the exposure](#invE)**\n",
    "\n",
    "\\- 1.1. [Understanding the `XTRACTAB` and examining a 2D spectrum](#lookE)\n",
    "\n",
    "\\- 1.2. [Defining some useful functions](#funE)\n",
    "\n",
    "\\- 1.3. [Examining the extraction boxes](#boxE)\n",
    "\n",
    "\n",
    "**2. [Editing the extraction boxes](#editE)**\n",
    "\n",
    "\\- 2.1. [Defining an editing function](#edfnE)\n",
    "\n",
    "\\- 2.2. [Making the edits](#mkedE)\n",
    "\n",
    "\\- 2.3. [Confirming the changes](#confE)\n",
    "  \n",
    "\n",
    "**3. [Running the CalCOS Pipeline with the new `XTRACTAB`](#calexE)**\n",
    "\n",
    "\\- 3.1. [Editing the `XTRACTAB` header value](#edhdrE)\n",
    "\n",
    "\\- 3.2. [Running the pipeline](#runcE)\n",
    "\n",
    "\n",
    "**4. [Example using FUV Data](#fuvE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-syracuse",
   "metadata": {},
   "source": [
    "\n",
    "# 0. Introduction\n",
    "**The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope ([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).**\n",
    "\n",
    "**This tutorial aims to prepare you to work with the COS data of your choice by walking you through altering the extraction box sizes in the `XTRACTAB`/`_1dx` file to make sure you are extracting the cleanest possible signal from your source and background.** We will demonstrate this in both the NUV and FUV. \n",
    "\n",
    "*Note* that some COS modes which use the FUV detector can be better extracted using the [TWOZONE method](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-2-pipeline-processing-overview), which is not directly discussed in this Notebook. All COS/NUV modes use the [BOXCAR method](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-2-pipeline-processing-overview#id-3.2PipelineProcessingOverview-3.2.1OverviewofTWOZONEextraction) discussed in this Notebook.\n",
    "\n",
    "- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n",
    "- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-oliver",
   "metadata": {},
   "source": [
    "## We will import the following packages:\n",
    "\n",
    "- `numpy` to handle arrays and functions\n",
    "- `astropy.io fits` and `astropy.table Table` for accessing FITS files\n",
    "- `glob`, `os`, and `shutil` for working with system files\n",
    "- `astroquery.mast Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- `matplotlib.pyplot` for plotting\n",
    "- `matplotlib.image` for reading in images\n",
    "- `calcos` to run the CalCOS pipeline for COS data reduction\n",
    "- `scipy.interpolate interp1d` for interpolating datasets to the same sampling\n",
    "- `pathlib Path` for managing system paths\n",
    "\n",
    "New versions of `CalCOS` are currently incompatible with astroconda. To create a Python environment capable of running all the data analyses in these COS Notebooks, please see Section 1 of our Notebook tutorial on [setting up an environment](https://github.com/spacetelescope/hst_notebooks/blob/master/notebooks/COS/Setup/Setup.ipynb).\n",
    "\n",
    "We'll also filter out two unhelpful warnings about a deprecation and dividing by zero which do not affect our data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Import for reading FITS files\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "\n",
    "# Import for downloading the data\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# Import for plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import for showing images from within Python\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "# Import for dealing with system files\n",
    "import glob, os, shutil\n",
    "\n",
    "# Import for running the CalCOS pipeline\n",
    "import calcos\n",
    "\n",
    "# Import for comparing the old and new CalCOS values\n",
    "from scipy.interpolate import interp1d \n",
    "\n",
    "# Import for working with system paths\n",
    "from pathlib import Path\n",
    "\n",
    "# We will also suppress a warning that won't affect our data processing\n",
    "import warnings\n",
    "np.seterr(divide='ignore') \n",
    "warnings.filterwarnings('ignore',\n",
    "                        category=np.VisibleDeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-hypothesis",
   "metadata": {},
   "source": [
    "## We will also define a few directories we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be important directories for the notebook\n",
    "datadir = Path('./data/')\n",
    "outputdir = Path('./output/')\n",
    "plotsdir = Path('./output/plots/')\n",
    "\n",
    "# Make the directories if they don't exist\n",
    "datadir.mkdir(exist_ok=True)\n",
    "outputdir.mkdir(exist_ok=True)\n",
    "plotsdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-carry",
   "metadata": {},
   "source": [
    "## And we will need to download the data we wish to work with:\n",
    "We choose the exposures with the association obs_id: `LE4B04010` and download all the `_rawtag` data. This dataset happens to be COS/NUV data taken with the G185M grating, observing the star: [LS IV -13 30](https://simbad.u-strasbg.fr/simbad/sim-id?Ident=%402582869&Name=LS%20%20IV%20-13%20%20%2030&submit=submit).\n",
    "For more information on downloading COS data, see our [notebook tutorial on downloading COS data](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/DataDl/DataDl.ipynb).\n",
    "\n",
    "*Note*, we're working with the `_rawtags` because they are smaller files and quicker to download than the `_corrtag` files. However, this workflow translates very well to using `_corrtag` files, as you likely will want to do when working with your actual data. If you wish to use the default corrections converting from raw to corrected `TIME-TAG` data, you may instead download and work with `CORRTAG` files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying our exposures with the association observation ID LE4B04010\n",
    "productlist = Observations.get_product_list(Observations.query_criteria(\n",
    "                                                obs_id='LE4B04010'))\n",
    "\n",
    "# Getting only the RAWTAG, ASN, and X1DSUM files\n",
    "masked_productlist = productlist[np.isin(productlist['productSubGroupDescription'], ['RAWTAG', 'ASN', 'X1DSUM'])]\n",
    "\n",
    "# Now download the files\n",
    "Observations.download_products(masked_productlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-washington",
   "metadata": {},
   "source": [
    "We gather a list of all the `_rawtag` files we have downloaded, as well as the `_asnfile` and `_x1dsum` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a list of the RAWTAG, ASN, and X1DSUM files\n",
    "rawtags = glob.glob('./mastDownload/HST/**/*_rawtag.fits', \n",
    "                    recursive=True)\n",
    "\n",
    "asnfile = glob.glob('./mastDownload/HST/**/*_asn.fits', \n",
    "                    recursive=True)[0]\n",
    "\n",
    "old_x1dsum = glob.glob('./mastDownload/HST/**/*_x1dsum.fits', \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-valuable",
   "metadata": {},
   "source": [
    "<a id = invE></a>\n",
    "# 1. Investigating the exposure\n",
    "\n",
    "<a id = lookE></a>\n",
    "## 1.1. Understanding the `XTRACTAB` and examining a 2D spectrum\n",
    "The raw data from the COS instrument is a series of events, each corresponding to a photon interacting with the detector at a specific X, Y point, (*and at a specific time if in `TIME-TAG` mode*). We generally wish to translate this to a 1-dimensional spectrum (***Flux** or Intensity on the y axis vs. **Wavelength** on the x axis*). To do this, we can first make a 2-dimensional spectrum, by plotting all the X and Y points of the spectrum onto a 2D image of the detector. The different spectra (i.e. of the NUV of FUV target, the wavelength calibration source) then appear of stripes of high count density on this image. We can then simply draw extraction boxes around these stripes, and integrate to collapse the data onto the wavelenth axis.\n",
    "\n",
    "**The `XTRACTAB` is a FITS file which contains a series of parallelogram \"boxes\" to be used for different COS modes.**\n",
    "\n",
    "These are the boxes which we collapse to create a 1-dimensional spectrum. For each combination of COS lifetime position, grating, cenwave, etc., the extraction box is specified by giving the slope and y-intercept of a line, and the height of the parallelogram which should be centered on the line. Similar boxes are specified for background regions. For more information on the `XTRACTAB`, see the [COS Data Handbook](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-7-reference-files#id-3.7ReferenceFiles-3.7.12XTRACTAB:1-DSpectralExtractionTablehttps://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-7-reference-files#id-3.7ReferenceFiles-3.7.12XTRACTAB:1-DSpectralExtractionTable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-gallery",
   "metadata": {},
   "source": [
    "**For many reasons, we may wish to use an extraction box different from the one specified by the default XTRACTAB, and instead set the boxes manually.**\n",
    "\n",
    "We need to see where the NUV stripes fall in order to determine where we should place the extraction boxes. First, let's plot this as a 2D image of the raw counts.\n",
    "To begin, we select and plot the raw counts data from the 0th rawtag file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the first rawtag\n",
    "rawtag = rawtags[0]\n",
    "rt_data = Table.read(rawtag, 1)\n",
    "\n",
    "# Setting up the figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot the raw counts\n",
    "plt.scatter(rt_data['RAWX'], rt_data['RAWY'], \n",
    "            # Size of data points\n",
    "            s=0.1, \n",
    "            # Transparency of data points\n",
    "            alpha=0.1, \n",
    "            # Color of data points\n",
    "            c='C0')\n",
    "\n",
    "# Plot lines roughly centered on the three NUV stripes (units are pixels)\n",
    "line = [187, 285, 422]\n",
    "label = ['NUVA', 'NUVB', 'NUVC']\n",
    "\n",
    "for i in range(3): \n",
    "    plt.axhline(line[i], \n",
    "                color='myr'[i],\n",
    "                linewidth=3, \n",
    "                alpha=0.8, \n",
    "                linestyle='dotted', \n",
    "                label=label[i])\n",
    "\n",
    "# Setting plot axis limits\n",
    "plt.xlim(0, 1024)\n",
    "plt.ylim(0, 1024)\n",
    "\n",
    "# Adding labels to axes and plot\n",
    "plt.xlabel('Dispersion axis Pixel', \n",
    "           size=20)\n",
    "plt.ylabel('Cross-dispersion axis Pixel', \n",
    "           size=20)\n",
    "plt.title(\"Fig 1.1\\n2D spectrum of all raw (unfiltered) counts\", \n",
    "          size=25)\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Working with plot formatting\n",
    "plt.tight_layout()\n",
    "\n",
    "# Showing the plot below\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-diploma",
   "metadata": {},
   "source": [
    "**The dense stripes in the lower half of Fig 1.1 (*highlighted by the dotted lines*) are the actual science data raw counts, while the *patched* stripes towards the top of the plot are the wavelength calibration counts.** For a diagram of a NUV 2D spectrum, see COS Data Handbook [Figure 1.10](https://hst-docs.stsci.edu/cosdhb/chapter-1-cos-overview/1-2-cos-physical-configuration#id-1.2COSPhysicalConfiguration-Figure1.10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-madrid",
   "metadata": {},
   "source": [
    "Now we'll need to see where the original `XTRACTAB` places its extraction boxes:\n",
    "\n",
    "Find the name of the `XTRACTAB` used by this first `_rawtag` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_xtractab = fits.getheader(rawtag)['XTRACTAB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-jersey",
   "metadata": {},
   "source": [
    "**If you have an existing `lref` directory with a cache of reference files:**\n",
    "Give the system the `lref` system variable, which points to the reference file directory, uncomment the cell below (lines beginning with `###`). If you do NOT have an existing `lref variable`, DO NOT run the following cell. We will setup the reference files used in this notebook in the cell after this one. The path to your `lref` file should be printed below after you run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment \"###\" and run if you have an existing lref:\n",
    "\n",
    "###lref = \"YOUR_EXISTING_LREF_PATH\"\n",
    "###%env lref YOUR_EXISTING_LREF_PATH\n",
    "\n",
    "###orig_xtractab = lref + orig_xtractab.split('$')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-elements",
   "metadata": {},
   "source": [
    "**If you DO NOT have an existing `lref` directory with a cache of reference files:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-editor",
   "metadata": {},
   "source": [
    "If you do not have a local copy of the reference files, (i.e. an `lref` directory,) you may, for the purposes of this Notebook, download just the `XTRACTAB` using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment \"###\" and run if you DO NOT have an existing lref directory:\n",
    "\n",
    "###%env CRDS_PATH ./data\n",
    "###%env CRDS_SERVER_URL https://hst-crds.stsci.edu\n",
    "###%env lref ./data/references/hst/cos/\n",
    "###lref = './data/references/hst/cos/'\n",
    "###! crds sync --files=w5g1439sl_1dx.fits\n",
    "\n",
    "###orig_xtractab = lref + orig_xtractab.split('$')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-programming",
   "metadata": {},
   "source": [
    "\n",
    "<a id = funE></a>\n",
    "## 1.2. Defining some useful functions\n",
    "\n",
    "We'll define a few functions to:\n",
    "- Read in the data rows containing relevant extraction boxes from an `XTRACTAB` file\n",
    "- Plot these extraction boxes over a spectrum \n",
    "  + *For clarity and signal to noise, we'll collapse this spectrum onto the y (cross-dispersion) axis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-morris",
   "metadata": {},
   "source": [
    "**First, we'll write a function to read in the relavent extraction boxes from an `XTRACTAB`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readxtractab(xtractab, grat, cw, aper):\n",
    "    \"\"\"\n",
    "    Reads in an XTRACTAB row of a particular COS mode and\n",
    "    returns extraction box sizes and locations.\n",
    "\n",
    "    Inputs:\n",
    "    xtractab (str) : path to XTRACTAB file.\n",
    "    raw (bool) : default False, meaning that the data is assumed to be corrtag.\n",
    "    grat (string) : grating of relavent row (i.e. \"G185M\")\n",
    "    cw (int or numerical) : cenwave of relavent row (i.e. (1786))\n",
    "    aper (str) : aperture of relavent row (i.e. \"PSA\")\n",
    "\n",
    "    Returns:\n",
    "    y locations of bottoms/tops of extraction boxes\n",
    "        if NUV: stripe NUVA/B/C, and 2 background boxes\n",
    "        elif FUV: FUVA/B, and 2 background boxes for each FUVA/B.\n",
    "    \"\"\"\n",
    "    # Read the XTRACTAB FITS data\n",
    "    with fits.open(xtractab) as f:\n",
    "        xtrdata = f[1].data \n",
    "    \n",
    "    # Check if the detector is the FUV or NUV detector\n",
    "    isFUV = fits.getheader(xtractab)['DETECTOR'] == 'FUV'\n",
    "    \n",
    "    # If it's the NUV detector, then:\n",
    "    if not isFUV:\n",
    "        # Find NUVA of the right row\n",
    "        sel_nuva = np.where((xtrdata['segment'] == 'NUVA') & \n",
    "                            (xtrdata['aperture'] == aper) & \n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "        \n",
    "        # Now NUVB\n",
    "        sel_nuvb = np.where((xtrdata['segment'] == 'NUVB') & \n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "        \n",
    "        # Now NUVC\n",
    "        sel_nuvc = np.where((xtrdata['segment'] == 'NUVC') & \n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        # Find heights of the spec extract boxes\n",
    "        hgta = xtrdata['HEIGHT'][sel_nuva][0] \n",
    "        hgtb = xtrdata['HEIGHT'][sel_nuvb][0] \n",
    "        hgtc = xtrdata['HEIGHT'][sel_nuvc][0]\n",
    "\n",
    "        # Get the y-intercept (b) of the spec\n",
    "        bspeca = xtrdata['B_SPEC'][sel_nuva][0] \n",
    "        bspecb = xtrdata['B_SPEC'][sel_nuvb][0] \n",
    "        bspecc = xtrdata['B_SPEC'][sel_nuvc][0]\n",
    "\n",
    "        # Determine the y bounds of boxes \n",
    "        boundsa = [bspeca - hgta/2, bspeca + hgta/2] \n",
    "        boundsb = [bspecb - hgtb/2, bspecb + hgtb/2]\n",
    "        boundsc = [bspecc - hgtc/2, bspecc + hgtc/2]\n",
    "\n",
    "        # Do the same for the bkg extract boxes\n",
    "        bkg1a = xtrdata['B_BKG1'][sel_nuva] \n",
    "        bkg2a = xtrdata['B_BKG2'][sel_nuva]\n",
    "        bhgta = xtrdata['BHEIGHT'][sel_nuva]\n",
    "\n",
    "        bkg1boundsa = [bkg1a - bhgta/2, bkg1a + bhgta/2]\n",
    "        bkg2boundsa = [bkg2a - bhgta/2, bkg2a + bhgta/2]\n",
    "\n",
    "        # The background locations are by default the same for all stripes\n",
    "        return boundsa, boundsb, boundsc, bkg1boundsa, bkg2boundsa\n",
    "    \n",
    "    # If it's the FUV detector, then:\n",
    "    elif isFUV: \n",
    "        # Find FUVA of the right row\n",
    "        sel_fuva = np.where((xtrdata['segment'] == 'FUVA') & \n",
    "                            (xtrdata['aperture'] == aper) &  \n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        # Now FUVB\n",
    "        sel_fuvb = np.where((xtrdata['segment'] == 'FUVB') & \n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "        \n",
    "        # Find heights of the spec extract boxes\n",
    "        hgta = xtrdata['HEIGHT'][sel_fuva][0] \n",
    "        hgtb = xtrdata['HEIGHT'][sel_fuvb][0] \n",
    "\n",
    "        # Get the y-intercept (b) of the spec boxes\n",
    "        bspeca = xtrdata['B_SPEC'][sel_fuva][0] \n",
    "        bspecb = xtrdata['B_SPEC'][sel_fuvb][0] \n",
    "\n",
    "        # Determine the y bounds of the boxes \n",
    "        boundsa = [bspeca - hgta/2, bspeca + hgta/2] \n",
    "        boundsb = [bspecb - hgtb/2, bspecb + hgtb/2]\n",
    "\n",
    "        # Do the same for the bkg extract boxes\n",
    "        bkg1a = xtrdata['B_BKG1'][sel_fuva] \n",
    "        bkg2a = xtrdata['B_BKG2'][sel_fuva]\n",
    "        bhgt1a = xtrdata['B_HGT1'][sel_fuva]\n",
    "        bhgt2a = xtrdata['B_HGT2'][sel_fuva]\n",
    "\n",
    "        # Determine the y bounds of the bkg extract boxes\n",
    "        bkg1boundsa = [bkg1a - bhgt1a/2, bkg1a + bhgt1a/2]\n",
    "        bkg2boundsa = [bkg2a - bhgt2a/2, bkg2a + bhgt2a/2]\n",
    "        \n",
    "        bkg1b = xtrdata['B_BKG1'][sel_fuvb]\n",
    "        bkg2b = xtrdata['B_BKG2'][sel_fuvb]\n",
    "        bhgt1b = xtrdata['B_HGT1'][sel_fuvb]\n",
    "        bhgt2b = xtrdata['B_HGT2'][sel_fuvb]\n",
    "\n",
    "        bkg1boundsb = [bkg1b - bhgt1b/2, bkg1b + bhgt1b/2]\n",
    "        bkg2boundsb = [bkg2b - bhgt2b/2, bkg2b + bhgt2b/2]\n",
    "\n",
    "        return boundsa, boundsb, bkg1boundsa, bkg2boundsa, bkg1boundsb, bkg2boundsb\n",
    "\n",
    "# We'll note the returned values correspond to these extraction boxes\n",
    "box_names = ['NUVA', 'NUVB', 'NUVC', 'BKG-1', 'BKG-2']\n",
    "box_names_fuv = ['FUVA', 'FUVB', 'BKG-1A', 'BKG-2A', 'BKG-1B', 'BKG-2B']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-october",
   "metadata": {},
   "source": [
    "**We'll now need two functions in order to plot.**\n",
    "\n",
    "The first function: `makeims()` is a helper function for the second: `collapsey()`.\n",
    "\n",
    "The second function: `collapsey()` takes a list of either `_rawtag` or `_corrtag` exposure files, as well as an `XTRACTAB` file, and creates a summary plot, with the 2D spectrum collapsed onto the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeims(xarr, yarr):\n",
    "    \"\"\"\n",
    "    Helper function for collapsey(): converts list of counts to image.\n",
    "    \"\"\"\n",
    "    # Size of the new image we will create\n",
    "    new_img = np.zeros((1024, 1024))\n",
    " \n",
    "    xbin = np.asarray(np.floor((xarr + 0.5)), \n",
    "                      dtype=int)\n",
    "    ybin = np.asarray(np.floor((yarr + 0.5)), \n",
    "                      dtype=int)\n",
    "\n",
    "    # Add a count for each x, y pair\n",
    "    for x, y in zip(xbin, ybin):\n",
    "        try:\n",
    "            new_img[y, x] += 1\n",
    "\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-going",
   "metadata": {},
   "source": [
    "**Define the \"collapse on y axis\" function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapsey() assumes corrtag, but will work with rawtag if raw=True\n",
    "def collapsey(tagfiles, xtractab, raw=False, save=True, savename=False, display=True, fignum=False):\n",
    "    \"\"\"\n",
    "    Takes a corrtag (default) or RAWTAG and makes a plot of the 2D spectrum collapsed to the y axis\n",
    "    i.e. summed over rows of pixels along the dispersion direction\n",
    "    then it overplots the extraction regions from a provided XTRACTAB.\n",
    "    The behavior is the same for CORRTAG/RAWTAG, only the data columns differ.\n",
    "    \n",
    "    Inputs:\n",
    "    tagfiles (list of str) : List of RAWTAG or CORRTAG file paths.\n",
    "    xtractab (str) : Path to XTRACTAB.\n",
    "    raw (bool) : Default False, meaning that the data is assumed to be CORRTAG.\n",
    "    save (bool) : Do you want to save the image of the plot? Default True\n",
    "    savename (str if specified) : Name to save file as in plotsdir, if save == True.\n",
    "    display (bool) : Display the image? Default True.\n",
    "    fignum  (str if specified) : Figure number to include in figtitle. Dafault is False.\n",
    "    \n",
    "    Outputs:\n",
    "    yprof (numpy array of floats) : the 2D spectrum collapsed onto the y axis.\n",
    "    \"\"\"\n",
    "    # Setting up the figure\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Go through all the tag files\n",
    "    for numfile, myfile in enumerate(tagfiles): \n",
    "        # Read data from the file\n",
    "        with fits.open(myfile) as f: \n",
    "            data = f[1].data\n",
    "            h0 = f[0].header\n",
    "\n",
    "        # Find important header keys to determine row\n",
    "        fppos = h0['FPPOS'] \n",
    "        rootname = h0['ROOTNAME']\n",
    "        target = h0['TARGNAME']\n",
    "        grating = h0['OPT_ELEM']\n",
    "        cenwave = h0['CENWAVE']\n",
    "        \n",
    "        # Select corrected or raw time-tag points x and y locations\n",
    "        if not raw: \n",
    "            xcorr = data['XCORR']\n",
    "            ycorr = data['YCORR']\n",
    "\n",
    "        elif raw:\n",
    "            rawx = data['RAWX']\n",
    "            rawy = data['RAWY']\n",
    "        \n",
    "        # Call the helper function on timetag data\n",
    "        if raw: \n",
    "            nuvim = makeims(rawx, rawy)\n",
    "        else:\n",
    "            nuvim = makeims(xcorr, ycorr)\n",
    "\n",
    "        # Collapse onto the y axis\n",
    "        yprof = np.sum(nuvim, \n",
    "                       axis=1) \n",
    "\n",
    "        # Make the main y-axis spectrum plot\n",
    "        yaxis = np.arange(0, 1024)\n",
    "\n",
    "        # Plot the newly collapsed spectrum plot\n",
    "        plt.plot(yprof, yaxis, \n",
    "                 label=f'{rootname} fppos={fppos}')\n",
    "\n",
    "        # Add in the plot formatting/titles\n",
    "        if numfile == 0: \n",
    "            if raw:\n",
    "                plt.ylabel('RAWY Pixel', \n",
    "                           size=18)\n",
    "            else:\n",
    "                plt.ylabel('YCORR Pixel', \n",
    "                           size=18)\n",
    "\n",
    "            plt.xlabel('Counts summed along X', \n",
    "                       size=18)\n",
    "            \n",
    "            fig_title = f\"Target: {target} spectrum;\" +\"\\n\"+f\"XTRACTAB: {os.path.basename(xtractab)}\"\n",
    "\n",
    "            if fignum:\n",
    "                fig_title = f\"Fig {fignum}\" + \"\\n\" + fig_title\n",
    "\n",
    "            plt.title(fig_title, \n",
    "                      fontsize=23)\n",
    "\n",
    "            # Get the extraction box sizes and locations for the science and wavecal apertures\n",
    "            psaboundsa, psaboundsb, psaboundsc, psabkg1, psabkg2 = readxtractab(xtractab, grating, cenwave, 'PSA')\n",
    "            wcaboundsa, wcaboundsb, wcaboundsc, wcabkg1, wcabkg2 = readxtractab(xtractab, grating, cenwave, 'WCA')\n",
    "\n",
    "            # Adding shading to show the PSA/WCA regions on the image\n",
    "            plt.axhspan(psaboundsa[0], psaboundsa[1],\n",
    "                        # Color of shaded region\n",
    "                        color='m', \n",
    "                        # Label\n",
    "                        label='PSA Regions', \n",
    "                        # Transparency\n",
    "                        alpha=0.15)\n",
    "            \n",
    "            plt.axhspan(psaboundsb[0], psaboundsb[1], \n",
    "                        color='m', \n",
    "                        alpha=0.15)\n",
    "            \n",
    "            plt.axhspan(psaboundsc[0], psaboundsc[1], \n",
    "                        color='m', \n",
    "                        alpha=0.15)\n",
    "\n",
    "            plt.axhspan(wcaboundsa[0], wcaboundsa[1],\n",
    "                        color='blue', \n",
    "                        label='WCA regions', \n",
    "                        alpha=0.15)\n",
    "\n",
    "            plt.axhspan(wcaboundsb[0], wcaboundsb[1], \n",
    "                        color='blue', \n",
    "                        alpha=0.15)\n",
    "\n",
    "            plt.axhspan(wcaboundsc[0], wcaboundsc[1], \n",
    "                        color='blue', \n",
    "                        alpha=0.15)\n",
    "    \n",
    "    # Add a legend\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    # More formatting\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Saving the figure\n",
    "    if save:\n",
    "        # Save in the default manner\n",
    "        if not savename: \n",
    "            plt.savefig(str(plotsdir / f\"{target}_regions.png\"), \n",
    "                        dpi=200, \n",
    "                        bbox_inches='tight')\n",
    "\n",
    "        # Save with input savename\n",
    "        elif savename: \n",
    "            plt.savefig(str(plotsdir / f\"{savename}.png\"), \n",
    "                        dpi=200, \n",
    "                        bbox_inches='tight')\n",
    "            \n",
    "    # If specified, show the image\n",
    "    if display:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    return yprof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-birthday",
   "metadata": {},
   "source": [
    "<a id = boxE></a>\n",
    "## 1.3. Examining the extraction boxes\n",
    "\n",
    "Now let's make a plot showing where these original `XTRACTAB` boxes fall on the raw count image:\n",
    "\n",
    "*It's important to note that each extraction box also has a slope associated with it.* This slope is generally very small, and we will not plot the boxes with their slopes while determining the box centers and heights. However, for the purposes of actual extractions, these slopes should be incorporated to determine final extraction bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds of all boxes for these conditions\n",
    "read_bounds = readxtractab(orig_xtractab, \n",
    "                           grat='G185M', \n",
    "                           cw=1786, \n",
    "                           aper='PSA') \n",
    "\n",
    "# Set up figure\n",
    "plt.figure(figsize=(10, 8)) \n",
    "\n",
    "# Image of the raw counts\n",
    "plt.scatter(rt_data['RAWX'], rt_data['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0')\n",
    "\n",
    "# Add all boxes\n",
    "for i in range(3):\n",
    "    plt.axhspan(read_bounds[i][0], read_bounds[i][1],\n",
    "                color=\"myr\"[i],\n",
    "                alpha=0.3,\n",
    "                label=box_names[i])\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend(loc='upper right') \n",
    "\n",
    "# Add x and y axis ranges\n",
    "plt.xlim(0, 1024)\n",
    "plt.ylim(0, 1024)\n",
    "\n",
    "# Add labels and titles\n",
    "plt.xlabel('Dispersion axis Pixel', \n",
    "           size=20)\n",
    "plt.ylabel('Cross-dispersion axis Pixel', \n",
    "           size=20)\n",
    "plt.suptitle(\"Fig 1.2\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original extraction boxes\", \n",
    "             size=25)\n",
    "\n",
    "# Work with formatting\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure to our plots directory\n",
    "plt.savefig(str(plotsdir / '2D_spec_orig_boxes.png'), \n",
    "            dpi=200, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to plot the original boxes over the y-axis spectrum\n",
    "flat_yspec = collapsey(tagfiles=rawtags, \n",
    "                       xtractab=orig_xtractab, \n",
    "                       raw=True,\n",
    "                       save=True, \n",
    "                       savename=\"orig_xtractab_col_y\", \n",
    "                       fignum=\"1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-boxing",
   "metadata": {},
   "source": [
    "<a id = editE></a>\n",
    "# 2. Editing the extraction boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-millennium",
   "metadata": {},
   "source": [
    "Now that we know how to show the location of the extraction boxes, we can begin actually editing the `XTRACTAB` file.\n",
    "\n",
    "We'll define another function to edit the existing `XTRACTAB` and save to a new file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-alaska",
   "metadata": {},
   "source": [
    "<a id = edfnE></a>\n",
    "## 2.1. Defining an editing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_xtractab(xtractab, gratlist, cwlist, h_dict, b_dict, new_filename):\n",
    "    \"\"\"\n",
    "    Function to actually edit the XTRACTAB itself.\n",
    "    Change the height and y-intercepts of the extraction boxes,\n",
    "    and save to new XTRACTAB (1dx) file.\n",
    "\n",
    "    Inputs:\n",
    "    xtractab (str) : path to the XTRACTAB to edit\n",
    "    gratlist (list of str) : all the gratings whose rows you would like to edit\n",
    "    cwlist (list of str) : all the cenwave whose rows you would like to edit\n",
    "    h_dict (dict of numerical) : heights of NUV A,B,C extraction boxes. Should be ODD!\n",
    "    b_dict (dict) : dict of the y-intercepts - i.e. box center locations\n",
    "    new_filename : filename/local path to new XTRACTAB file to create\n",
    "    \"\"\"\n",
    "    # Opening the XTRACTAB file and getting its data\n",
    "    f = fits.open(xtractab)\n",
    "    xtrdata = f[1].data\n",
    "\n",
    "    # Is it FUV or NUV?\n",
    "    isFUV = fits.getheader(xtractab)['DETECTOR'] == 'FUV'\n",
    "    \n",
    "    # Print warning if even height is specified\n",
    "    for height in h_dict: \n",
    "        if h_dict[height] % 2 == 0:\n",
    "            print(\"WARNING \" + f\"Height of {height} is currently even ({h_dict[height]}), but \" +\n",
    "                  \"should be ODD. Allowed change, but unadvised.\")\n",
    "    \n",
    "    # Going through all gratings that you wish to edit\n",
    "    for grat in gratlist:\n",
    "        # Going through all cenwaves that you wish to edit\n",
    "        for cw in cwlist:\n",
    "            # For NUV data, changing all three gratings and cenwaves\n",
    "            if not isFUV: \n",
    "\n",
    "                sel_nuva = np.where((xtrdata['segment'] == 'NUVA') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_nuvb = np.where((xtrdata['segment'] == 'NUVB') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_nuvc = np.where((xtrdata['segment'] == 'NUVC') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                # Change the background region locations:\n",
    "                xtrdata['B_BKG1'][sel_nuva] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuva] = b_dict['bbkg2']\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuvb] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuvb] = b_dict['bbkg2']\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuvc] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuvc] = b_dict['bbkg2']\n",
    "\n",
    "                # Change the extraction heights\n",
    "                xtrdata['HEIGHT'][sel_nuva] = h_dict['h_a']\n",
    "                xtrdata['HEIGHT'][sel_nuvb] = h_dict['h_b']\n",
    "                xtrdata['HEIGHT'][sel_nuvc] = h_dict['h_c']\n",
    "\n",
    "                # Change the B_SPEC\n",
    "                xtrdata['B_SPEC'][sel_nuva] = b_dict['bspa']\n",
    "                xtrdata['B_SPEC'][sel_nuvb] = b_dict['bspb']\n",
    "                xtrdata['B_SPEC'][sel_nuvc] = b_dict['bspc']\n",
    "                \n",
    "                \n",
    "            # For FUV data\n",
    "            elif isFUV: \n",
    "                sel_fuva = np.where((xtrdata['segment'] == 'FUVA') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_fuvb = np.where((xtrdata['segment'] == 'FUVB') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "                \n",
    "                # Change the background region locations:\n",
    "                xtrdata['B_BKG1'][sel_fuva] = b_dict['bbkg1a']\n",
    "                xtrdata['B_BKG2'][sel_fuva] = b_dict['bbkg2a']\n",
    "                \n",
    "                xtrdata['B_BKG1'][sel_fuvb] = b_dict['bbkg1b']\n",
    "                xtrdata['B_BKG2'][sel_fuvb] = b_dict['bbkg2b']\n",
    "                # Change the extraction heights\n",
    "                xtrdata['HEIGHT'][sel_fuva] = h_dict['h_a']\n",
    "                xtrdata['HEIGHT'][sel_fuvb] = h_dict['h_b']\n",
    "                # Change the B_SPEC\n",
    "                xtrdata['B_SPEC'][sel_fuva] = b_dict['bspa']\n",
    "                xtrdata['B_SPEC'][sel_fuvb] = b_dict['bspb']\n",
    "                \n",
    "    # Save and close the file\n",
    "    f.writeto(new_filename, \n",
    "              overwrite=True)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-touch",
   "metadata": {},
   "source": [
    "<a id = mkedE></a>\n",
    "## 2.2. Making the edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-opportunity",
   "metadata": {},
   "source": [
    "Now we'll edit the `XTRACTAB` file to have different sizes and locations of the extraction boxes using `edit_xtractab()`.\n",
    "\n",
    "For the purposes of this example, we'll **arbitrarily** set our y-intercepts and heights, just trying to roughly cover the NUV stripes, and show the different heights we can set the boxes to. *Note* that this function does not stop us from setting the boxes to overlap - but, dependent on your data, this may be a bad idea. \n",
    "\n",
    "The scope of this Notebook is merely to explain *how* to alter the extraction boxes, not to determine the best box locations for any given dataset. While we cannot give specific rules to fit every single dataset, the general rules suggest you: \n",
    "\n",
    "* Define spectral extraction boxes which contain as much flux from the target as possible while including very little of the background region.\n",
    "\n",
    "* Define background extraction boxes as close to your target as possible without the possibility of overlap.\n",
    "\n",
    "* Avoid detector hotspots and regions of poor sensitivity.\n",
    "\n",
    "* Box heights should be odd, so that there is a central pixel.\n",
    "\n",
    "First we'll set up the values to which we'll edit the box parameters, and then run the function on the original XTRACTAB to change our G185M extraction boxes in the rows for cenwaves 1786 and 1817:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values we set the box params to:\n",
    "# Centers of the background extract regions\n",
    "intercept_dict = {\"bbkg1\":900., \"bbkg2\":60., \n",
    "                  # Centers of NUV stripe extract regions\n",
    "                  'bspa':195., 'bspb':285., 'bspc':415.} \n",
    "\n",
    "hgt_dict = {'h_a':41, 'h_b':51, 'h_c':61}\n",
    "\n",
    "# Now edit using the edit_xtractab() function;\n",
    "# We'll change G185M grating for cenwaves 1786, 1817:\n",
    "edit_xtractab(xtractab=orig_xtractab, \n",
    "              # We're changing the G185M grating\n",
    "              gratlist=['G185M'], \n",
    "              # We're changing the 1786 and 1817 cenwaves for this grating\n",
    "              cwlist=[1786, 1817], \n",
    "              # New (arbitrary) heights to set boxes to\n",
    "              h_dict=hgt_dict, \n",
    "              # New y-intercepts for boxes\n",
    "              b_dict=intercept_dict, \n",
    "              new_filename='./edit_1dx.fits') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-oliver",
   "metadata": {},
   "source": [
    "<a id = confE></a>\n",
    "## 2.3. Confirming the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-correction",
   "metadata": {},
   "source": [
    "**Now we plot the old and new extraction boxes side-by-side to compare:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot, we're going to have 2 subplots\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, \n",
    "                              figsize=(14, 8), \n",
    "                              sharey=True)\n",
    "\n",
    "# Add raw count images to both subplots\n",
    "ax0.scatter(rt_data['RAWX'], rt_data['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0')\n",
    "\n",
    "ax1.scatter(rt_data['RAWX'], rt_data['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0')\n",
    "\n",
    "# First plot the boxes from the original XTRACTAB \n",
    "read_bounds_old = readxtractab(orig_xtractab, \n",
    "                           grat='G185M', \n",
    "                           cw=1786, \n",
    "                           aper='PSA')\n",
    "\n",
    "for i in range(3):\n",
    "    ax0.axhspan(read_bounds_old[i][0], read_bounds_old[i][1],\n",
    "                color=\"myr\"[i],\n",
    "                alpha=0.3,\n",
    "                label=box_names[i]+\"_old\")\n",
    "\n",
    "# Hatches will help differentiate between the old and new boxes\n",
    "plt.rcParams['hatch.linewidth'] = 1\n",
    "\n",
    "# Now with the newly edited XTRACTAB\n",
    "read_bounds_new = readxtractab('./edit_1dx.fits', \n",
    "                           grat='G185M', \n",
    "                           cw=1786, \n",
    "                           aper='PSA')\n",
    "  \n",
    "for i in range(3):\n",
    "    ax1.axhspan(read_bounds_new[i][0], read_bounds_new[i][1],\n",
    "                color=\"myr\"[i],\n",
    "                alpha=0.3,\n",
    "                # Specifying the hatch\n",
    "                hatch=\"x*\",\n",
    "                label=box_names[i]+\"_new\")\n",
    "\n",
    "# Now some plot formatting\n",
    "ax0.legend(loc='upper right')\n",
    "ax1.legend(loc='upper right')\n",
    "\n",
    "ax0.set_xlim(0, 1024)\n",
    "ax0.set_ylim(0, 1024)\n",
    "ax1.set_xlim(ax0.get_xlim())\n",
    "\n",
    "fig.text(0.42, -0.01,\n",
    "         'Dispersion axis Pixel', \n",
    "         size=20)\n",
    "ax0.set_ylabel('Cross-dispersion axis Pixel', \n",
    "               size=20)\n",
    "plt.suptitle(\"Fig 2.1\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original ($left$) and new ($right$) extraction boxes\", \n",
    "             size=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(str(plotsdir / '2D_spec_both_box_sets.png'), \n",
    "            dpi=200, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-debut",
   "metadata": {},
   "source": [
    "**We'll also make a plot of the new boxes over the spectrum collapsed onto the y-axis, and we'll plot it side-by-side with Fig 1.3, which shows the original extraction boxes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to plot the original boxes over the y-axis spectrum\n",
    "flat_yspec = collapsey(tagfiles=rawtags, \n",
    "                       xtractab='./edit_1dx.fits', \n",
    "                       raw=True,\n",
    "                       save=True, \n",
    "                       display=False, \n",
    "                       savename=\"edit_xtractab_col_y\", \n",
    "                       fignum=\"2.2\")\n",
    "\n",
    "# Now plot both together\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2,\n",
    "                              figsize =(25, 18))\n",
    "\n",
    "ax0.imshow(mpimg.imread('./output/plots/orig_xtractab_col_y.png'))\n",
    "ax1.imshow(mpimg.imread('./output/plots/edit_xtractab_col_y.png'))\n",
    "\n",
    "ax0.axis('off')\n",
    "ax1.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-ontario",
   "metadata": {},
   "source": [
    "<a id = calexE></a>\n",
    "# 3. Running the CalCOS Pipeline with the new `XTRACTAB`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-channel",
   "metadata": {},
   "source": [
    "<a id = edhdrE></a>\n",
    "## 3.1. Editing the `XTRACTAB` header value\n",
    "More detailed information on changing header parameters can be found in our [walkthrough Notebook on `CalCOS`](https://github.com/spacetelescope/hst_notebooks/blob/master/notebooks/COS/CalCOS/CalCOS.ipynb).\n",
    "\n",
    "Here, we just need to tell the pipeline to use our newly edited `XTRACTAB`. We do this by editing one of the header key values in all of the affected files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for rawtag in rawtags:\n",
    "        os.rename(rawtag, datadir / os.path.basename(rawtag))\n",
    "except FileNotFoundError:\n",
    "    print ('No files')\n",
    "\n",
    "try: \n",
    "    os.rename(asnfile, datadir / os.path.basename(asnfile))\n",
    "except FileNotFoundError:\n",
    "    print ('No files')\n",
    "    \n",
    "rawtags = glob.glob(str(datadir / '*rawtag*'))\n",
    "asnfile = glob.glob(str(datadir / '*asn*'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rawtag in rawtags:\n",
    "    print(\"changing XTRACTAB for \", os.path.basename(rawtag))\n",
    "    print(\"\\tOriginally: \", fits.getheader(rawtag)['XTRACTAB'])\n",
    "\n",
    "    fits.setval(filename=rawtag, \n",
    "                keyword='XTRACTAB', \n",
    "                value='./edit_1dx.fits' )\n",
    "    \n",
    "    print(\"\\tNow set to: \", fits.getheader(rawtag)['XTRACTAB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-counter",
   "metadata": {},
   "source": [
    "<a id = runcE></a>\n",
    "## 3.2. Running the pipeline\n",
    "We will also largely gloss over the details of running the pipeline, `CalCOS`, in this Notebook. Once again, much more detailed information on running the `CalCOS` pipeline can be found in our [walkthrough Notebook on using `CalCOS`](https://github.com/spacetelescope/hst_notebooks/blob/master/notebooks/COS/CalCOS/CalCOS.ipynb).\n",
    "\n",
    "**If you don't have an `lref` directory with all your COS reference files, the following cells will fail to run** and you should see our tutorial on [Setting up an environment to work with COS data](https://github.com/spacetelescope/hst_notebooks/blob/master/hst_notebooks/COS/Setup/Setup.ipynb).\n",
    "\n",
    "Note too that if you've already run calcos in this cell, it will fail to run again unless you clear the directory that the products are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr \n",
    "# Above ^ capture the output and save it in the next cell\n",
    "\n",
    "# This line actually runs the pipeline:\n",
    "calcos.calcos(asnfile, \n",
    "              verbosity=1, \n",
    "              outdir=str(outputdir / \"calcos_run1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6b174",
   "metadata": {},
   "source": [
    "This file now contains the output of the last cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(outputdir/'output_calcos_1.txt'), 'w') as f: \n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-freight",
   "metadata": {},
   "source": [
    "**We'll finish up by plotting the new and original `x1dsum` spectra as extracted with the new and original extraction boxes:**\n",
    "\n",
    "*Note* that we can ignore the UnitsWarning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure:\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "# Using gridspec to control panel sizes and locations\n",
    "gs = fig.add_gridspec(nrows=5, \n",
    "                      ncols=3) \n",
    "\n",
    "# Going through each NUV stripe\n",
    "for i in range(3):\n",
    "    # Creating two subplots, one with the X1DSUM data and the other a residual plot\n",
    "    ax0 = fig.add_subplot(gs[0:4, i])\n",
    "    ax1 = fig.add_subplot(gs[4:5, i])\n",
    "\n",
    "    # Getting the newly created (edited) X1DSUM's data\n",
    "    new_wvln, new_flux = Table.read('./output/calcos_run1/le4b04010_x1dsum.fits')[i]['WAVELENGTH', 'FLUX']\n",
    "    # Getting the old X1DSUM's data\n",
    "    old_wvln, old_flux, seg = Table.read(old_x1dsum)[i]['WAVELENGTH', 'FLUX', 'SEGMENT']\n",
    "    \n",
    "    # Interpolate the new wvln onto the old wvln's sampling:\n",
    "    new_flux_interp = interp1d(x=new_wvln, y=new_flux, \n",
    "                               fill_value=\"extrapolate\")(old_wvln)\n",
    "\n",
    "    # Print max difference to user:\n",
    "    print(f\"Stripe {seg} differs by up to: \\\n",
    "    {100 * max(new_flux - old_flux)/np.mean(abs(old_flux)):.3f}%\")\n",
    "\n",
    "    # Plotting upper panel\n",
    "    ax0.plot(new_wvln, new_flux, \n",
    "             linewidth=0.5, \n",
    "             label='$New$ extracted spectrum')\n",
    "    ax0.plot(old_wvln, old_flux, \n",
    "             linewidth=0.5, \n",
    "             label='$Original$ extracted spectrum')\n",
    "\n",
    "    # Plotting lower panel\n",
    "    ax1.plot(new_wvln,old_flux - new_flux_interp, \n",
    "             linewidth=0.5, \n",
    "             label='Residual')\n",
    "\n",
    "    # Formatting:\n",
    "    ax0.set_title(f\"Segment {seg}\", \n",
    "                  fontsize=20)\n",
    "\n",
    "    ax0.set_xticks([])\n",
    "\n",
    "    # Adding a legend\n",
    "    ax0.legend(loc='lower center')\n",
    "    ax1.legend(loc='lower center')\n",
    "\n",
    "    # Add axis labels to the plot\n",
    "    if i == 0: \n",
    "        ax0.set_ylabel(\"Flux\\n[$erg\\ \\AA^{-1}\\ cm^{-2}\\ s^{-1}$]\", \n",
    "                       fontsize=20)\n",
    "    if i == 1:\n",
    "        plt.xlabel(\"Wavelength\", \n",
    "                   fontsize=20)\n",
    "\n",
    "plt.suptitle(\"Fig 3.1\\nComparing the old and new extracted spectra for each segment\", \n",
    "             fontsize=25)\n",
    "\n",
    "# More formatting\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(str(plotsdir / \"comp_extracted.png\"), \n",
    "            dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-commodity",
   "metadata": {},
   "source": [
    "<a id = fuvE></a>\n",
    "# 4. Example using FUV data\n",
    "\n",
    "Let's go through doing all of the above with an FUV dataset and corresponding FUV `XTRACTAB`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-exchange",
   "metadata": {},
   "source": [
    "First download the FUV data; we'll select an FUV/G160M/C1533 dataset from the same proposal as the NUV dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying the PID's data\n",
    "pl = Observations.get_product_list(\n",
    "                        Observations.query_criteria(\n",
    "                            proposal_id=15869, \n",
    "                            obs_id='LE4B01040'))\n",
    "\n",
    "# Getting only the RAWTAG, ASN, and X1DSUM files\n",
    "masked_pl = pl[np.isin(pl['productSubGroupDescription'], ['RAWTAG_A', 'RAWTAG_B', 'ASN', 'X1DSUM'])]\n",
    "\n",
    "# Now download the files\n",
    "Observations.download_products(masked_pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-career",
   "metadata": {},
   "source": [
    "**We gather a list of all the `_rawtag` files we have downloaded, as well as the `_asnfile` and `_x1dsum` file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtags_a = glob.glob('./mastDownload/HST/le4b01*/**/*_rawtag_a.fits', \n",
    "                      recursive=True)\n",
    "\n",
    "rawtags_b = glob.glob('./mastDownload/HST/le4b01*/**/*_rawtag_b.fits', \n",
    "                      recursive=True)\n",
    "\n",
    "rawtags_ab = rawtags_a + rawtags_b\n",
    "\n",
    "asnfile = glob.glob('./mastDownload/HST/le4b01040/**/*_asn.fits', \n",
    "                    recursive=True)[0]\n",
    "\n",
    "old_x1dsum = glob.glob('./mastDownload/HST/le4b01040/**/*_x1dsum.fits', \n",
    "                       recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-morning",
   "metadata": {},
   "source": [
    "Move the files and index them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all this FUV data, except the calibrated x1dsum\n",
    "fdatadir = Path('./fuv_data/') \n",
    "fdatadir.mkdir(exist_ok=True)\n",
    "\n",
    "[os.rename(rta, fdatadir / os.path.basename(rta)) for rta in rawtags_a]\n",
    "[os.rename(rtb, fdatadir / os.path.basename(rtb)) for rtb in rawtags_b]\n",
    "\n",
    "os.rename(asnfile, fdatadir / os.path.basename(asnfile))\n",
    "\n",
    "# Re-find all the data now that it's moved\n",
    "rawtags_a = glob.glob(str(fdatadir/'*_rawtag_a.fits'), \n",
    "                      recursive=True)\n",
    "rawtags_b = glob.glob(str(fdatadir/'*_rawtag_b.fits'), \n",
    "                      recursive=True)\n",
    "\n",
    "rawtags_ab = rawtags_a + rawtags_b\n",
    "\n",
    "asnfile = glob.glob(str(fdatadir/'*_asn.fits'), \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-might",
   "metadata": {},
   "source": [
    "**We need to see where the FUV spectra fall in order to determine where we should place the extraction boxes.**\n",
    "\n",
    "We'll first plot this as a 2D image of the raw counts.\n",
    "We select and plot the raw counts data from the 0th `rawtag_a` and `rawtag_b` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the data from the first rawtag_a/b file\n",
    "rtda = Table.read(rawtags_a[0], 1)\n",
    "rtdb = Table.read(rawtags_b[0], 1)\n",
    "\n",
    "# Creating our figure\n",
    "fig, (ax0,ax1) = plt.subplots(1, 2,\n",
    "                              figsize=(16, 8))\n",
    "\n",
    "ax0.scatter(rtdb['RAWX'], rtdb['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0')\n",
    "\n",
    "ax1.scatter(rtda['RAWX'], rtda['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0')\n",
    "\n",
    "ax0.set_title(\"Segment FUVB\", \n",
    "              fontsize=20)\n",
    "ax1.set_title(\"Segment FUVA\", \n",
    "              fontsize=20)\n",
    "\n",
    "ax0.set_xlabel('Dispersion axis Pixel',\n",
    "               size=20)\n",
    "ax1.set_xlabel('Dispersion axis Pixel',\n",
    "               size=20)\n",
    "ax0.set_ylabel('Cross-dispersion axis Pixel', \n",
    "               size=20)\n",
    "plt.suptitle(\"Fig 4.1\\n2D spectrum of all raw (unfiltered) counts\", \n",
    "             size=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(str(plotsdir / 'fuv_2Dspectrum.png'), \n",
    "            dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-training",
   "metadata": {},
   "source": [
    "**We now need to download the correct `XTRACTAB`.**\n",
    "\n",
    "The next cell tells you what this `XTRACTAB` *should* be, and you download it in the cell that follows. Make sure these filenames match, as the reference files may have changed since this tutorial was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_fuv_1dx = fits.getheader(rawtags_a[0])['XTRACTAB'].split(\"$\")[1]\n",
    "\n",
    "print(\"Make sure the next line is set to download: \", correct_fuv_1dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "! crds sync --files=2bj2256il_1dx.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-onion",
   "metadata": {},
   "source": [
    "**Now we can plot the original fuv boxes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our XTRACTAB reference file for the FUV\n",
    "fuv_xtractab = lref + correct_fuv_1dx\n",
    "\n",
    "read_bounds = readxtractab(fuv_xtractab, \n",
    "                           grat='G160M', \n",
    "                           cw=1533, \n",
    "                           aper='PSA')\n",
    "\n",
    "# Setting up a figure with two subplots, top being FUVA and bottom being FUVB\n",
    "fig, (ax0, ax1) = plt.subplots(2, 1, \n",
    "                               figsize=(10, 8), \n",
    "                               sharex=True)\n",
    "\n",
    "# Getting an image of the raw counts (RAWTAG A)\n",
    "ax1.scatter(rtda['RAWX'], rtda['RAWY'],\n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0')\n",
    "\n",
    "# Getting an image of the raw counts (RAWTAG B)\n",
    "ax0.scatter(rtdb['RAWX'], rtdb['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0')\n",
    "\n",
    "# Plotting the boxes for FUVA and FUVB (not background)\n",
    "for i in range(2):\n",
    "    # If it's the FUVB box:\n",
    "    if 'A' not in box_names_fuv[i]:\n",
    "        ax0.axhspan(read_bounds[i][0], read_bounds[i][1],\n",
    "                    color='cm'[i],\n",
    "                    hatch='/\\+x+x'[i],\n",
    "                    alpha=0.3,\n",
    "                    label=box_names_fuv[i])\n",
    "        \n",
    "    # If it's the FUVA box\n",
    "    else:\n",
    "        ax1.axhspan(read_bounds[i][0], read_bounds[i][1],\n",
    "                    color='cm'[i],\n",
    "                    hatch='/\\+x+x'[i],\n",
    "                    alpha=0.3,\n",
    "                    label=box_names_fuv[i])\n",
    "\n",
    "# Add plot formatting\n",
    "ax0.legend(loc='upper right') \n",
    "ax1.legend(loc='upper right') \n",
    "\n",
    "ax0.set_xlim(920, 15450)\n",
    "ax0.set_ylim(300, 700)\n",
    "ax1.set_ylim(ax0.get_ylim())\n",
    "\n",
    "ax1.set_xlabel('Dispersion axis Pixel', \n",
    "               size=20)\n",
    "fig.text(-0.01, 0.2,\n",
    "         'Cross-dispersion axis Pixel', \n",
    "         size=20, \n",
    "         rotation='vertical')\n",
    "\n",
    "plt.suptitle(\"Fig 4.2\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original extraction boxes in the FUV\", \n",
    "             size=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure to the plots directory\n",
    "plt.savefig(str(plotsdir / '2D_spec_orig_boxes_fuv.png'), \n",
    "            dpi=200, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-indiana",
   "metadata": {},
   "source": [
    "**Here we make the edits to the FUV `XTRACTAB`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be the values we set the box params to:\n",
    "# Centers of the background extract regions\n",
    "intercept_dict_fuv = {\"bbkg1a\":550., \"bbkg2a\":340.,\n",
    "                      \"bbkg1b\":350., \"bbkg2b\":665.,\n",
    "                      # Centers of NUV stripe extract regions\n",
    "                      'bspa':415., 'bspb':469.} \n",
    "\n",
    "hgt_dict_fuv = {'h_a':51, 'h_b':41}\n",
    "\n",
    "# Now edit using the edit_xtractab() function\n",
    "edit_xtractab(xtractab=fuv_xtractab, \n",
    "              gratlist=['G160M'], \n",
    "              cwlist=[1533], \n",
    "              h_dict=hgt_dict_fuv, \n",
    "              b_dict=intercept_dict_fuv, \n",
    "              new_filename='./edit_fuv_1dx.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-hindu",
   "metadata": {},
   "source": [
    "**We'll create a plot showing the old and new extraction boxes side-by-side:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original boxes\n",
    "read_bounds = readxtractab(fuv_xtractab, \n",
    "                           grat='G160M', \n",
    "                           cw=1533, \n",
    "                           aper='PSA') \n",
    "\n",
    "# Edited boxes\n",
    "read_bounds_fuv_edit = readxtractab('./edit_fuv_1dx.fits', \n",
    "                                    grat='G160M',\n",
    "                                    cw=1533, \n",
    "                                    aper='PSA') \n",
    "\n",
    "# Orig = ax0, ax1; New/Edited = ax2, ax3\n",
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, \n",
    "                                             figsize=(20, 10), \n",
    "                                             sharex=True, \n",
    "                                             sharey=True)\n",
    "\n",
    "# The original:\n",
    "# Images of the raw counts:\n",
    "# RAWTAG A\n",
    "ax2.scatter(rtda['RAWX'], rtda['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0')\n",
    "\n",
    "# RAWTAG B\n",
    "ax0.scatter(rtdb['RAWX'], rtdb['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0')\n",
    "\n",
    "# RAWTAG A\n",
    "ax3.scatter(rtda['RAWX'], rtda['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0') \n",
    "\n",
    "# RAWTAG B\n",
    "ax1.scatter(rtdb['RAWX'], rtdb['RAWY'], \n",
    "            s=0.1, \n",
    "            alpha=0.1, \n",
    "            c='C0') \n",
    "\n",
    "# Add all the boxes onto each subplots' image\n",
    "for i, (oldbox, newbox, bname) in enumerate(zip(read_bounds[:2], read_bounds_fuv_edit[:2], box_names_fuv[:2])):\n",
    "    # FUVA in ax0, ax1 (top left/right) \n",
    "    if 'A' not in bname: \n",
    "        ax0.axhspan(oldbox[0], oldbox[1], \n",
    "                    color='cmkyky'[i], \n",
    "                    hatch='/\\+x+x'[i], \n",
    "                    alpha=0.3, \n",
    "                    label=bname)\n",
    "        ax1.axhspan(newbox[0], newbox[1], \n",
    "                    color='cmkyky'[i], \n",
    "                    hatch='/\\+x+x'[i], \n",
    "                    alpha=0.3, \n",
    "                    label=bname)\n",
    "        \n",
    "    # FUVB in ax2, ax3 (bottom left/right)\n",
    "    else: \n",
    "        ax2.axhspan(oldbox[0], oldbox[1], \n",
    "                    color='cmkyky'[i], \n",
    "                    hatch='/\\+x+x'[i], \n",
    "                    alpha=0.3, \n",
    "                    label=bname)\n",
    "        ax3.axhspan(newbox[0], newbox[1], \n",
    "                    color='cmkyky'[i], \n",
    "                    hatch='/\\+x+x'[i], \n",
    "                    alpha=0.3, \n",
    "                    label=bname)\n",
    "\n",
    "# Add plot formatting\n",
    "ax0.legend(loc='upper right') \n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper right') \n",
    "ax3.legend(loc='upper right')\n",
    "\n",
    "ax0.set_xlim(920, 15450)\n",
    "ax0.set_ylim(300, 700)\n",
    "\n",
    "ax1.set_ylim(ax0.get_ylim())\n",
    "\n",
    "ax0.set_title(\"Original extraction boxes\", \n",
    "              fontsize=20)\n",
    "ax1.set_title(\"Edited extraction boxes\", \n",
    "              fontsize=20)\n",
    "\n",
    "fig.text(-0.01, 0.2,'Cross-dispersion axis Pixel', \n",
    "         size=20, \n",
    "         rotation='vertical')\n",
    "fig.text(0.45, -0.01,'Dispersion axis Pixel', \n",
    "         size=20)\n",
    "\n",
    "plt.suptitle(\"Fig 4.3\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original and edited extraction boxes in the FUV\", \n",
    "             size=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Saving the figure\n",
    "plt.savefig(str(plotsdir / '2D_spec_origedit_boxes_fuv.png'),\n",
    "            dpi=200, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-luxembourg",
   "metadata": {},
   "source": [
    "**Before we could run CalCOS on this file with the new `XTRACTAB`, (or *any* `BOXCAR` extraction file, for that matter,) you must change the relevant calibration switches in the file's primary fits header to...**\n",
    "1. perform a `BOXCAR` extraction\n",
    "2. use the newly edited `XTRACTAB` file.\n",
    "\n",
    "We must set the switches as follows in the Table:\n",
    "\n",
    "|Header Keyword|Possible Values|Value to set in order to apply this `XTRACTAB`|What does it tell CalCOS to do?|\n",
    "|-|-|-|-|\n",
    "|`XTRCTALG`|**`BOXCAR`**/`TWOZONE`|`BOXCAR`|Which extraction method to apply|\n",
    "|`TRCECORR`|`PERFORM`/**`OMIT`**|`OMIT`|Whether to perform or omit the [trace correction](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-4-descriptions-of-spectroscopic-calibration-steps#id-3.4DescriptionsofSpectroscopicCalibrationSteps-3.4.14TRCECORR:ApplyTraceCorrection)|\n",
    "|`ALGNCORR`|`PERFORM`/**`OMIT`**|`OMIT`|Whether to perform or omit the [align correction](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-4-descriptions-of-spectroscopic-calibration-steps#id-3.4DescriptionsofSpectroscopicCalibrationSteps-3.4.15ALGNCORR:AlignmentCorrection)|\n",
    "|`XTRACTAB`|Local path to any valid `XTRACTAB` file|./edit_fuv_1dx.fits|Where to find a local copy of the `XTRACTAB` to use|\n",
    "\n",
    "We set the switches below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary we'll use to set the values of the header calib switches\n",
    "fuv_keys_dict = { \n",
    "    'XTRCTALG':'BOXCAR',\n",
    "    'TRCECORR':'OMIT',\n",
    "    'ALGNCORR':'OMIT',\n",
    "    'XTRACTAB':'./edit_fuv_1dx.fits'}\n",
    "\n",
    "# Change this to True if you want to see the changes\n",
    "verbose = False \n",
    "\n",
    "# Loop through the rawtag A/B files\n",
    "for rawtag in rawtags_ab: \n",
    "    print(\"changing header switches for \", os.path.basename(rawtag))\n",
    "    for fuv_key, fuv_val in fuv_keys_dict.items():\n",
    "        if verbose:\n",
    "            print(\"\\tOriginally: \", fuv_key,'=', fits.getheader(rawtag)[fuv_key])\n",
    "\n",
    "        # Change the value of the FITS file\n",
    "        fits.setval(filename=rawtag, \n",
    "                    keyword=fuv_key, \n",
    "                    value=fuv_val)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\t       Now: \", fuv_key,'=', fits.getheader(rawtag)[fuv_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-poker",
   "metadata": {},
   "source": [
    "**You may now run `CalCOS` using this new FUV `XTRACTAB`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr \n",
    "# Above, capture the output and save it in the next cell\n",
    "\n",
    "# This line actually runs the pipeline:\n",
    "calcos.calcos(asnfile, \n",
    "              verbosity=1, \n",
    "              outdir=str(outputdir / \"calcos_fuv_run1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file now contains the output of the last cell\n",
    "with open(str(outputdir/'output_calcos_fuv_1.txt'), 'w') as f: \n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-patient",
   "metadata": {},
   "source": [
    "**Now let's compare the FUV spectra extracted with the original and new `XTRACTAB`s:**\n",
    "\n",
    "*Note* again, that we can ignore the UnitsWarning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "gs = fig.add_gridspec(nrows=5, \n",
    "                      ncols=2) \n",
    "\n",
    " # Use i,j to plot FUVA on the right, not the left, by inverting subplot index\n",
    "for i,j in zip([0, 1], [1, 0]):\n",
    "    ax0 = fig.add_subplot(gs[0:4, j])\n",
    "    ax1 = fig.add_subplot(gs[4:5, j])\n",
    "\n",
    "    # Get the new and old flux/wavelength data to be plotted\n",
    "    new_wvln, new_flux = Table.read('./output/calcos_fuv_run1/le4b01040_x1dsum.fits')[i]['WAVELENGTH', 'FLUX']\n",
    "    old_wvln, old_flux, seg = Table.read(old_x1dsum)[i]['WAVELENGTH', 'FLUX', 'SEGMENT']\n",
    "    \n",
    "    # Interpolate the new wvln onto the old wvln's sampling:\n",
    "    new_flux_interp = interp1d(x=new_wvln, y=new_flux, \n",
    "                               fill_value=\"extrapolate\")(old_wvln)\n",
    "\n",
    "    # Print the max difference\n",
    "    print(f\"Stripe {seg} differs by up to: \\\n",
    "    {max(new_flux - old_flux)/np.mean(abs(old_flux)):.3f}%\")\n",
    "\n",
    "    # Plotting the upper panel\n",
    "    ax0.plot(new_wvln, new_flux,\n",
    "             alpha=1, \n",
    "             linewidth=0.5, \n",
    "             c='C1',\n",
    "             label='$New$ extracted spectrum')\n",
    "    \n",
    "    ax0.plot(old_wvln, old_flux, \n",
    "             linewidth=1, \n",
    "             c='C0',\n",
    "             linestyle='dotted', \n",
    "             alpha=0.75,\n",
    "             label='$Original$ extracted spectrum')\n",
    "\n",
    "    # Plotting the lower panel\n",
    "    ax1.plot(new_wvln, old_flux - new_flux_interp, \n",
    "             linewidth=0.5, \n",
    "             label='Residual')\n",
    "\n",
    "    # Some formatting:\n",
    "    ax0.set_title(f\"Segment {seg}\", \n",
    "                  fontsize=20)\n",
    "\n",
    "    ax0.set_xticks([])\n",
    "\n",
    "    ax0.legend(loc='lower center')\n",
    "    ax1.legend(loc='lower center')\n",
    "\n",
    "    # Add axis labels to the plot\n",
    "    if i == 0: \n",
    "        ax0.set_ylabel(\"Flux\\n[$erg\\ \\AA^{-1}\\ cm^{-2}\\ s^{-1}$]\", \n",
    "                       fontsize=20)\n",
    "    if i == 1:\n",
    "        plt.xlabel(\"Wavelength\", \n",
    "                   fontsize=20)\n",
    "\n",
    "plt.suptitle(\"Fig 4.4\\nComparing the old and new extracted spectra for each segment in the FUV\", \n",
    "             fontsize=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Saving the figure\n",
    "plt.savefig(str(plotsdir / \"comp_fuv_extracted.png\"), \n",
    "            dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9149e29-cbdb-47ee-ba27-0ad51a8e794d",
   "metadata": {},
   "source": [
    "# In conclusion\n",
    "* We have learned what the `XTRACTAB` file is and how it affects your calibration of COS spectra\n",
    "* We have learned how to edit your `XTRACTAB` to tailor how `CalCOS` extracts the spectrum of the source and background\n",
    "* We have shown examples of changing the `XTRACTAB` and reprocessing the data with the altered extraction boxes in both the FUV and NUV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-texas",
   "metadata": {},
   "source": [
    "## Congratulations! You finished this Notebook!\n",
    "### There are more COS data walkthrough Notebooks on different topics. You can find them [here](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/COS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-ultimate",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## About this Notebook\n",
    "**Author:** Nat Kerman <nkerman@stsci.edu>\n",
    "\n",
    "**Contributors:** Elaine Mae Frazer\n",
    "\n",
    "**Updated On:** 2023-07-27\n",
    "\n",
    "> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n",
    "\n",
    "## Citations\n",
    "\n",
    "If you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\n",
    "authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `astropy`](https://docs.astropy.org/en/stable/index.html)\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/)\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "---\n",
    "\n",
    "[Top of Page](#topE)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5581d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
