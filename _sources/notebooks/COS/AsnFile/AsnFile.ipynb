{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topAF\"></a>\n",
    "\n",
    "# Modifying or Creating an Association File\n",
    " \n",
    "# Learning Goals\n",
    "<font size=\"4\"> This Notebook is designed to walk the user (<em>you</em>) through: <b>Creating or altering the association (<tt>asn</tt>) file used by the Cosmic Origins Spectrograph (<em>COS</em>) pipeline to determine which data to process:</b> </font><br>\n",
    "    \n",
    "**1. [Examining an association file](#examAF)**\n",
    "\n",
    "**2. [Editing an existing association file](#editAF)**\n",
    "\n",
    "\\- 2.1. [Removing an exposure](#subAF)\n",
    "\n",
    "\\+ 2.1.1. [Removing a bad exposure](#removebadAF)\n",
    "\n",
    "\\+ 2.1.2. [Filtering to a single exposure (e.g. for LP6 data)](#removefiltAF)\n",
    "    \n",
    "\\- 2.2. [Adding an exposure](#addAF)\n",
    "    \n",
    "**3. [Creating an entirely new association file](#newAF)**\n",
    "\n",
    "\\- 3.1. [Simplest method](#simpleAF)\n",
    "    \n",
    "\\- 3.2. [With FITS header metadata](#metaAF)\n",
    "    \n",
    "\\- 3.3. [Association files for non-TAGFLASH datasets](#nontagAF)\n",
    "\n",
    "\\+ 3.3.1. [Gathering the exposure information](#331-gathering-the-exposure-informationAF)\n",
    "\n",
    "\\+ 3.3.2. [Creating the `SPLIT` wavecal association file](#332-creating-the-split-wavecal-association-fileAF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "**The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope ([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).**\n",
    "\n",
    "**This tutorial aims to prepare you to alter the association file used by the `CalCOS` pipeline.** Association files are `fits` files containing a binary table extension, which list their \"member\" files: science and calibration exposures which the pipeline will process together into spectral data products.\n",
    "\n",
    "- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n",
    "- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/).\n",
    "\n",
    "We'll demonstrate creating an `asn` file in three ways: First, we'll demonstrate [editing an existing `asn` file to add or remove an exposure](#editAF). Second, we'll show how to [create an entirely new `asn` file](#newAF). Finally, we'll show an example of [creating an `asn` file for use with SPLIT wavecal data](#nontagAF), such as that obtained at COS lifetime position 6 (LP6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will import the following packages:\n",
    "\n",
    "- `numpy` to handle array functions\n",
    "- `astropy.io fits` and `astropy.table Table` for accessing FITS files\n",
    "- `glob`, `os`, and `shutil` for working with system files \n",
    "  - `glob` helps us search for filenames\n",
    "  - `os` and `shutil` for moving files and deleting folders, respectively\n",
    "- `astroquery.mast Mast` and `Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- `datetime` for updating FITS headers with today's date\n",
    "- `pathlib Path` for managing system paths\n",
    "- `pandas` for data table manipulation\n",
    "\n",
    "If you have an existing astroconda environment, it may or may not already have the necessary packages to run this Notebook. To create a Python environment capable of running all the data analyses in these COS Notebooks, please see Section 1 of our Notebook tutorial on [setting up an environment](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/Setup/Setup.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:01:05.783568Z",
     "iopub.status.busy": "2025-09-17T22:01:05.783334Z",
     "iopub.status.idle": "2025-09-17T22:01:07.545834Z",
     "shell.execute_reply": "2025-09-17T22:01:07.545311Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from astroquery.mast import Observations\n",
    "import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will also define a few directories we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:01:07.547746Z",
     "iopub.status.busy": "2025-09-17T22:01:07.547571Z",
     "iopub.status.idle": "2025-09-17T22:01:07.551231Z",
     "shell.execute_reply": "2025-09-17T22:01:07.550762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made the following directories:\n",
      "     ./data, ./output, ./output/plots\n"
     ]
    }
   ],
   "source": [
    "# These will be important directories for the Notebook\n",
    "datadir = Path('./data/')\n",
    "outputdir = Path('./output/')\n",
    "plotsdir = Path('./output/plots/')\n",
    "\n",
    "# Make the directories if they don't already exist\n",
    "datadir.mkdir(exist_ok=True)\n",
    "outputdir.mkdir(exist_ok=True)\n",
    "plotsdir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Made the following directories:\"+\"\\n    \",\n",
    "      f'./{datadir}, ./{outputdir}, ./{plotsdir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And we will need to download the data we wish to filter and analyze\n",
    "We choose the exposures with the association obs_ids: `ldif01010` and `ldif02010` because we happen to know that some of the exposures in these groups failed, which gives us a real-world use case for editing an association file. Both `ldif01010` and `ldif02010` are far-ultraviolet (FUV) datasets on the quasi-stellar object (QSO) [PDS 456](https://doi.org/10.1051/0004-6361/201935524).\n",
    "\n",
    "For more information on downloading COS data, see our [Notebook tutorial on downloading COS data](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/DataDl/DataDl.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:01:07.578893Z",
     "iopub.status.busy": "2025-09-17T22:01:07.578661Z",
     "iopub.status.idle": "2025-09-17T22:01:43.866800Z",
     "shell.execute_reply": "2025-09-17T22:01:43.866311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01010_asn.fits to data/mastDownload/HST/ldif01010/ldif01010_asn.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01tyq_rawtag_a.fits to data/mastDownload/HST/ldif01tyq/ldif01tyq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01tyq_rawtag_b.fits to data/mastDownload/HST/ldif01tyq/ldif01tyq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u0q_rawtag_a.fits to data/mastDownload/HST/ldif01u0q/ldif01u0q_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u0q_rawtag_b.fits to data/mastDownload/HST/ldif01u0q/ldif01u0q_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u2q_rawtag_a.fits to data/mastDownload/HST/ldif01u2q/ldif01u2q_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u2q_rawtag_b.fits to data/mastDownload/HST/ldif01u2q/ldif01u2q_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u4q_rawtag_a.fits to data/mastDownload/HST/ldif01u4q/ldif01u4q_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u4q_rawtag_b.fits to data/mastDownload/HST/ldif01u4q/ldif01u4q_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02010_asn.fits to data/mastDownload/HST/ldif02010/ldif02010_asn.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nmq_rawtag_a.fits to data/mastDownload/HST/ldif02nmq/ldif02nmq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nmq_rawtag_b.fits to data/mastDownload/HST/ldif02nmq/ldif02nmq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nsq_rawtag_a.fits to data/mastDownload/HST/ldif02nsq/ldif02nsq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nsq_rawtag_b.fits to data/mastDownload/HST/ldif02nsq/ldif02nsq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nuq_rawtag_a.fits to data/mastDownload/HST/ldif02nuq/ldif02nuq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nuq_rawtag_b.fits to data/mastDownload/HST/ldif02nuq/ldif02nuq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nwq_rawtag_a.fits to data/mastDownload/HST/ldif02nwq/ldif02nwq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nwq_rawtag_b.fits to data/mastDownload/HST/ldif02nwq/ldif02nwq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    }
   ],
   "source": [
    "# Search for the correct obs_ids and get the product list\n",
    "pl = Observations.get_product_list(\n",
    "                            Observations.query_criteria(\n",
    "                                obs_id='ldif0*10'))\n",
    "\n",
    "# filter to rawtag and asn files in the product list\n",
    "fpl = Observations.filter_products(\n",
    "                    pl,\n",
    "                    productSubGroupDescription=['RAWTAG_A', 'RAWTAG_B', 'ASN'])\n",
    "\n",
    "# Download these chosen products\n",
    "Observations.download_products(\n",
    "                            fpl,\n",
    "                            download_dir=str(datadir))\n",
    "\n",
    "# Move all FITS files in this set to the base data directory\n",
    "for gfile in glob.glob(\"**/ldif*/*.fits\", recursive=True):\n",
    "    os.rename(gfile, datadir / os.path.basename(gfile))\n",
    "\n",
    "# Delete the now-empty, nested mastDownload directory\n",
    "shutil.rmtree(datadir / 'mastDownload')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = examAF></a>\n",
    "# 1. Examining an association file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association files are lists of \"member\" files - science and wavelength calibration exposures - which the `CalCOS` pipeline will process together.\n",
    "Above, we downloaded two association files and the rawtag data files which are their members. We will begin by searching for the association files and reading one of them (with observation ID `LDIF01010`). We could just as easily pick `ldif02010`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:01:43.868429Z",
     "iopub.status.busy": "2025-09-17T22:01:43.868280Z",
     "iopub.status.idle": "2025-09-17T22:01:43.879133Z",
     "shell.execute_reply": "2025-09-17T22:01:43.878649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=5</i>\n",
       "<table id=\"table140084698342416\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF01TYQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U2Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LDIF01TYQ         EXP-FP        1\n",
       "     LDIF01U0Q         EXP-FP        1\n",
       "     LDIF01U2Q         EXP-FP        1\n",
       "     LDIF01U4Q         EXP-FP        1\n",
       "     LDIF01010        PROD-FP        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There will be two (ldif01010_asn.fits and ldif02010_asn.fits)\n",
    "asnfiles = sorted(glob.glob(\"**/*ldif*asn*\", recursive=True))\n",
    "# We want to work primarily with ldif01010_asn.fits\n",
    "asnfile = asnfiles[0]\n",
    "\n",
    "# Gets the contents of the asn file\n",
    "asn_contents = Table.read(asnfile)\n",
    "\n",
    "# Display these contents\n",
    "asn_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The association file has three columns: `MEMNAME`, `MEMTYPE`, `MEMPRSNT` which we describe below. More information can be found in [Section 3 of the COS Data Handbook](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration).\n",
    "\n",
    "1. `MEMNAME` (*short for \"member name\"*): The rootname of the file, e.g. `ldif01u0q` for the file `ldif01u0q_rawtag_a.fits`\n",
    "2. `MEMTYPE` (*\"membership type\"*): Whether the item is a science exposure (`EXP-FP`), a wavecal exposure (`EXP-SWAVE`/`EXP-GWAVE`/`EXP-AWAVE`), or the output product (`PROD-FP`)\n",
    "3. `MEMPRSNT` (*\"member present\"*): Whether to include the file in `CalCOS`' processing\n",
    "\n",
    "We also see that this association file has five rows: four science exposures denoted with the `MEMTYPE` = `EXP-FP`, and an output product with `MEMTYPE` = `PROD-FP`.\n",
    "\n",
    "In the cell below, we examine a bit about each of the exposures as a diagnostic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:01:43.880744Z",
     "iopub.status.busy": "2025-09-17T22:01:43.880578Z",
     "iopub.status.idle": "2025-09-17T22:01:43.906381Z",
     "shell.execute_reply": "2025-09-17T22:01:43.905894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association LDIF01010 has EXP-FP exposure LDIF01TYQ with exptime 0.0 sec at cenwave 1280Å and FP-POS 1.\n",
      "\n",
      "Association LDIF01010 has EXP-FP exposure LDIF01U0Q with exptime 1404.0 sec at cenwave 1280Å and FP-POS 2.\n",
      "\n",
      "Association LDIF01010 has EXP-FP exposure LDIF01U2Q with exptime 1404.0 sec at cenwave 1280Å and FP-POS 3.\n",
      "\n",
      "Association LDIF01010 has EXP-FP exposure LDIF01U4Q with exptime 2923.0 sec at cenwave 1280Å and FP-POS 4.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cycles through each file in asn table\n",
    "for memname, memtype in zip(asn_contents['MEMNAME'], asn_contents[\"MEMTYPE\"]):\n",
    "    # Find file names in lower case letters\n",
    "    memname = memname.lower()\n",
    "    # We only want to look at the exposure files\n",
    "    if memtype == 'EXP-FP':\n",
    "        # Find the actual filepath of the memname for rawtag_a and rawtag_b\n",
    "        rt_a = (glob.glob(f\"**/*{memname}*rawtag_a*\", recursive=True))[0]\n",
    "        rt_b = (glob.glob(f\"**/*{memname}*rawtag_b*\", recursive=True))[0]\n",
    "\n",
    "        # Now print all these diagnostics:\n",
    "        print(f\"Association {(fits.getheader(rt_a))['ASN_ID']} has {memtype} \"\n",
    "              f\"exposure {memname.upper()} with exptime \"\n",
    "              f\"{(fits.getheader(rt_a, ext=1))['EXPTIME']} \"\n",
    "              f\"sec at cenwave {(fits.getheader(rt_a, ext=0))['CENWAVE']}\"\n",
    "              f\"Å and FP-POS {(fits.getheader(rt_a, ext=0))['FPPOS']}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We notice that something seems amiss with the science exposure LDIF01TYQ**:\n",
    "This file has an exposure time of 0.0 seconds - something has gone wrong. In this case, there was a guide star acquisition failure as described on the [data preview page](http://archive.stsci.edu/cgi-bin/mastpreview?mission=hst&dataid=LDIF01010).\n",
    "\n",
    "In the next section, we will correct this lack of data by removing the bad exposure and combining in exposures from the other association group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = editAF></a>\n",
    "# 2. Editing an existing association file\n",
    "\n",
    "<a id = subAF></a>\n",
    "## 2.1. Removing an exposure\n",
    "\n",
    "<a id = removebadAF></a>\n",
    "#### 2.1.1. Removing a bad exposure\n",
    "\n",
    "We know that at least one of our exposures - `ldif01tyq` - is not suited for combination into the final product. It has an exposure time of 0.0 seconds, in this case from a guide star acquisition failure. This is a generalizable issue, as you may often know an exposure is \"*bad*\" for many reasons: perhaps it was taken with the shutter closed, or with anomolously high background noise, or any number of reasons we may wish to exclude an exposure from our data. To do this, we will need to alter our existing association file before we re-run `CalCOS`. Afterwards we will compare the flux of the resulting spectrum made without the bad exposure to the same dataset with the bad exposure. The flux levels should match closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again see the contents of our main association file below. Note that `True/False` and `1/0` are essentially interchangable in the `MEMPRSNT` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:01:43.907904Z",
     "iopub.status.busy": "2025-09-17T22:01:43.907761Z",
     "iopub.status.idle": "2025-09-17T22:01:43.915746Z",
     "shell.execute_reply": "2025-09-17T22:01:43.915318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=5</i>\n",
       "<table id=\"table140084698444176\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF01TYQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U2Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LDIF01TYQ         EXP-FP        1\n",
       "     LDIF01U0Q         EXP-FP        1\n",
       "     LDIF01U2Q         EXP-FP        1\n",
       "     LDIF01U4Q         EXP-FP        1\n",
       "     LDIF01010        PROD-FP        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(asnfiles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the `MEMPRSNT` value to `False` or `0` for our bad exposure. If we were to run the `CalCOS` pipeline on the edited association file, it would not be processed. `CalCOS` can take a long time to run. To avoid slowing down this Notebook, the code to run `CalCOS` on the association files we have created has been spun out into `Python` files in this directory with the names `test_<type of association file>.py` (in this case, `test_removed_exposure_asn.py`). If you wish to re-run the analysis within, you will need to specify a valid cache of CRDS reference files (see our [Setup Notebook](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/Setup/Setup.ipynb) for details on downloading reference files) in the `Python` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:01:43.917121Z",
     "iopub.status.busy": "2025-09-17T22:01:43.916970Z",
     "iopub.status.idle": "2025-09-17T22:01:43.932919Z",
     "shell.execute_reply": "2025-09-17T22:01:43.932494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=5</i>\n",
       "<table id=\"table140084700205264\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF01TYQ</td><td>EXP-FP</td><td>0</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U2Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LDIF01TYQ         EXP-FP        0\n",
       "     LDIF01U0Q         EXP-FP        1\n",
       "     LDIF01U2Q         EXP-FP        1\n",
       "     LDIF01U4Q         EXP-FP        1\n",
       "     LDIF01010        PROD-FP        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to change values with the asnfile opened and in 'update' mode\n",
    "with fits.open(asnfile, mode='update') as hdulist:\n",
    "    # This is where the table data is read into\n",
    "    tbdata = hdulist[1].data\n",
    "    # Check if each file is one of the bad ones\n",
    "    for expfile in tbdata:\n",
    "        # If so, set MEMPRSNT to False AKA 0\n",
    "        if expfile['MEMNAME'] in ['LDIF01TYQ']:\n",
    "            expfile['MEMPRSNT'] = False\n",
    "\n",
    "# Copy this file we will edit, in case we want to run CalCOS on it.\n",
    "shutil.copy(asnfile, datadir / \"removed_badfile_asn.fits\")\n",
    "\n",
    "# Re-read the table to see the change\n",
    "Table.read(asnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show what would happen if we run `CalCOS` on this association file, we include Figure 1. This figure shows that the flux level of the spectrum retrieved from MAST matches that which was processed after removing the bad exposure. Slight differences in the two spectra may arise from MAST using a different random seed value. What matters for this comparison is that the fluxes match well, as they should because the empty exposure adds 0 counts over 0 time. Thus, for the purposes of flux calibration, it should be ignored. Other types of bad exposures, for instance those taken with the source at the edge of COS's aperture, would impact the fluxes.\n",
    "\n",
    "### Figure 1. Comparison of fluxes between the data retrieved from MAST, and the same data reprocessed after removing the bad exposure\n",
    "\n",
    "<img src=./figures/compare_fluxes_after_removing_badfile.png width=60% title='Comparison of fluxes' alt='A comparison between the fluxes of our data. One dataset if without our bad exposure removed, and the other is with our bad exposure removed. Both plots are relatively the same, as they should be.'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = removefiltAF></a>\n",
    "#### 2.1.2. Filtering to a single exposure (e.g. for LP6 data)\n",
    "\n",
    "Another situation when users often wish to remove exposures from an association file is when re-processing individual exposures taken at COS's lifetime position 6 (LP6) or other modes at which the wavelength calibration data is not contained by the science exposures' `rawtag` files. \n",
    "\n",
    "Often users wish to process a single exposure's file with `CalCOS`. With the [`TAGFLASH` wavelength calibration method](https://hst-docs.stsci.edu/cosihb/chapter-5-spectroscopy-with-cos/5-7-internal-wavelength-calibration-exposures#id-5.7InternalWavelengthCalibrationExposures-Section5.7.15.7.1ConcurrentWavelengthCalibrationwithTAGFLASH) standard at all lifetime positions prior to LP6, the wavelength calibration data was taken concurrently with the science data and was contained by the same `rawtag` data files. However, as described in this [COS 2030 plan poster](https://aas240-aas.ipostersessions.com/default.aspx?s=06-68-AE-28-CC-4A-12-7A-B0-4F-02-46-BC-D1-BE-7E), this is not possible at LP6. Instead, separate wavelength calibration exposures are taken at separate lifetime positions in a process known as [SPLIT wavecals](https://hst-docs.stsci.edu/cosihb/chapter-5-spectroscopy-with-cos/5-7-internal-wavelength-calibration-exposures#id-5.7InternalWavelengthCalibrationExposures-Section5.7.65.7.6SPLITWavecals(defaultnon-concurrentwavelengthcalibrationatLP6)). As a result, the wavelength calibration data no longer exists in the same file as the science data for such exposures.\n",
    "\n",
    "For `TAGFLASH` data, users could run `CalCOS` directly on their `rawtag` file of interest (though using an association file was always recommended). However, doing so with LP6 data would not allow the proper wavelength calibration. Instead, users should create a custom association file created by removing exposures from the default association file. We demonstrate this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll alter an LP6 association file with the observation ID `letc01010`.\n",
    "Let's begin by downloading the default LP6 association file from MAST and displaying it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:01:43.934507Z",
     "iopub.status.busy": "2025-09-17T22:01:43.934342Z",
     "iopub.status.idle": "2025-09-17T22:02:11.061929Z",
     "shell.execute_reply": "2025-09-17T22:02:11.061499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01010_asn.fits to data/mastDownload/HST/letc01010/letc01010_asn.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><i>Table length=13</i>\n",
       "<table id=\"table140084698380688\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LETC01LMQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01LOQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LETC01LRQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01LTQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01LWQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LETC01M1Q</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01M6Q</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01MTQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LETC01MVQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01MXQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01MZQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LETC01N1Q</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=13>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LETC01LMQ      EXP-SWAVE        1\n",
       "     LETC01LOQ         EXP-FP        1\n",
       "     LETC01LRQ      EXP-SWAVE        1\n",
       "     LETC01LTQ      EXP-SWAVE        1\n",
       "     LETC01LWQ         EXP-FP        1\n",
       "     LETC01M1Q      EXP-SWAVE        1\n",
       "     LETC01M6Q      EXP-SWAVE        1\n",
       "     LETC01MTQ         EXP-FP        1\n",
       "     LETC01MVQ      EXP-SWAVE        1\n",
       "     LETC01MXQ      EXP-SWAVE        1\n",
       "     LETC01MZQ         EXP-FP        1\n",
       "     LETC01N1Q      EXP-SWAVE        1\n",
       "     LETC01010        PROD-FP        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for the correct obs_ids and get the list of data products\n",
    "lp6_observation_products = Observations.get_product_list(\n",
    "                                Observations.query_criteria(\n",
    "                                    obs_id='letc01010'),\n",
    ")\n",
    "\n",
    "# Download the asnfile product list, then get the 0th element of the\n",
    "# resulting path list, since there's only 1 asn file\n",
    "lp6_original_asnfile = Path(\n",
    "    Observations.download_products(\n",
    "        Observations.filter_products(\n",
    "            lp6_observation_products,\n",
    "            productSubGroupDescription=['ASN'],\n",
    "        ),\n",
    "        download_dir=str(datadir)\n",
    "    )['Local Path'][0]\n",
    ")\n",
    "\n",
    "# Show the default association file for the LP6 dataset.\n",
    "Table.read(lp6_original_asnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we see 4 `EXP-FP` members, which are the science exposures at COS's 4 [fixed-pattern noise positions (`FP-POS`)](https://hst-docs.stsci.edu/cosdhb/chapter-1-cos-overview/1-1-instrument-capabilities-and-design). Each is bracketed by a SPLIT wavecal wavelength calibration exposure on each side (`EXP-SWAVE`).\n",
    "\n",
    "If we only wish to process one of the science exposures, (along with its wavelength calibration exposures,) we turn off all the other exposures by setting their `MEMPRSNT` values to 0/`False`. The product file (`PROD-FP`) must also be turned on, and should be renamed to show that it will only include data from a single exposure. Below, we do so, assuming we wish to process only the `FP-POS = 3` science exposure: `LETC01MTQ` (and its wavelength calibration exposures: `LETC01M6Q` and `LETC01MVQ`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.063388Z",
     "iopub.status.busy": "2025-09-17T22:02:11.063246Z",
     "iopub.status.idle": "2025-09-17T22:02:11.078912Z",
     "shell.execute_reply": "2025-09-17T22:02:11.078503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will turn off the input exposures except for: ['LETC01M6Q', 'LETC01MTQ', 'LETC01MVQ']. We will also leave the output product file turned on.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><i>Table length=13</i>\n",
       "<table id=\"table140084698262992\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LETC01LMQ</td><td>EXP-SWAVE</td><td>0</td></tr>\n",
       "<tr><td>LETC01LOQ</td><td>EXP-FP</td><td>0</td></tr>\n",
       "<tr><td>LETC01LRQ</td><td>EXP-SWAVE</td><td>0</td></tr>\n",
       "<tr><td>LETC01LTQ</td><td>EXP-SWAVE</td><td>0</td></tr>\n",
       "<tr><td>LETC01LWQ</td><td>EXP-FP</td><td>0</td></tr>\n",
       "<tr><td>LETC01M1Q</td><td>EXP-SWAVE</td><td>0</td></tr>\n",
       "<tr><td>LETC01M6Q</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01MTQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LETC01MVQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01MXQ</td><td>EXP-SWAVE</td><td>0</td></tr>\n",
       "<tr><td>LETC01MZQ</td><td>EXP-FP</td><td>0</td></tr>\n",
       "<tr><td>LETC01N1Q</td><td>EXP-SWAVE</td><td>0</td></tr>\n",
       "<tr><td>LETC01MTQ_only</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=13>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LETC01LMQ      EXP-SWAVE        0\n",
       "     LETC01LOQ         EXP-FP        0\n",
       "     LETC01LRQ      EXP-SWAVE        0\n",
       "     LETC01LTQ      EXP-SWAVE        0\n",
       "     LETC01LWQ         EXP-FP        0\n",
       "     LETC01M1Q      EXP-SWAVE        0\n",
       "     LETC01M6Q      EXP-SWAVE        1\n",
       "     LETC01MTQ         EXP-FP        1\n",
       "     LETC01MVQ      EXP-SWAVE        1\n",
       "     LETC01MXQ      EXP-SWAVE        0\n",
       "     LETC01MZQ         EXP-FP        0\n",
       "     LETC01N1Q      EXP-SWAVE        0\n",
       "LETC01MTQ_only        PROD-FP        1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WAVECAL -> SCIENCE -> WAVECAL\n",
    "exposures_to_use = ['LETC01M6Q', 'LETC01MTQ', 'LETC01MVQ']\n",
    "\n",
    "print(f\"We will turn off the input exposures except for: {exposures_to_use}.\"\n",
    "      f\" We will also leave the output product file turned on.\")\n",
    "\n",
    "# Make a copy of the original asn file with a name to\n",
    "# indicate it will only process a single chosen exposure:\n",
    "lp6_1exposure_asnfile = shutil.copy(lp6_original_asnfile,\n",
    "                                    datadir / 'letc01mtq_only_asn.fits')\n",
    "\n",
    "# Turn off all the other exposures in the copy\n",
    "with fits.open(lp6_1exposure_asnfile, mode='update') as hdulist:\n",
    "    tbdata = hdulist[1].data\n",
    "    # Turn off files except those listed here\n",
    "    for expfile in tbdata:\n",
    "        # If file isn't what we're going to use, set MEMPRSNT to False AKA 0\n",
    "        if expfile['MEMNAME'] not in exposures_to_use:\n",
    "            expfile['MEMPRSNT'] = False\n",
    "        # Turn on and rename the product file to indicate\n",
    "        # it will only include the chosen exposure:\n",
    "        if expfile['MEMTYPE'] == 'PROD-FP':\n",
    "            # Turn on the product file\n",
    "            expfile['MEMPRSNT'] = True\n",
    "            # Rename the product file\n",
    "            expfile['MEMNAME'] = \"LETC01MTQ_only\"\n",
    "\n",
    "# Re-read the table to see the change\n",
    "Table.read(lp6_1exposure_asnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = addAF></a>\n",
    "## 2.2. Adding an exposure\n",
    "In section 2.1.1, we removed the failed exposure taken with `FP-POS = 1` from our `ldif01010` association file. When possible, we usually want to combine one or more of each of the four FP-POS types. In this example scenario, let's add the `FP-POS = 1` exposure from the other association group. Please note that combining data from separate visits with different target acquisitions can result in true errors which are higher than those calculated by `CalCOS`.\n",
    "We combine the datasets here as an example only and do not specifically endorse combining these exposures.\n",
    "Also note that you should only combine files taken using the same grating and central wavelength settings in this manner.\n",
    "\n",
    "In the cell below, we determine which exposure from `LDIF02010` was taken with `FP-POS = 1`.\n",
    "- *It does this by looping through the files listed in `LDIF02010`'s association file, and then reading in that file's header to check if its `FPPOS = 1`.*\n",
    "- *It also prints some diagnostic information about all of the exposure files.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.080339Z",
     "iopub.status.busy": "2025-09-17T22:02:11.080181Z",
     "iopub.status.idle": "2025-09-17T22:02:11.113128Z",
     "shell.execute_reply": "2025-09-17T22:02:11.112610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association LDIF02010 has EXP-FP exposure LDIF02NMQ with exptime 1653.0 seconds at cenwave 1280 Å and FP-POS 1.\n",
      "^^ The one above this has the FP-POS we are looking for (LDIF02NMQ)^^^\n",
      "\n",
      "Association LDIF02010 has EXP-FP exposure LDIF02NSQ with exptime 1334.0 seconds at cenwave 1280 Å and FP-POS 2.\n",
      "Association LDIF02010 has EXP-FP exposure LDIF02NUQ with exptime 1334.0 seconds at cenwave 1280 Å and FP-POS 3.\n",
      "Association LDIF02010 has EXP-FP exposure LDIF02NWQ with exptime 2783.0 seconds at cenwave 1280 Å and FP-POS 4.\n"
     ]
    }
   ],
   "source": [
    "# Reads the contents of the 2nd asn file\n",
    "asn_con_2 = Table.read(asnfiles[1])\n",
    "\n",
    "# Loops through each file in asn table for `LDIF02010`\n",
    "for memname, memtype in zip(asn_con_2['MEMNAME'], asn_con_2[\"MEMTYPE\"]):\n",
    "    # Convert file names to lower case letters, as in actual filenames\n",
    "    memname = memname.lower()\n",
    "    # We only want to look at the exposure files\n",
    "    if memtype == 'EXP-FP':\n",
    "        # Search for the actual filepath of the memname for rawtag_a & rawtag_b\n",
    "        rt_a = (glob.glob(f\"**/*{memname}*rawtag_a*\", recursive=True))[0]\n",
    "        rt_b = (glob.glob(f\"**/*{memname}*rawtag_b*\", recursive=True))[0]\n",
    "\n",
    "        # Now print all these diagnostics:\n",
    "        print(f\"Association {(fits.getheader(rt_a))['ASN_ID']} has {memtype} \"\n",
    "              f\"exposure {memname.upper()} with \"\n",
    "              f\"exptime {(fits.getheader(rt_a, ext=1))['EXPTIME']} seconds\"\n",
    "              f\" at cenwave {(fits.getheader(rt_a, ext=0))['CENWAVE']} Å and \"\n",
    "              f\"FP-POS {(fits.getheader(rt_a, ext=0))['FPPOS']}.\")\n",
    "\n",
    "        # Checking if the file is FP-POS = 1\n",
    "        if (fits.getheader(rt_a, ext=0))['FPPOS'] == 1:\n",
    "            print(f\"^^ The one above this has the FP-POS \"\n",
    "                  f\"we are looking for ({memname.upper()})^^^\\n\")\n",
    "            # Save the right file basename in a variable\n",
    "            asn2_fppos1_name = memname.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a slightly different procedure to add a new exposure to the list rather than remove one. \n",
    "\n",
    "Here we will read the table in the FITS association file into an `astropy` Table. We can then add a row into the right spot, filling it with the new file's `MEMNAME`, `MEMTYPE`, and `MEMPRSNT`. Finally, we have to save this table into the existing FITS association file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.114814Z",
     "iopub.status.busy": "2025-09-17T22:02:11.114645Z",
     "iopub.status.idle": "2025-09-17T22:02:11.129476Z",
     "shell.execute_reply": "2025-09-17T22:02:11.128959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added LDIF02NMQ to the association file.\n"
     ]
    }
   ],
   "source": [
    "# Read in original data from the file\n",
    "asn_orig_table = Table.read(asnfile)\n",
    "\n",
    "# Add a row with the right name after all the original EXP-FP's\n",
    "asn_orig_table.insert_row(len(asn_orig_table) - 1,\n",
    "                          [asn2_fppos1_name, 'EXP-FP', 1])\n",
    "\n",
    "# Turn this into a FITS Binary Table HDU\n",
    "new_table = fits.BinTableHDU(asn_orig_table)\n",
    "\n",
    "# We need to change data with the asnfile opened and in 'update' mode\n",
    "with fits.open(asnfile, mode='update') as hdulist:\n",
    "    # Change the orig file's data to the new table data we made\n",
    "    hdulist[1].data = new_table.data\n",
    "\n",
    "print(f\"Added {asn2_fppos1_name} to the association file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see there is a new row with our exposure from the other `asn` file group: `LDIF02NMQ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.130899Z",
     "iopub.status.busy": "2025-09-17T22:02:11.130746Z",
     "iopub.status.idle": "2025-09-17T22:02:11.138147Z",
     "shell.execute_reply": "2025-09-17T22:02:11.137668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=6</i>\n",
       "<table id=\"table140084700321488\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF01TYQ</td><td>EXP-FP</td><td>0</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U2Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF02NMQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=6>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LDIF01TYQ         EXP-FP        0\n",
       "     LDIF01U0Q         EXP-FP        1\n",
       "     LDIF01U2Q         EXP-FP        1\n",
       "     LDIF01U4Q         EXP-FP        1\n",
       "     LDIF02NMQ         EXP-FP        1\n",
       "     LDIF01010        PROD-FP        1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(asnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4 \"><b>Excellent.</b> In the next section we will create a new association file from scratch.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = newAF></a>\n",
    "# 3. Creating an entirely new association file\n",
    "\n",
    "Users will rarely need to create an entirely new association file. Much more often, they should alter an existing one found on MAST. However, a user may wish to create a new association file if they are combining altered exposures, perhaps after using the [`costools.splittag` tool](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/SplitTag/SplitTag.ipynb). This section describes how to make one from scratch.\n",
    "\n",
    "For the sake of demonstration, we will generate a new association file with four exposure members: even-numbered `FP-POS` (2,4) from the first original association (`LDIF01010`), and odd-numbered `FP-POS` (1,3) from from the second original association (`LDIF02010`).\n",
    "\n",
    "From [Section 2](editAF), we see that this corresponds to :\n",
    "\n",
    "|Name|Original asn|FP-POS|\n",
    "|----|------------|------|\n",
    "|LDIF02010|LDIF02NMQ|1|\n",
    "|LDIF01010|LDIF01U0Q|2|\n",
    "|LDIF02010|LDIF02NUQ|3|\n",
    "|LDIF01010|LDIF01U4Q|4|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = simpleAF></a>\n",
    "## 3.1. Simplest method\n",
    "Below, we manually build up an association file from the three necessary columns (`MEMNAME`, `MEMTYPE`, `MEMPRSNT`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.139596Z",
     "iopub.status.busy": "2025-09-17T22:02:11.139428Z",
     "iopub.status.idle": "2025-09-17T22:02:11.147973Z",
     "shell.execute_reply": "2025-09-17T22:02:11.147587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ldifcombo_asn.fits in the output directory: output\n"
     ]
    }
   ],
   "source": [
    "# Adding the exposure file details to the association table\n",
    "# MEMNAME:\n",
    "new_asn_memnames = ['LDIF02NMQ', 'LDIF01U0Q', 'LDIF02NUQ', 'LDIF01U4Q']\n",
    "# MEMTYPE:\n",
    "types = ['EXP-FP', 'EXP-FP', 'EXP-FP', 'EXP-FP']\n",
    "# MEMPRSNT\n",
    "included = [True, True, True, True]\n",
    "\n",
    "# Adding the ASN details to the end of the association table\n",
    "# MEMNAME column:\n",
    "new_asn_memnames.append('ldifcombo'.upper())\n",
    "# MEMTYPE column:\n",
    "types.append('PROD-FP')\n",
    "# MEMPRSNT column\n",
    "included.append(True)\n",
    "\n",
    "# Putting together the FITS table:\n",
    "#   40 is the number of characters allowed in this\n",
    "#   field with the MEMNAME format = 40A. If your rootname\n",
    "#   is longer than 40, you will need to increase this.\n",
    "c1 = fits.Column(name='MEMNAME',\n",
    "                 array=np.array(new_asn_memnames),\n",
    "                 format='40A')\n",
    "\n",
    "c2 = fits.Column(name='MEMTYPE',\n",
    "                 array=np.array(types),\n",
    "                 format='14A')\n",
    "\n",
    "c3 = fits.Column(name='MEMPRSNT',\n",
    "                 format='L',\n",
    "                 array=included)\n",
    "\n",
    "asn_table = fits.BinTableHDU.from_columns([c1, c2, c3])\n",
    "\n",
    "# Writing the fits table\n",
    "asn_table.writeto(outputdir / 'ldifcombo_asn.fits', overwrite=True)\n",
    "\n",
    "print('Saved ' + 'ldifcombo_asn.fits'\n",
    "      + f\" in the output directory: {outputdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examining the file we have created:**\n",
    "\n",
    "We see that the data looks correct - exactly the table we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.149328Z",
     "iopub.status.busy": "2025-09-17T22:02:11.149174Z",
     "iopub.status.idle": "2025-09-17T22:02:11.155849Z",
     "shell.execute_reply": "2025-09-17T22:02:11.155436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=5</i>\n",
       "<table id=\"table140084698441168\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes40</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF02NMQ</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIF02NUQ</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIFCOMBO</td><td>PROD-FP</td><td>True</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       " MEMNAME  MEMTYPE MEMPRSNT\n",
       " bytes40  bytes14   bool  \n",
       "--------- ------- --------\n",
       "LDIF02NMQ  EXP-FP     True\n",
       "LDIF01U0Q  EXP-FP     True\n",
       "LDIF02NUQ  EXP-FP     True\n",
       "LDIF01U4Q  EXP-FP     True\n",
       "LDIFCOMBO PROD-FP     True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(outputdir / 'ldifcombo_asn.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, the 0th and 1st fits headers no longer contain useful information about the data.**\n",
    "While `CalCOS` will process these files, vital header keys may not be propagated. If it's important to preserve the header information, you may follow the steps in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.157242Z",
     "iopub.status.busy": "2025-09-17T22:02:11.157093Z",
     "iopub.status.idle": "2025-09-17T22:02:11.160945Z",
     "shell.execute_reply": "2025-09-17T22:02:11.160543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIMPLE  =                    T / conforms to FITS standard                      \n",
       "BITPIX  =                    8 / array data type                                \n",
       "NAXIS   =                    0 / number of array dimensions                     \n",
       "EXTEND  =                    T                                                  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits.getheader(outputdir / 'ldifcombo_asn.fits', ext=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.162331Z",
     "iopub.status.busy": "2025-09-17T22:02:11.162180Z",
     "iopub.status.idle": "2025-09-17T22:02:11.166275Z",
     "shell.execute_reply": "2025-09-17T22:02:11.165909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XTENSION= 'BINTABLE'           / binary table extension                         \n",
       "BITPIX  =                    8 / array data type                                \n",
       "NAXIS   =                    2 / number of array dimensions                     \n",
       "NAXIS1  =                   55 / length of dimension 1                          \n",
       "NAXIS2  =                    5 / length of dimension 2                          \n",
       "PCOUNT  =                    0 / number of group parameters                     \n",
       "GCOUNT  =                    1 / number of groups                               \n",
       "TFIELDS =                    3 / number of table fields                         \n",
       "TTYPE1  = 'MEMNAME '                                                            \n",
       "TFORM1  = '40A     '                                                            \n",
       "TTYPE2  = 'MEMTYPE '                                                            \n",
       "TFORM2  = '14A     '                                                            \n",
       "TTYPE3  = 'MEMPRSNT'                                                            \n",
       "TFORM3  = 'L       '                                                            "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits.getheader(outputdir / 'ldifcombo_asn.fits', ext=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = metaAF></a>\n",
    "## 3.2. With FITS header metadata\n",
    "\n",
    "**We can instead build up a new file with our old file's FITS header, and alter it to reflect our changes.**\n",
    "\n",
    "We first build a new association file, a piecewise combination of our original file's headers and our new table. \n",
    "\n",
    "A FITS header is essentially a section of data and its associated metadata. See [this site](https://fits.gsfc.nasa.gov/fits_primer.html) for info on FITS structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.167651Z",
     "iopub.status.busy": "2025-09-17T22:02:11.167485Z",
     "iopub.status.idle": "2025-09-17T22:02:11.177376Z",
     "shell.execute_reply": "2025-09-17T22:02:11.177007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: data/ldif01010_asn.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      43   ()      \n",
      "  1  ASN           1 BinTableHDU     24   6R x 3C   [14A, 14A, L]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved ldifcombo_2_asn.fitsin the output directory: output\n"
     ]
    }
   ],
   "source": [
    "# Open up the old asn file\n",
    "with fits.open(asnfile, mode='readonly') as hdulist:\n",
    "    # Shows the first hdu is empty except for the header we want\n",
    "    hdulist.info()\n",
    "    # We want to directly copy over the old 0th header/data-unit AKA \"hdu\".\n",
    "    hdu0 = hdulist[0]\n",
    "    # Gather the data from the header/data unit to allow the readout\n",
    "    d0 = hdulist[0].data\n",
    "    # Gather the header from the 1st header/data unit to copy to our new file\n",
    "    h1 = hdulist[1].header\n",
    "\n",
    "# Put together new 1st hdu from old header and new data\n",
    "hdu1 = fits.BinTableHDU.from_columns([c1, c2, c3],\n",
    "                                     header=h1)\n",
    "\n",
    "# New HDUList from old HDU 0 and new combined HDU 1\n",
    "new_HDUlist = fits.HDUList([hdu0, hdu1])\n",
    "\n",
    "# Write this out to a new file\n",
    "new_HDUlist.writeto(outputdir / 'ldifcombo_2_asn.fits',\n",
    "                    overwrite=True)\n",
    "# Path to this new file\n",
    "new_asnfile = outputdir / 'ldifcombo_2_asn.fits'\n",
    "\n",
    "print('\\nSaved ' + 'ldifcombo_2_asn.fits'\n",
    "      + f\"in the output directory: {outputdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we edit the relevant values in our FITS headers that are different from the original.**\n",
    "\n",
    "*Note: It is possible that a generic FITS file may have different values you may wish to change. It is highly recommended to examine your FITS headers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.178793Z",
     "iopub.status.busy": "2025-09-17T22:02:11.178653Z",
     "iopub.status.idle": "2025-09-17T22:02:11.203573Z",
     "shell.execute_reply": "2025-09-17T22:02:11.203078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Editing DATE in Extension 0\n",
      "Editing FILENAME in Extension 0\n",
      "Editing ROOTNAME in Extension 0\n",
      "Editing ROOTNAME in Extension 1\n",
      "Editing ASN_ID in Extension 0\n",
      "Editing ASN_TAB in Extension 0\n",
      "Editing ASN_PROD in Extension 0\n",
      "Editing EXTVER in Extension 1\n",
      "Editing EXPNAME in Extension 1\n"
     ]
    }
   ],
   "source": [
    "# Find today's date\n",
    "date = datetime.date.today()\n",
    "# Below, make a dict of what header values we want to change,\n",
    "# corresponding to [new value, ext. the value lives in, 2nd ext. if applies]\n",
    "keys_to_change = {'DATE': [f'{date.year}-{date.month}-{date.day}', 0],\n",
    "                  'FILENAME': ['ldifcombo_2_asn.fits', 0],\n",
    "                  'ROOTNAME': ['ldifcombo_2', 0, 1],\n",
    "                  'ASN_ID': ['ldifcombo_2', 0],\n",
    "                  'ASN_TAB': ['ldifcombo_2_asn.fits', 0],\n",
    "                  'ASN_PROD': ['False', 0],\n",
    "                  'EXTVER': [2, 1],\n",
    "                  'EXPNAME': ['ldifcombo_2', 1]}\n",
    "\n",
    "# Actually change the values below (verbosely):\n",
    "for keyval in keys_to_change.items():\n",
    "    print(f\"Editing {keyval[0]} in Extension {keyval[1][1]}\")\n",
    "    fits.setval(filename=new_asnfile,\n",
    "                keyword=keyval[0],\n",
    "                value=keyval[1][0],\n",
    "                ext=keyval[1][1])\n",
    "    \n",
    "    # Below is necessary as some keys are repeated in both headers ('ROOTNAME')\n",
    "    if len(keyval[1]) > 2:\n",
    "        print(f\"Editing {keyval[0]} in Extension {keyval[1][2]}\")\n",
    "        fits.setval(filename=new_asnfile,\n",
    "                    keyword=keyval[0],\n",
    "                    value=keyval[1][0],\n",
    "                    ext=keyval[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4 \"><b>And now we have created our new association file.</b> The file is now ready to be used in the <code>CalCOS</code> pipeline!</font>\n",
    "    \n",
    "If you're interested in testing your file by running it through the `CalCOS` pipeline, you may wish to run the `test_asn.py file` included in this subdirectory of the GitHub repository. i.e. from the command line: \n",
    "\n",
    "```bash\n",
    "$ python test_asn.py\n",
    "```\n",
    "*Note* that you must first...\n",
    "1. Have created the file by running this Notebook\n",
    "2. Alter line 21 of `test_asn.py` to set the lref directory to wherever you have your cache of CRDS reference files (see our [Setup Notebook](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/Setup/Setup.ipynb)).\n",
    "\n",
    "If the test runs successfully, it will create a plot in the subdirectory `./output/plots/` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = nontagAF></a>\n",
    "## 3.3. Association files for non-TAGFLASH datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As touched upon in [Section 2.1.2.](#removefiltAF), most COS exposures contain the calibration lamp data necessary to perform wavelength calibration; however, exposures taken at LP6 and those taken with [AUTO and GO wavecals](https://hst-docs.stsci.edu/cosihb/chapter-5-spectroscopy-with-cos/5-7-internal-wavelength-calibration-exposures#id-5.7InternalWavelengthCalibrationExposures-Section5.7.25.7.2AUTOWavecals(whenTAGFLASHisnotused)) (including BOA and ACCUM mode exposures) have separate exposures for wavelength calibration. Table 1 below summarizes the types of wavelength calibration modes. More information may be found in [Section 5.7 of the COS Instrument Handbook](https://hst-docs.stsci.edu/cosihb/chapter-5-spectroscopy-with-cos/5-7-internal-wavelength-calibration-exposures).\n",
    "\n",
    "#### Table 1. Comparison of wavelength calibration modes\n",
    "\n",
    "|**Wavelength calibration mode**||`TAGFLASH`|`SPLIT` Wavecal|`AUTO` Wavecal|GO Wavecal|\n",
    "|-|-|-|-|-|-|\n",
    "|**When used**||Default for LP1-LP5|Default for LP6|Used for LP1-LP5 non-TAGFLASH exposures|User specified (rare)|\n",
    "|**Description**||Wavelength calibration lamp flashes concurrently with science exposure|Wavelength calibration lamp flashes at another LP|Wavelength calibration lamp flashes separately from science exposure|Wavelength calibration lamp flashes separately from science exposure|\n",
    "|**Additional wavelength calibration file in the association table**||None - wavelength calibration data included in the `EXP-FP`s of the science exposures|`EXP-SWAVE`|`EXP-AWAVE`|`EXP-GWAVE`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-`TAGFLASH` datasets must be processed from a single association file which includes all the science and wavelength calibration exposures, properly labeled with the correct `MEMTYPE`s.\n",
    "\n",
    "Users will rarely need to build an entirely new association file for non-TAGFLASH datasets. The most common reason for a user to have non-TAGFLASH data is that the exposures were obtained using the `SPLIT` wavecal method at LP6. The association files for these files are correctly created and made available in the MAST archive. Removing specific exposures can most easily be done as in [Section 2.1.2](#212-filtering-to-a-single-exposure-eg-for-lp6-data). However, if a user needed to craft a completely customized `CalCOS` run, for instance to combine multiple non-TAGFLASH datasets, they can follow this section.\n",
    "\n",
    "In this section we will manually recreate the association file for the `SPLIT` wavecal data from the same dataset whose association file we altered as part of [Section 2.1.2](#removefiltAF). We could just as easily do so with `AUTO` or GO wavecal data. We will first select and examine the relevant exposures, then we will combine them into an association file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 331-gathering-the-exposure-informationAF></a>\n",
    "### 3.3.1. Gathering the exposure information\n",
    "We begin by downloading the data from a visit which utilized COS' LP6 split wavecal mode (proposal ID: `16907`, observation ID: `letc01010`). We previously downloaded the association file for this dataset in [Section 2.1.2](#removefiltAF), but here we download the rest of the data products we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:11.205060Z",
     "iopub.status.busy": "2025-09-17T22:02:11.204914Z",
     "iopub.status.idle": "2025-09-17T22:02:19.233744Z",
     "shell.execute_reply": "2025-09-17T22:02:19.233324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01lmq_rawtag_a.fits to data/mastDownload/HST/letc01lmq/letc01lmq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01lmq_rawtag_b.fits to data/mastDownload/HST/letc01lmq/letc01lmq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01loq_rawtag_a.fits to data/mastDownload/HST/letc01loq/letc01loq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01loq_rawtag_b.fits to data/mastDownload/HST/letc01loq/letc01loq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01lrq_rawtag_a.fits to data/mastDownload/HST/letc01lrq/letc01lrq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01lrq_rawtag_b.fits to data/mastDownload/HST/letc01lrq/letc01lrq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01ltq_rawtag_a.fits to data/mastDownload/HST/letc01ltq/letc01ltq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01ltq_rawtag_b.fits to data/mastDownload/HST/letc01ltq/letc01ltq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01lwq_rawtag_a.fits to data/mastDownload/HST/letc01lwq/letc01lwq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01lwq_rawtag_b.fits to data/mastDownload/HST/letc01lwq/letc01lwq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01m1q_rawtag_a.fits to data/mastDownload/HST/letc01m1q/letc01m1q_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01m1q_rawtag_b.fits to data/mastDownload/HST/letc01m1q/letc01m1q_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01m6q_rawtag_a.fits to data/mastDownload/HST/letc01m6q/letc01m6q_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01m6q_rawtag_b.fits to data/mastDownload/HST/letc01m6q/letc01m6q_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01mtq_rawtag_a.fits to data/mastDownload/HST/letc01mtq/letc01mtq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01mtq_rawtag_b.fits to data/mastDownload/HST/letc01mtq/letc01mtq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01mvq_rawtag_a.fits to data/mastDownload/HST/letc01mvq/letc01mvq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01mvq_rawtag_b.fits to data/mastDownload/HST/letc01mvq/letc01mvq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01mxq_rawtag_a.fits to data/mastDownload/HST/letc01mxq/letc01mxq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01mxq_rawtag_b.fits to data/mastDownload/HST/letc01mxq/letc01mxq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01mzq_rawtag_a.fits to data/mastDownload/HST/letc01mzq/letc01mzq_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01mzq_rawtag_b.fits to data/mastDownload/HST/letc01mzq/letc01mzq_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01n1q_rawtag_a.fits to data/mastDownload/HST/letc01n1q/letc01n1q_rawtag_a.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/letc01n1q_rawtag_b.fits to data/mastDownload/HST/letc01n1q/letc01n1q_rawtag_b.fits ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Done]\n"
     ]
    }
   ],
   "source": [
    "# Search for the correct obs_ids and get the list of data products\n",
    "lp6_observation_products = Observations.get_product_list(\n",
    "                                    Observations.query_criteria(\n",
    "                                        obs_id='letc01010'),\n",
    ")\n",
    "\n",
    "# Filter & download the rawtag files and asn file in the product list from MAST\n",
    "# First filter to just the rawtag products\n",
    "lp6_rawtags_pl = Observations.filter_products(\n",
    "                    lp6_observation_products,\n",
    "                    productSubGroupDescription=['RAWTAG_A', 'RAWTAG_B'])\n",
    "\n",
    "# Download these chosen rawtag products\n",
    "lp6_rawtags = Observations.download_products(\n",
    "                                    lp6_rawtags_pl,\n",
    "                                    download_dir=str(datadir))['Local Path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by taking a look at the original association file from MAST in the cell below. Note that the exposures are ordered in groups of a single `EXP-FP` (also known as science or `EXTERNAL/SCI`) exposure bracketed on both sides by an `EXP-SWAVE` (`SPLIT` wavecal) exposure (i.e. `WAVECAL`--> `SCIENCE` --> `WAVECAL`). This is often the case for non-`TAGFLASH` files, especially for exposures longer than ~600 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:19.235248Z",
     "iopub.status.busy": "2025-09-17T22:02:19.235098Z",
     "iopub.status.idle": "2025-09-17T22:02:19.243095Z",
     "shell.execute_reply": "2025-09-17T22:02:19.242676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=13</i>\n",
       "<table id=\"table140084698259984\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LETC01LMQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01LOQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LETC01LRQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01LTQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01LWQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LETC01M1Q</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01M6Q</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01MTQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LETC01MVQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01MXQ</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01MZQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LETC01N1Q</td><td>EXP-SWAVE</td><td>1</td></tr>\n",
       "<tr><td>LETC01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=13>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LETC01LMQ      EXP-SWAVE        1\n",
       "     LETC01LOQ         EXP-FP        1\n",
       "     LETC01LRQ      EXP-SWAVE        1\n",
       "     LETC01LTQ      EXP-SWAVE        1\n",
       "     LETC01LWQ         EXP-FP        1\n",
       "     LETC01M1Q      EXP-SWAVE        1\n",
       "     LETC01M6Q      EXP-SWAVE        1\n",
       "     LETC01MTQ         EXP-FP        1\n",
       "     LETC01MVQ      EXP-SWAVE        1\n",
       "     LETC01MXQ      EXP-SWAVE        1\n",
       "     LETC01MZQ         EXP-FP        1\n",
       "     LETC01N1Q      EXP-SWAVE        1\n",
       "     LETC01010        PROD-FP        1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(lp6_original_asnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll simulate an occasion on which we would need to create our own association file by supposing we want to process only data from this observation taken in the `FP-POS = 1` or `FP-POS = 3` configuration. We could achieve the same result by taking the default association file from MAST and turning the `MEMPRSNT` value to False for all the `FP-POS = 2` and `FP-POS = 4` files, similarly to in [Section 2.1.2](#removefiltAF).\n",
    "\n",
    "Below, we filter to such exposures and check whether they meet our expectations for `SPLIT` wavecal data. Namely, we check that:\n",
    "1. The files are listed in chronological order.\n",
    "2. All science (`EXTERNAL/SCI`) exposures are bracketed by a `WAVECAL` exposure on either side.\n",
    "3. The data is organized into groups of 3 exposures with the grouping described in test 2 (`WAVECAL`-->`EXTERNAL/SCI`-->`WAVECAL`).\n",
    "\n",
    "`CalCOS` does not strictly need the files to be arranged in chronological order; however, it is a helpful exercise to make sure we include all the files we need to calibrate this dataset. We can investigate the files manually and diagnose any failures in the table printed by the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:19.244714Z",
     "iopub.status.busy": "2025-09-17T22:02:19.244559Z",
     "iopub.status.idle": "2025-09-17T22:02:19.299286Z",
     "shell.execute_reply": "2025-09-17T22:02:19.298814Z"
    },
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed Test #1: The exposures are in chronological order.\n",
      "Passed Test #2: Each EXTERNAL/SCI is bracketted on both sides by a WAVECAL exposure.\n",
      "Passed Test #3: No unexpected groupings of files were found.\n"
     ]
    }
   ],
   "source": [
    "# Filter the rawtag files to exposures at FP1 and FP3\n",
    "lp6_rawtags_fp13 = [rt for rt in lp6_rawtags\n",
    "                    if fits.getval(rt, \"FPPOS\", ext=0) in [1, 3]]\n",
    "\n",
    "# Gather information on all the exposures\n",
    "rawtag_a_exptypes_dict = {rt: fits.getval(rt, \"EXPTYPE\", ext=0)\n",
    "                          for rt in lp6_rawtags_fp13 if \"rawtag_a\" in rt}\n",
    "\n",
    "rawtag_a_rootnames = [fits.getval(rt, \"ROOTNAME\", ext=0)\n",
    "                      for rt in lp6_rawtags_fp13 if \"rawtag_a\" in rt]\n",
    "\n",
    "rawtag_a_exptypes = [fits.getval(rt, \"EXPTYPE\", ext=0)\n",
    "                     for rt in lp6_rawtags_fp13 if \"rawtag_a\" in rt]\n",
    "\n",
    "rawtag_a_expstart_times = [fits.getval(rt, \"EXPSTART\", ext=1)\n",
    "                           for rt in lp6_rawtags_fp13 if \"rawtag_a\" in rt]\n",
    "\n",
    "# Test 1\n",
    "# Check chronological sorting\n",
    "assert all(np.diff(rawtag_a_expstart_times) >= 0), \"These exposures are not ordered by start time.\"\n",
    "print(\"Passed Test #1: The exposures are in chronological order.\")\n",
    "\n",
    "# Test 2\n",
    "# Check science exposures are bracketed by wavecals\n",
    "for i, rta_type in enumerate(rawtag_a_exptypes):\n",
    "    if rta_type == \"EXTERNAL/SCI\":\n",
    "        assert rawtag_a_exptypes[i-1] == \"WAVECAL\", \"EXTERNAL/SCI exposure not preceded by a WAVECAL exposure\"\n",
    "        assert rawtag_a_exptypes[i+1] == \"WAVECAL\", \"EXTERNAL/SCI exposure not followed by a WAVECAL exposure\"\n",
    "print(\"Passed Test #2: Each EXTERNAL/SCI is bracketted on both sides by a WAVECAL exposure.\")\n",
    "\n",
    "# Test 3 \n",
    "# Check that only these groups of exposures exist (WAVECAL-->EXTERNAL/SCI-->WAVECAL)\n",
    "for group_of_3 in [rawtag_a_exptypes[3*i:3*i+3] for i in range(int(len(rawtag_a_exptypes)/3))]:\n",
    "    assert group_of_3 == ['WAVECAL', 'EXTERNAL/SCI', 'WAVECAL'], \"Incorrect groupings of exposures\"\n",
    "print(\"Passed Test #3: No unexpected groupings of files were found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we may inspect these files by eye, and see that they are indeed ordered correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:19.300742Z",
     "iopub.status.busy": "2025-09-17T22:02:19.300584Z",
     "iopub.status.idle": "2025-09-17T22:02:19.312694Z",
     "shell.execute_reply": "2025-09-17T22:02:19.312190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rootname</th>\n",
       "      <th>Exposure_type</th>\n",
       "      <th>Exposure_start_date</th>\n",
       "      <th>Seconds_since_first_exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LETC01LMQ</td>\n",
       "      <td>WAVECAL</td>\n",
       "      <td>59648.009183</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LETC01LOQ</td>\n",
       "      <td>EXTERNAL/SCI</td>\n",
       "      <td>59648.010537</td>\n",
       "      <td>116.991648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LETC01LRQ</td>\n",
       "      <td>WAVECAL</td>\n",
       "      <td>59648.019426</td>\n",
       "      <td>884.991744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LETC01M6Q</td>\n",
       "      <td>WAVECAL</td>\n",
       "      <td>59648.045549</td>\n",
       "      <td>3142.016352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LETC01MTQ</td>\n",
       "      <td>EXTERNAL/SCI</td>\n",
       "      <td>59648.065745</td>\n",
       "      <td>4887.007776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LETC01MVQ</td>\n",
       "      <td>WAVECAL</td>\n",
       "      <td>59648.074634</td>\n",
       "      <td>5655.007872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rootname Exposure_type  Exposure_start_date  Seconds_since_first_exposure\n",
       "0  LETC01LMQ       WAVECAL         59648.009183                      0.000000\n",
       "1  LETC01LOQ  EXTERNAL/SCI         59648.010537                    116.991648\n",
       "2  LETC01LRQ       WAVECAL         59648.019426                    884.991744\n",
       "3  LETC01M6Q       WAVECAL         59648.045549                   3142.016352\n",
       "4  LETC01MTQ  EXTERNAL/SCI         59648.065745                   4887.007776\n",
       "5  LETC01MVQ       WAVECAL         59648.074634                   5655.007872"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Rootname\": [name.upper() for name in rawtag_a_rootnames], \n",
    "    \"Exposure_type\": rawtag_a_exptypes,\n",
    "    # Date in MJD\n",
    "    \"Exposure_start_date\": rawtag_a_expstart_times,\n",
    "    \"Seconds_since_first_exposure\": \\\n",
    "    # Convert time since the first exposure into seconds\n",
    "    86400*np.subtract(rawtag_a_expstart_times, min(rawtag_a_expstart_times))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are sure that the correct exposures are selected, we gather the information we need for an association table:\n",
    "* The exposure ID (`ROOTNAME`) of each exposure.\n",
    "  * When capitalized, this is the same as the `MEMNAME` we find in association files.\n",
    "* The exposure type (`EXPTYPE`) of each exposure.\n",
    "  * We will need to convert from the way that exposure types are written in the FITS header to the way `CalCOS` will recognize them in the association file.\n",
    "\n",
    "To prevent duplication, we only gather this information from either the `rawtag_a` or `rawtag_b` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:19.314231Z",
     "iopub.status.busy": "2025-09-17T22:02:19.314072Z",
     "iopub.status.idle": "2025-09-17T22:02:19.328996Z",
     "shell.execute_reply": "2025-09-17T22:02:19.328474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered exposure information for creating a new non-TAGFLASH association file.\n"
     ]
    }
   ],
   "source": [
    "# Choose either rawtag_a (default) of rawtag_b files if no rawtag_a files found\n",
    "if any([\"rawtag_a\" in rt for rt in lp6_rawtags_fp13]):\n",
    "    seg_found = \"a\"\n",
    "elif any([\"rawtag_b\" in rt for rt in lp6_rawtags_fp13]):\n",
    "    seg_found = \"b\"\n",
    "else:\n",
    "    print(\"Neither rawtag_a nor rawtag_b found.\")\n",
    "\n",
    "lp6_fp13_memnames = [fits.getval(rt, \"ROOTNAME\", ext=0).upper()\n",
    "                     for rt in lp6_rawtags_fp13 if f\"rawtag_{seg_found}\" in rt]\n",
    "\n",
    "lp6_fp13_exptypes = [fits.getval(rt, \"EXPTYPE\", ext=0)\n",
    "                     for rt in lp6_rawtags_fp13 if f\"rawtag_{seg_found}\" in rt]\n",
    "\n",
    "# We need to change the wavecals' MEMTYPE to \"EXP-SWAVE\"\n",
    "# and the sciences' to \"EXP-FP\":\n",
    "lp6_fp13_exptypes = [\n",
    "    \"EXP-SWAVE\" if etype == \"WAVECAL\"\n",
    "    else \"EXP-FP\" if etype == \"EXTERNAL/SCI\"\n",
    "    else None for etype in lp6_fp13_exptypes\n",
    "]\n",
    "print(\"Gathered exposure information for creating a new non-TAGFLASH association file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 332-creating-the-split-wavecal-association-fileAF></a>\n",
    "### 3.3.2. Creating the `SPLIT` wavecal association file\n",
    "Now that we've gathered `MEMNAME`s and `MEMTYPE`s of our exposures, we can create the association file. This very closely mirrors [Section 3.2](#32-with-fits-header-metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:19.330368Z",
     "iopub.status.busy": "2025-09-17T22:02:19.330217Z",
     "iopub.status.idle": "2025-09-17T22:02:19.341948Z",
     "shell.execute_reply": "2025-09-17T22:02:19.341552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: data/mastDownload/HST/letc01010/letc01010_asn.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      43   ()      \n",
      "  1  ASN           1 BinTableHDU     25   13R x 3C   [14A, 14A, L]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved splitwave_asn.fits in the output directory: output\n"
     ]
    }
   ],
   "source": [
    "# Adding the exposure file details to the association table\n",
    "# MEMNAME:\n",
    "new_asn_memnames = lp6_fp13_memnames\n",
    "# MEMTYPE\n",
    "types = lp6_fp13_exptypes\n",
    "# MEMPRSNT\n",
    "included = [True] * len(lp6_fp13_memnames)\n",
    "\n",
    "# Adding the output science product details to the\n",
    "# end of the association table columns:\n",
    "\n",
    "# MEMNAME column:\n",
    "new_asn_memnames.append('splitwave'.upper())\n",
    "# MEMTYPE column:\n",
    "types.append('PROD-FP')\n",
    "# MEMPRSNT column:\n",
    "included.append(True)\n",
    "\n",
    "# Convert the columns into a the necessary form for a FITS file\n",
    "c1 = fits.Column(name='MEMNAME',\n",
    "                 array=np.array(new_asn_memnames),\n",
    "                 format='40A')\n",
    "\n",
    "c2 = fits.Column(name='MEMTYPE',\n",
    "                 array=np.array(types),\n",
    "                 format='14A')\n",
    "\n",
    "c3 = fits.Column(name='MEMPRSNT',\n",
    "                 format='L',\n",
    "                 array=included)\n",
    "\n",
    "# Open up the old asn file:\n",
    "with fits.open(lp6_original_asnfile, mode='readonly') as hdulist:\n",
    "    # Shows the first hdu is empty except for the header we want\n",
    "    hdulist.info()\n",
    "    # We want to directly copy over the old 0th header/data-unit\n",
    "    hdu0 = hdulist[0]\n",
    "    # Gather the data from the header/data unit to allow the readout\n",
    "    d0 = hdulist[0].data\n",
    "    # Gather the header from the 1st header/data unit to copy to our new file\n",
    "    h1 = hdulist[1].header\n",
    "\n",
    "# Put together new 1st hdu from old header and new data\n",
    "hdu1 = fits.BinTableHDU.from_columns([c1, c2, c3],\n",
    "                                     header=h1)\n",
    "\n",
    "# New HDUList from old HDU 0 and new combined HDU 1\n",
    "new_HDUlist = fits.HDUList([hdu0, hdu1])\n",
    "\n",
    "# Write this out to a new file\n",
    "new_HDUlist.writeto(outputdir / 'splitwave_asn.fits', overwrite=True)\n",
    "# Path to this new file\n",
    "new_asnfile = outputdir / 'splitwave_asn.fits'\n",
    "\n",
    "print('\\nSaved ' + 'splitwave_asn.fits'\n",
    "      f\" in the output directory: {outputdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T22:02:19.343222Z",
     "iopub.status.busy": "2025-09-17T22:02:19.343085Z",
     "iopub.status.idle": "2025-09-17T22:02:19.350029Z",
     "shell.execute_reply": "2025-09-17T22:02:19.349644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=7</i>\n",
       "<table id=\"table140084697655632\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes40</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LETC01LMQ</td><td>EXP-SWAVE</td><td>True</td></tr>\n",
       "<tr><td>LETC01LOQ</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LETC01LRQ</td><td>EXP-SWAVE</td><td>True</td></tr>\n",
       "<tr><td>LETC01M6Q</td><td>EXP-SWAVE</td><td>True</td></tr>\n",
       "<tr><td>LETC01MTQ</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LETC01MVQ</td><td>EXP-SWAVE</td><td>True</td></tr>\n",
       "<tr><td>SPLITWAVE</td><td>PROD-FP</td><td>True</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=7>\n",
       " MEMNAME   MEMTYPE  MEMPRSNT\n",
       " bytes40   bytes14    bool  \n",
       "--------- --------- --------\n",
       "LETC01LMQ EXP-SWAVE     True\n",
       "LETC01LOQ    EXP-FP     True\n",
       "LETC01LRQ EXP-SWAVE     True\n",
       "LETC01M6Q EXP-SWAVE     True\n",
       "LETC01MTQ    EXP-FP     True\n",
       "LETC01MVQ EXP-SWAVE     True\n",
       "SPLITWAVE   PROD-FP     True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(outputdir/\"splitwave_asn.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done - you have now successfully created the association file you need to process your `SPLIT` wavecal data. If you wish to test it by running the `CalCOS` data calibration pipeline on it, you may run the file `test_splitwave_asn.py` in this directory. Note the following requirements: \n",
    "1. `test_splitwave_asn.py` can only be run after creating the `asn` files in Section 3.3 of this Notebook.\n",
    "2. Your version of `CalCOS` must be ≥ 3.4. This version introduced the ability to process `SPLIT` wavecal data to the pipeline. You can check your version with `calcos --version` from the command line.\n",
    "3. You must first update the `lref` environment variable set in `test_splitwave_asn.py` to the path to a directory containing all of your reference files. For more information on setting up such a directory, see [our Notebook on setting up an environment for COS data analysis](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/Setup/Setup.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You finished this Notebook!\n",
    "<font size=\"5\">There are more COS data walkthrough Notebooks on different topics. You can find them <a href=\"https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/COS\">here</a>.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## About this Notebook\n",
    "**Author:** Nat Kerman: <nkerman@stsci.edu>\n",
    "\n",
    "**Contributors:** Elaine Mae Frazer, Travis Fischer\n",
    "\n",
    "**Updated On:** 2023-03-27\n",
    "\n",
    "> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n",
    "\n",
    "## Citations\n",
    "\n",
    "If you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\n",
    "authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `astropy`](https://docs.astropy.org/en/stable/index.html)\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/)\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "<hr>\n",
    "\n",
    "[Top of Page](#topAF)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3.9.5 ('fs2')"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    },
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "3.9.5"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3 (ipykernel)"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    },
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "3.9.7"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  },
  "vscode": {
   "interpreter": {
    "hash": "e5784b3e3be4ffa319eb7c9e4ac489bbbf191ad109372c471204ed1d5c08c61e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
