{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8346a078",
   "metadata": {},
   "source": [
    "# Inputting User Data using the Hubble Advanced Spectral Products Script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d2e317b",
   "metadata": {},
   "source": [
    "### <span style=\"font-weight:normal\">This Notebook is designed to walk you through downloading and using the **[Hubble Advanced Spectral Products (HASP)](https://archive.stsci.edu/missions-and-data/hst/hasp)** co-add script.</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01e97a32",
   "metadata": {},
   "source": [
    "## Learning Goals: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad4bc17b",
   "metadata": {},
   "source": [
    "By the end of this tutorial, you will learn how to:\n",
    "- Setup a `conda` environment \n",
    "\n",
    "- Download the HASP wrapper script\n",
    "\n",
    "- Use `astroquery.mast` to download COS and STIS data\n",
    "\n",
    "- Run the co-add script\n",
    "\n",
    "- Examine the co-added output\n",
    "\n",
    "- Run the scipt with multiple threshold values and examine output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75d6e2e4",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "**0. [Introduction](#introduction)**\n",
    "\n",
    "**1. [Downloading HST Spectroscopic Data](#datadownload)**\n",
    "\n",
    "\\- 1.1 [Using `astroquery` to Download STIS Data](#stisdownload)\n",
    "\n",
    "**2. [Running the Co-add Script](#runscript)**\n",
    "\n",
    "**3. [Working with Co-added Data Products](#workwithoutput)**\n",
    "\n",
    "\\- 3.1 [Inspecting the Output Files](#inspectoutput)\n",
    "\n",
    "\\- 3.2 [Viewing Co-added STIS Data](#viewstis)\n",
    "\n",
    "\\- 3.3 [Putting it all together with COS Data](#cos)\n",
    "\n",
    "**4. [Downloading HASP Data Products](#download_prods)**\n",
    "\n",
    "\\- 4.1 [Downloading Data Products using `astroquery`](#hasp_query)\n",
    "\n",
    "**5. [Changing the Threshold Flag](#threshold)**\n",
    "\n",
    "\\- 5.1 [Using `Astroquery` to Download Additional Data](#downloadthresh)\n",
    "\n",
    "\\- 5.2 [Running the Co-add Script with Multiple Threshold Values](#threshscriptrun)\n",
    "\n",
    "\\- 5.3 [Analyzing the Co-added Spectra of Different Threshold Values](#analyzethresh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a73ce7ef",
   "metadata": {},
   "source": [
    "<a id = introduction></a>\n",
    "## 0. Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40af9618",
   "metadata": {},
   "source": [
    "The [Hubble Advanced Spectral Products (HASP) code](https://github.com/spacetelescope/hasp) is a script that co-adds spectra of the same target within programs. This software is able to co-add data taken with the spectrographs onboard the [Hubble Space Telescope (HST)](https://www.stsci.edu/hst); the [Space Telescope Imaging Spectrograph (STIS)](https://www.stsci.edu/hst/instrumentation/stis) and the [Cosmic Origins Spectrograph (COS)](https://www.stsci.edu/hst/instrumentation/cos). The [Hubble Spectroscopic Legacy Archive (HSLA)](https://archive.stsci.edu/missions-and-data/hst/hasp) uses this script to co-add these instrumentsâ€™ data from [The Mikulski Archive for Space Telescopes (MAST)](https://archive.stsci.edu/) to create high-quality spectra with a broad wavelength coverage (whenever possible from the ultraviolet to the near-infrared) that is publicly available for the scientific community. These custom co-addition notebooks will instruct users on how to produce their own co-adds in cases where the MAST archive data needs special processing or is rejected by the default filters used in the co-add script.\n",
    "\n",
    "The script first co-adds the observations for each grating for a given program, then it combines all gratings for the observation set. Finally, it co-adds the spectra of each observation set in the program to produce a fully co-added spectra for each target in a program. Please check out the [COS 2024-01 ISR](https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/cos/documentation/instrument-science-reports-isrs/_documents/ISR2024-01.pdf) for more information about HASP. \n",
    "\n",
    "This notebook will show users how to download data from MAST, run the co-add script, understand the output files and inspect the abutted data by plotting flux as a function of wavelength. It will also show users how to change the flux threshold flag.\n",
    "\n",
    "**Please check out our [Setup.ipynb](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP/Setup) notebook before running this tutorial to learn how to install and run the co-add code.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cbdc832",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "We will be using multiple libraries to retrieve and analyze data. We will use: \n",
    "* `Path.pathlib` to create product and data directories \n",
    "* `astroquery.mast Observations` to download COS and STIS data\n",
    "* `shutil` to perform directory and file operations\n",
    "* `os` to interact with the operating system\n",
    "* `astropy.io fits` to work with FITS files\n",
    "* `matplotlib.pyplot` to plot abutted spectra\n",
    "* `glob` to work with multiple files in our directories\n",
    "* `subprocesses` to run our script in the notebook with varying threshold flag values\n",
    "* `numpy` to help analyze our data\n",
    "* `scipy.interpolate interp1d` to interpolate our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5014b29e",
   "metadata": {},
   "source": [
    "We recommend creating a HASP-specific `conda` environment when co-adding spectra. You can checkout our [Setup.ipynb](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP/Setup) notebook to create such an environment. Alternatively, you can also download the required dependencies to run this notebook with the terminal command: \n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "This will download the dependencies that are necessary to run this current notebook. Let's import all of our packages that we will use in this notebook and print our `conda` environment by running the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from astroquery.mast import Observations\n",
    "import shutil\n",
    "import glob as glob\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "print(\"Currently active conda environment:\", os.environ.get(\"CONDA_PREFIX\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0386593",
   "metadata": {},
   "source": [
    "To do our tutorial, we will create data folders that will contain downloaded data from MAST (one for the STIS and the another for COS). We will also create products folders to contain the HASP script output, a.k.a the co-added spectra. We will have one folder for STIS and another for COS too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data download directories for COS and STIS\n",
    "stis_data_dir = Path(\"./stis_data/\")\n",
    "cos_data_dir = Path(\"./cos_data/\")\n",
    "\n",
    "# Creating the products directory to hold the output\n",
    "stis_products_dir = Path(\"./stis_products/\")\n",
    "cos_products_dir = Path(\"./cos_products/\")\n",
    "\n",
    "# If the directory doesn't exist, then create it\n",
    "stis_data_dir.mkdir(exist_ok=True)\n",
    "cos_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "stis_products_dir.mkdir(exist_ok=True)\n",
    "cos_products_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dd2dbfd",
   "metadata": {},
   "source": [
    "<a id = datadownload></a>\n",
    "## 1. Downloading HST Spectroscopic Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bdca358",
   "metadata": {},
   "source": [
    "Now that we have a `conda` environment created and the co-add code downloaded, we can start downloading data using `Observations` class from the Python package `astroquery.mast`. Here we will download two datasets, one taken with STIS and the other taken with COS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8734b09c",
   "metadata": {},
   "source": [
    "<a id = stisdownload></a>\n",
    "### 1.1 Using `Astroquery` to Download STIS Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0361f8f3",
   "metadata": {},
   "source": [
    "We will be downloading STIS data for the white dwarf [GD71](http://simbad.u-strasbg.fr/simbad/sim-id?Ident=GD+++71); this object is a well-known primary white dwarf standard. We will specifically download data from Program 7656, which has observations of GD71 using the gratings `G230L` and `G140L`.\n",
    "\n",
    "We can start with querying the MAST database for the STIS program's data. This will give us a list of *all* observations for the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1dbe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying the data on MAST for our target\n",
    "gd71_query = Observations.query_criteria(\n",
    "    proposal_id=7656,\n",
    "    target_name=\"GD71\",\n",
    "    dataproduct_type=\"SPECTRUM\",\n",
    "    provenance_name=\"CALSTIS\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a832e923",
   "metadata": {},
   "source": [
    "Now that we have queried the observations for Program 7656, we can get a list that contains the data products for these observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e229622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a product list for our query\n",
    "gd71_products = Observations.get_product_list(\n",
    "    gd71_query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36057da",
   "metadata": {},
   "source": [
    "Let's print out this list to see the associated data files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fda461",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gd71_products[\"productFilename\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01628f8c",
   "metadata": {},
   "source": [
    "As you can see, we have a very long list of different type of data products for our program. Luckily, we don't need all of these files to run the wrapper. We only need to download the following COS and/or STIS files:\n",
    "\n",
    "*    [X1D](https://hst-docs.stsci.edu/cosdhb/chapter-2-cos-data-files/2-4-cos-data-products#:~:text=in%20the%20association.-,One%2DDimensional%20Extracted%20Spectra%20(x1d%2C%20x1dsum),-The%20COS%20pipeline) - the one-dimensional extracted product spectra.\n",
    "  \n",
    "*    [SX1](https://hst-docs.stsci.edu/stisdhb/chapter-2-stis-data-structure/2-2-types-of-stis-files#:~:text=corrected%20imaging%20data.-,_sx1,-table) - the one-dimensional extracted spectra from combined or cosmic-ray rejected images. This file is only produced with STIS data. \n",
    "\n",
    "We will specify that we want to download *only* these files with the `productSubGroupDescription` parameter. We will also specify the directory that will contain the downloaded data products. Below, we download the STIS files for the progam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db084fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Observations.download_products(\n",
    "    gd71_products,\n",
    "    download_dir=str(stis_data_dir),\n",
    "    productSubGroupDescription=[\"X1D\", \"SX1\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fbab7e9",
   "metadata": {},
   "source": [
    "When we downloaded the data using `astroquery`, it created a directory `./stis_data/mastDownload/HST`, with separate folders for each different dataset ID. The script will need all of our newly downloaded data product files in a single directory, so we must move all STIS files to our `./stis_data` directory. We will create a function to consolidate our data, since we will be utilizing it for two additional datasets later on in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47537172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_files(data_path):\n",
    "    '''\n",
    "    Consolidate all files to single directory; necessary for HASP script run.\n",
    "    ---------------\n",
    "    Input:\n",
    "    str data_path : ./mastDownload/HST folders paths; files to be moved here\n",
    "    ---------------\n",
    "    Output:\n",
    "    None. Files moved to data_path. ./mastDownload/HST directory is deleted.\n",
    "    '''\n",
    "    # The path to all obs_id folders\n",
    "    mast_path = f\"{data_path}/mastDownload/HST/\"\n",
    "\n",
    "    try:\n",
    "        # Check if mastDownload exists\n",
    "        if not os.path.exists(mast_path):\n",
    "            print(f\"Directory {mast_path} doesn't exist.\")\n",
    "            return\n",
    "\n",
    "        # Get a list of the obs_id paths in mastDownload\n",
    "        obs_id_dirs = os.listdir(mast_path)\n",
    "\n",
    "        # Iterate through each obs_id folder and move the files\n",
    "        for obs_id in obs_id_dirs:\n",
    "            obs_id_path = os.path.join(mast_path, obs_id)\n",
    "            files = glob.glob(obs_id_path + \"/*fits\")\n",
    "\n",
    "            for file in files:\n",
    "                file_path = Path(file)\n",
    "                new_path = data_path / file_path.name\n",
    "                shutil.move(file, new_path)\n",
    "\n",
    "        # Now we can remove the mastDownload directory\n",
    "        if os.path.exists(mast_path):\n",
    "            shutil.rmtree(f\"{data_path}/mastDownload\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5703f0a",
   "metadata": {},
   "source": [
    "Now, using the function to move our STIS files to a single directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef219002",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidate_files(stis_data_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4f44372",
   "metadata": {},
   "source": [
    "Now we can run the co-add script!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cd6cbc4",
   "metadata": {},
   "source": [
    "<a id = runscript></a>\n",
    "## 2. Running the Co-add Script\n",
    "\n",
    "Now that we've downloaded the GD71 STIS data, we can run the co-add script. Currently, the co-add code abuts spectra for a single program. Run the script by using the next cell's command. \n",
    "\n",
    "**Note: Make sure that you are in the `hasp-env` `conda` environment that we created at the beginning of the [Setup.ipynb](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP/Setup) notebook.**\n",
    "\n",
    "The `-i` parameter is the input directory (i.e, where the FITS files are located). `-o` is the directory that will contain the newly created co-added products. Note that if you want to exclude certain data files from the co-add, you can just remove them from the input directory. There is more information about this (and the other flags) in our [Setup.ipynb](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP/Setup) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!swrapper -i ./stis_data -o ./stis_products"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a5dae88",
   "metadata": {},
   "source": [
    "We have now created the co-added products for Program 7656 using the wrapper!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ced371d0",
   "metadata": {},
   "source": [
    "<a id = workwithoutput></a>\n",
    "## 3. Working with Co-added Data Products"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37ae13cc",
   "metadata": {},
   "source": [
    "With the newly co-added files in the `./stis_products/output` directory, we can begin to inspect the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13a8116e",
   "metadata": {},
   "source": [
    "<a id = inspectoutput></a>\n",
    "### 3.1 Understanding the Output Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e368a5c",
   "metadata": {},
   "source": [
    "**_The following information about the output file naming conventions is in our [Setup.ipynb](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP/Setup) notebook. If you're already familiar with this, you can skip to [Section 4.2](viewstis), where we view our co-added spectra._** \n",
    "\n",
    "Let's look at the `./stis_products/output` directory to look at the newly abutted spectra. Currently, the script outputs abutted products for a single program.\n",
    "\n",
    "The script produces multiple different files with abutted spectra. Currently, the script outputs abutted products for a single program. It first creates co-added spectra for each grating of a single observation set:\n",
    "\n",
    "`hst_programID_instrument_targetname_grating_obset_cspec.fits`\n",
    "\n",
    "It then co-adds the spectra of all gratings for a single observation set:\n",
    "\n",
    "`hst_programID_instrument_targetname_allGratings_obset_cspec.fits`\n",
    "\n",
    "Finally, it co-adds all abutted observation sets' spectra to create a final co-added product for a single target:\n",
    "\n",
    "`hst_programID_instrument_targetname_allGratings_cspec.fits`\n",
    "\n",
    "An example of this is below. These filenames are the output files for our STIS GD71 dataset that is co-added in this notebook. Here, the `programID` is `7656`, the `instrument` is `STIS`, and the `targetname` is `gd71`.\n",
    "\n",
    "| Step | Filename | Description |\n",
    "|----------|----------|----------|\n",
    "| 1 | `hst_7656_stis_gd71_g140l_o4a520_cspec.fits` | Co-adding all `G140L` observations for the observation set, `O4A520`. |\n",
    "| 2 | `hst_7656_stis_gd71_g140l-g230l-g430l-g750l_o4a520_cspec.fits` | Co-adding all observations taken at every grating for the observation set, `O4A520`. |\n",
    "| 3 | `hst_7656_stis_gd71_g140l-g230l-g430l-g750l_o4a5_cspec.fits` | Co-adding all GD71 observations at each grating for this program, `O4A5`. |\n",
    "\n",
    "***Note: HST file naming conventions use a combination of three letters and/or numbers to have a unique association between a PI's proposal ID and program ID, meaning that `o4a5` at the end of `hst_7656_stis_gd71_g140l-g230l-g430l-g750l_o4a5_cspec.fits` is essentially the program ID for our example. Check out more information on the [MAST HST file naming convention page](https://archive.stsci.edu/hlsp/ipppssoot.html)*** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab5c5fc8",
   "metadata": {},
   "source": [
    "<a id = viewstis></a>\n",
    "### 3.2 Viewing the Co-added Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f588944",
   "metadata": {},
   "source": [
    "Let's take a look at the co-added spectra that we just created. We will create a plot of flux as a function of wavelength using `matplotlib.pyplot`.\n",
    "\n",
    "With the current version of the HASP script, the fully abutted filename should be:\n",
    "\n",
    "`hst_7656_stis_gd71_sg140l-sg230l-g430l-g750l_o4a5_cspec.fits`\n",
    "\n",
    "Double check your products folder to make sure the name of your fully co-added spectra is the same as above, otherwise the subsequent cells in this notebook will not run since the pathname won't exist. Update and run the cell below with the full co-add filename. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bae3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stis_coadd_filename = \"hst_7656_stis_gd71_sg140l-sg230l-g430l-g750l_o4a5_cspec.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2627f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(f\"./{stis_products_dir}/{stis_coadd_filename}\") as hdul:\n",
    "    # Getting the file's data\n",
    "    gd71_data = hdul[1].data\n",
    "\n",
    "    # Getting the wavelength and flux data for the abutted file\n",
    "    wavelength = gd71_data[\"WAVELENGTH\"]\n",
    "    flux = gd71_data[\"FLUX\"]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plotting the spectra\n",
    "    plt.scatter(wavelength, flux,\n",
    "                # Setting the size of the data points\n",
    "                s=1)\n",
    "\n",
    "    # Formatting the plot by adding titles\n",
    "    plt.title(\"STIS GD71, abutted\")\n",
    "    plt.xlabel(r'Wavelength [$\\AA$]')\n",
    "    plt.ylabel(r'Flux [$erg\\ s^{-1}\\ cm^{-2}\\ \\AA^{-1}$]')\n",
    "\n",
    "    # Saving the figure to the ./stis_products_dir\n",
    "    plt.savefig(f\"{stis_products_dir}/gd71_stis.png\")\n",
    "\n",
    "    # Showing the plot below\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17f9adc9",
   "metadata": {},
   "source": [
    "<a id = cos></a>\n",
    "### 3.3 Putting it all together with COS data\n",
    "\n",
    "Let's combine all of the STIS work from above and do another example, but this time using COS data instead of STIS. We will use the same target, GD71, and download the data from Program 11479. This has observations of GD71 using the gratings `G230L`, `G185M`, `G225M`, and `G285M`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ca5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying the COS data in MAST and getting the product list\n",
    "gd71_products = Observations.get_product_list(\n",
    "    Observations.query_criteria(\n",
    "        proposal_id=11479,\n",
    "        target_name=\"GD71\",\n",
    "        dataproduct_type=\"SPECTRUM\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Downloading the data to the ./cos_data directory\n",
    "Observations.download_products(\n",
    "    gd71_products,\n",
    "    download_dir=str(cos_data_dir),\n",
    "    productSubGroupDescription=[\"X1D\", \"SX1\"]\n",
    ")\n",
    "\n",
    "# Consolidating all of our files to a single directory\n",
    "consolidate_files(cos_data_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96356f2f",
   "metadata": {},
   "source": [
    "Now we run the wrapper script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!swrapper -i ./cos_data -o ./cos_products"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db592869",
   "metadata": {},
   "source": [
    "Similar to our STIS example, ensure that the filename is updated to the current HASP version by running and/or updating the next cell, then plot the newly abutted COS spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_coadd_filename = \"hst_11479_cos_gd71_cg230l-g185m-g225m-g285m_laad_cspec.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1eab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(f\"./{cos_products_dir}/{cos_coadd_filename}\") as hdul:\n",
    "    # Getting the file's data\n",
    "    gd71_data = hdul[1].data\n",
    "\n",
    "    # Getting the wavelength and flux data for the abutted file\n",
    "    wavelength = gd71_data[\"WAVELENGTH\"]\n",
    "    flux = gd71_data[\"FLUX\"]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plotting the spectra\n",
    "    plt.scatter(wavelength, flux,\n",
    "                s=1)\n",
    "\n",
    "    # Formatting the plot\n",
    "    plt.title(\"COS GD71, abutted\")\n",
    "    plt.xlabel(r'Wavelength [$\\AA$]')\n",
    "    plt.ylabel(r'Flux [$erg\\ s^{-1}\\ cm^{-2}\\ \\AA^{-1}$]')\n",
    "\n",
    "    # Saving the figure to ./cos_products\n",
    "    plt.savefig(f\"{cos_products_dir}/gd71_cos.png\")\n",
    "\n",
    "    # Showing the figure below\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "522bc972",
   "metadata": {},
   "source": [
    "We have now created and plotted the abutted COS spectra. Just for fun, let's compare the abutted STIS and COS products!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93974a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the COS and STIS data\n",
    "stis_hdul = fits.open(f\"{stis_products_dir}/{stis_coadd_filename}\")\n",
    "stis_data = stis_hdul[1].data\n",
    "\n",
    "cos_hdul = fits.open(f\"{cos_products_dir}/{cos_coadd_filename}\")\n",
    "cos_data = cos_hdul[1].data\n",
    "\n",
    "# Getting the flux and wavelengths for both files\n",
    "stis_wavelength = stis_data[\"WAVELENGTH\"]\n",
    "stis_flux = stis_data[\"FLUX\"]\n",
    "\n",
    "cos_wavelength = cos_data[\"WAVELENGTH\"]\n",
    "cos_flux = cos_data[\"FLUX\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting datapoints for STIS\n",
    "plt.scatter(stis_wavelength, stis_flux,\n",
    "            # Setting the size of the datapoints\n",
    "            s=1,\n",
    "            # Setting the color for the STIS datapoints\n",
    "            color=\"red\",\n",
    "            # Adding a label for the legend\n",
    "            label=\"STIS\")\n",
    "\n",
    "# Plotting the datapoints for COS\n",
    "plt.scatter(cos_wavelength, cos_flux,\n",
    "            s=1,\n",
    "            color=\"blue\",\n",
    "            label=\"COS\")\n",
    "\n",
    "# Formatting the plot by adding labels\n",
    "plt.title(\"STIS & COS GD71, abutted\")\n",
    "plt.xlabel(r'Wavelength [$\\AA$]')\n",
    "plt.ylabel(r'Flux [$erg\\ s^{-1}\\ cm^{-2}\\ \\AA^{-1}$]')\n",
    "\n",
    "# Adding a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# Saving the figure to our general directory\n",
    "plt.savefig(\"./gd71_cos_stis.png\")\n",
    "\n",
    "# Showing the plot below\n",
    "plt.show()\n",
    "\n",
    "stis_hdul.close()\n",
    "cos_hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b552a2d",
   "metadata": {},
   "source": [
    "<a id = download_prods></a>\n",
    "## 4. Downloading HASP Data Products\n",
    "\n",
    "As of January 2024, the HASP data products are available for download via `astroquery`. The products will also be available for query and download on the official HASP web search form (still a work in progress at the time of this notebook's publishing).\n",
    "\n",
    "Users can download coadded data themselves; we will show an example of this with a STIS coadd. \n",
    "\n",
    "<a id = hasp_query></a>\n",
    "### 4.1 Downloading Data Products using `astroquery`\n",
    "\n",
    "We can use `astroquery.mast`'s `Observations` module to download data products, similar to how we downloaded our STIS and COS data in [Section 1.1](#stisdownload) and [Section 3.3](#cos), respectively. Let's download GD71 coadds for the STIS example that we created in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b308273",
   "metadata": {},
   "outputs": [],
   "source": [
    "stis_query = Observations.query_criteria(\n",
    "    proposal_id=7656,\n",
    "    target_name=\"GD71\",\n",
    "    dataproduct_type=\"SPECTRUM\",\n",
    ")\n",
    "\n",
    "display(stis_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61c27d",
   "metadata": {},
   "source": [
    "We can see that our query returned a total of 11 datasets. We can see our HASP coadd is at the bottom of the table, with the value for `project` being `HASP` instead of `HST`. We will add these criteria to our query to isolate our product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "stis_query = Observations.query_criteria(\n",
    "    proposal_id=7656,\n",
    "    target_name=\"GD71\",\n",
    "    dataproduct_type=\"SPECTRUM\",\n",
    "    project=\"HASP\"\n",
    ")\n",
    "\n",
    "display(stis_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1837245",
   "metadata": {},
   "source": [
    "Now, let's see our product list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "stis_prodlist = Observations.get_product_list(\n",
    "    stis_query\n",
    ")\n",
    "\n",
    "# Print number of product files that can be downloaded\n",
    "print(f\"Number of files: {len(stis_prodlist)}\\n\")\n",
    "\n",
    "# Printing the entire product list\n",
    "stis_prodlist.pprint_include_names = (\"productFilename\", \"obs_id\", \"description\", \"productType\", \"productSubGroupDescription\", \"proposal_id\")\n",
    "\n",
    "display(stis_prodlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baea23b",
   "metadata": {},
   "source": [
    "We have 68 files that we can download for our dataset! There are many different file types, auxiliary files such as support (`SPT`), jitter (`JIT`), wavecal exposures (`WAV`), previews of the spectra in `.PNG` format, and our science files (to name a few). Note that the files with a `productSubGroupDescription` value not equal to `CSPEC` are files that are used by `CALSTIS` during data calibration (meaning they are not produced by the HASP coadd script). The science files consist of the `SX1` files which we downloaded when running the coadd script, and the actual coadds themselves (both intermediate and final). Let's just download the `Minimum Recommended Product` files after we create directories to store them by setting `mrp_only = True`. \n",
    "\n",
    "**Note that the minimum recommended product filetypes are different depending on if you are downloading a HASP dataset or a non-HASP dataset, e.g. HASP will not include the `SX1` files but downloading a science dataset would.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3507dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store our astroquery example STIS and COS data\n",
    "stis_astroquery = Path(\"./stis_astroquery/\")\n",
    "stis_astroquery.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4398dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the products to our new directory\n",
    "Observations.download_products(\n",
    "    stis_prodlist,\n",
    "    download_dir=str(stis_astroquery),\n",
    "    mrp_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all files to the stis_astroquery directory, rather than MAST's nested directories\n",
    "consolidate_files(stis_astroquery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb2563",
   "metadata": {},
   "source": [
    "We've downloaded the HASP products, so let's plot them now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# The name of the full coadd (same filename that we have in Section 3.2)\n",
    "stis_coadd_filename = \"hst_7656_stis_gd71_sg140l-sg230l-g430l-g750l_o4a5_cspec.fits\"\n",
    "stis_coadd_path = f\"./{stis_astroquery}/{stis_coadd_filename}\"\n",
    "\n",
    "full_coadd_hdul = fits.open(stis_coadd_path)\n",
    "\n",
    "# List of coadd files for a single grating (ignoring the full coadd above)\n",
    "grat_coadds = [f for f in glob.glob(f\"./{stis_astroquery}/*_o4a5_*\") if f != stis_coadd_path]\n",
    "\n",
    "# Starting to plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting the coadd for each grating\n",
    "for file in grat_coadds:\n",
    "    file_hdul = fits.open(file)\n",
    "    data = file_hdul[1].data\n",
    "    wl = data[\"WAVELENGTH\"].flatten()\n",
    "    flux = data[\"FLUX\"].flatten()\n",
    "\n",
    "    plt.plot(wl, flux,\n",
    "             lw=2,\n",
    "             label=file.split(\"/\")[-1])\n",
    "    \n",
    "    file_hdul.close()\n",
    "    \n",
    "# Plotting full coadd over the plot\n",
    "data = full_coadd_hdul[1].data\n",
    "\n",
    "wl = data[\"WAVELENGTH\"].flatten()\n",
    "flux = data[\"FLUX\"].flatten()\n",
    "\n",
    "plt.plot(wl, flux,\n",
    "         lw=1,\n",
    "         color=\"black\",\n",
    "         alpha=0.6,\n",
    "         label=\"Full Coadd\")\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title(\"STIS GD71 Coadd from Astroquery\")\n",
    "plt.xlabel(r'Wavelength [$\\AA$]')\n",
    "plt.ylabel(r'Flux [$erg\\ s^{-1}\\ cm^{-2}\\ \\AA^{-1}$]')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Setting ylimit to better show spectral features\n",
    "plt.ylim(0, 3e-12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "full_coadd_hdul.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96378986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the plot to save memory\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc8886",
   "metadata": {},
   "source": [
    "Click the rectangular box on the left hand side of the plot to zoom into specific portions of the plot -- you will be able to see each grating's caodd against the final full coadd. Cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e690d53",
   "metadata": {},
   "source": [
    "<a id = threshold></a>\n",
    "## 5. Changing the Threshold Flag\n",
    "\n",
    "The flux threshold flag is an optional flag that can be used to change the number of files that are co-added based on the flux of each spectra. When determining which files to abut, the script first creates a general co-add using all of the input files, and then iterates through each file to calculate the scaled median deviation. The script rejects a file if: \n",
    "\n",
    "$$\n",
    "\\left\\langle{\\frac{F_{x1d}(i) - F_{coadd(i)}}{\\sigma_{x1d}(i)}}\\right\\rangle{} < \\frac{C_{thresh}}{\\sqrt{N_{pix}}}\n",
    "$$\n",
    "\n",
    "In the equation, the median deviation from the co-add is $F_{x1d}(i) - F_{coadd(i)}$, the uncertainty per\n",
    "wavelength bin of the input spectrum is $\\sigma_{x1d}(i)$ and $N_{pix}$ is the number of wavelength bins for a given mode. Essentially, the scaled median deviation is the dispersion that quantifies the data quality (DQ) flag pixel spread for a spectrum that is less sensitive to outliers and size variations. The script will reject all files containing segments with scaled median deviation less than (i.e. more negative than) the threshold (the default is -50). For example, raising the threshold to -25 will abut less files than the default threshold of -50. Likewise, lowering the threshold to -100 will include more files in the dataset to be co-added. \n",
    "\n",
    "An important thing to note about changing the threshold is that including more files increases the SNR of your co-added spectra but decreases the flux accuracy. The threshold value may be altered if a user's science case is not dependent on the accuracy of a dataset's absolute flux. For example, if you have a large dataset of a bright target (i.e. a standard star), then you can lower the threshold to include more files in the abutment since the spread of data quality between each file is minimal. Conversely, if you have a dataset of a dim target, or a dataset with many poor observations, then you will want to raise the threshold to only include the best data out of the dataset.\n",
    "\n",
    "More information about the flux checking algorithm can be found in Section 2.3.2 of the [ISR COS 2024-01](https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/cos/documentation/instrument-science-reports-isrs/_documents/ISR2024-01.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373aaf58",
   "metadata": {},
   "source": [
    "<a id = downloadthresh></a>\n",
    "## 5.1 Downloading the Data\n",
    "\n",
    "We will first download an additional dataset to illustrate how the co-add code changes abutment when the threshold flag is changed. We will download data for the spectroscopic binary, [BD+17D4708](https://simbad.cds.unistra.fr/simbad/sim-coo?Coord=332.88126259897996+18.092873506782&CooFrame=FK5&CooEpoch=2000&CooEqui=2000&CooDefinedFrames=none&Radius=2&Radius.unit=arcmin&submit=submit+query&CoordList=) from Program 9631. We will run the script with three different threshold values: `t = -1, -2, -50`.\n",
    "\n",
    "First we will query and download the data using `Observations` from `astroquery.mast`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying out data from MAST\n",
    "bd_query = query = Observations.query_criteria(\n",
    "            proposal_id=9631,\n",
    "            target_name=\"BD+17D4708\",\n",
    "            dataproduct_type=\"SPECTRUM\",\n",
    "            provenance_name=[\"CALCOS\", \"CALSTIS\"]\n",
    "        )\n",
    "\n",
    "print(f\"The number of datasets queried is {str(len(bd_query))} datasets. \\\n",
    "      The query list is printed below:\")\n",
    "print(bd_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98752dde",
   "metadata": {},
   "source": [
    "Let's create a new directory and download our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725fec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data download directories\n",
    "bd_data_dir = Path(\"./bd_data/\")\n",
    "bd_products_dir = Path(\"./bd_products/\")\n",
    "\n",
    "# If the directory doesn't exist, then create it\n",
    "bd_data_dir.mkdir(exist_ok=True)\n",
    "bd_products_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cdc8c5",
   "metadata": {},
   "source": [
    "Now we get the product list and download our data to our directory `./bd_products`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb362b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the product list from our query\n",
    "bd_prod = Observations.get_product_list(\n",
    "            bd_query\n",
    "        )\n",
    "\n",
    "# Downloading the products, but only the necessary X1D and SX1 files\n",
    "Observations.download_products(\n",
    "            bd_prod,\n",
    "            download_dir=str(bd_data_dir),\n",
    "            productSubGroupDescription=[\"X1D\", \"SX1\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e922b85",
   "metadata": {},
   "source": [
    "<a id = threshscriptrun></a>\n",
    "## 5.2 Running the Co-add Script with Different Threshold Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2dc256",
   "metadata": {},
   "source": [
    "Let's first organize our data so that all data files are in a single directory instead of separate observation set directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8baffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidate_files(bd_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f72ec",
   "metadata": {},
   "source": [
    "Now that we've downloaded our data and organized it to be properly run by the script, we can run the code using different threshold values. Below is a function that runs the script using inputted threshold values, which will allow us to run the code in a single cell rather than multiple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c058e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_script(indir, outdir, thresh):\n",
    "    '''\n",
    "    Run the hasp wrapper script with different thresholds.\n",
    "    -------------------\n",
    "    Input:\n",
    "    str indir : Directory that holds all un-abutted data.\n",
    "    str outdir : Directory that will store output folders and files.\n",
    "    list thresh : List of threshold values used for script.\n",
    "    --------------------\n",
    "    Output:\n",
    "    Wrapper script is run using different threshold values.\n",
    "    A folder will be created for each value used, containing abutted products.\n",
    "    '''\n",
    "    # Looping through thresh vals to run through script\n",
    "    for val in thresh:\n",
    "        # Creating a folder for each thresh val\n",
    "        output = os.path.join(outdir, \"out\" + str(val))\n",
    "        if not os.path.exists(output):\n",
    "            os.mkdir(output)\n",
    "\n",
    "        print(f\"Running script where threshold = {str(val)}\")\n",
    "\n",
    "        # Specifying the arguments for the scipt\n",
    "        arguments = [\"-i\", indir, \"-o\", output, \"-t\", val]\n",
    "\n",
    "        # Creating a list composed of the script commands and arguments\n",
    "        command = [\"python\", \"-m\", \"hasp.wrapper\"] + arguments\n",
    "\n",
    "        # Running the script with the arguments above\n",
    "        subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78744d6d",
   "metadata": {},
   "source": [
    "Let's create a variable called `thresholds` that will consist of the different threshold values that we will use to help us visualize the relationship between number of files co-added and the final co-added product. We will run the script using each of these values.\n",
    "\n",
    "*Note: feel free to run the cells with more threshold values!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that the default value is t = -50\n",
    "thresholds = [\"-1\", \"-2\", \"-50\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1bc53",
   "metadata": {},
   "source": [
    "Let's run the script on our data now using the `run_script` function, using the thresholds defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_script(bd_data_dir, bd_products_dir, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b544942",
   "metadata": {},
   "source": [
    "<a id = analyzethresh></a>\n",
    "## 5.3 Analyzing the Different Co-added Spectra of Different Threshold Values\n",
    "\n",
    "Now that we've run the script on our dataset using differnet threshold values, we can start to analyze the differences between them. \n",
    "\n",
    "The `run_script` function created multiple folders for the abutted products; one folder for each threshold value (ex. `./out-50`). In each folder is the fully co-added spectra. At the time of this notebook, the fully co-added filename is:\n",
    "\n",
    "`hst_9631_stis_bdp17d4708_g230lb-g430l-g750l_o8h1_cspec.fits`\n",
    " \n",
    "Before you continue, make sure that the fully co-added filename is valid, as the filenaming structure may have changed since this notebook was published. Update and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_coadd_name = \"hst_9631_stis_bdp17d4708_g230lb-g430l-g750l_o8h1_cspec.fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55724aa8",
   "metadata": {},
   "source": [
    "We can see how many files were used in the co-add by running next the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8110dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through the threshold values\n",
    "for thresh in thresholds:\n",
    "    # Path to the co-added file\n",
    "    path_to_coadd = f\"{bd_products_dir}/out{thresh}/{bd_coadd_name}\"\n",
    "    coadd_hdul = fits.open(path_to_coadd)\n",
    "\n",
    "    # Opening the file to check num files, and printing\n",
    "    numfiles = len(coadd_hdul[2].data[\"FILENAME\"])\n",
    "\n",
    "    # Printing the number of files for the given threshold value\n",
    "    print(f\"The number of files co-added for t = {thresh} is {numfiles} files\")\n",
    "\n",
    "    coadd_hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1fbf98",
   "metadata": {},
   "source": [
    "As we can see, as we increase the threshold value (`t = -50` -> `t = -1`) we went from 12 files being used to only 6. Since we are using more data with the lower threshold (`t = -50`), we should see an increase in SNR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ef427",
   "metadata": {},
   "source": [
    "### Looking at SNR:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92731fa",
   "metadata": {},
   "source": [
    "We'll plot the SNR of both coadds below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bff131",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# A list of the the non-default thresholds used.\n",
    "nondefault_thresholds = [thresh for thresh in thresholds if thresh != \"-50\"]\n",
    "\n",
    "# List of colors to be used when plotting\n",
    "colors = ['blue',\n",
    "          'red']\n",
    "\n",
    "# Creating our figure: 1 column and len(thresholds) rows\n",
    "figure, ax = plt.subplots(len(nondefault_thresholds), 1,\n",
    "                          figsize=(10, 9))\n",
    "\n",
    "# Iterating through threshold values to compare their SNR to default output\n",
    "for i, thresh in enumerate(nondefault_thresholds):\n",
    "\n",
    "    # The SNR and wavelength data for the default threshold co-add output\n",
    "    default_path = f\"{bd_products_dir}/out-50/{bd_coadd_name}\"\n",
    "    default_hdul = fits.open(default_path)\n",
    "    data50 = default_hdul[1].data\n",
    "    wavelength50 = data50[\"WAVELENGTH\"]\n",
    "    snr50 = data50[\"SNR\"]\n",
    "\n",
    "    # Getting wavelength and SNR for the current iteration's threshold value\n",
    "    curr_path = f\"{bd_products_dir}/out{thresh}/{bd_coadd_name}\"\n",
    "    curr_hdul = fits.open(curr_path)\n",
    "    data = curr_hdul[1].data\n",
    "    wavelength = data[\"WAVELENGTH\"]\n",
    "    snr = data[\"SNR\"]\n",
    "\n",
    "    # This is the number of files used in the particular co-add\n",
    "    numfiles = len(fits.open(curr_path)[2].data[\"FILENAME\"])\n",
    "    numfiles_default = len(fits.open(default_path)[2].data[\"FILENAME\"])\n",
    "\n",
    "    ax[i].scatter(wavelength50, snr50,\n",
    "                  label=f\"t = -50, {numfiles_default} files co-added\",\n",
    "                  s=1,\n",
    "                  color=\"black\")\n",
    "\n",
    "    ax[i].scatter(wavelength, snr,\n",
    "                  label=f\"t = {thresh}, {numfiles} files co-added\",\n",
    "                  color=colors[i],\n",
    "                  s=1,\n",
    "                  alpha=0.4)\n",
    "\n",
    "    ax[i].legend()\n",
    "\n",
    "    # Highlighting the region of the plot with the biggest SNR change\n",
    "    ax[i].axvspan(3050, 5700,\n",
    "                  alpha=0.3,\n",
    "                  color=\"grey\")\n",
    "\n",
    "    # Adding formatting\n",
    "    ax[i].set_title(f\"SNR vs Wavelength for t = {thresh}, -50\",\n",
    "                    weight=\"bold\")\n",
    "    ax[i].set_xlabel(r'Wavelength [$\\AA$]')\n",
    "    ax[i].set_ylabel(\"SNR\")\n",
    "\n",
    "    default_hdul.close()\n",
    "    curr_hdul.close()\n",
    "\n",
    "figure.tight_layout()\n",
    "\n",
    "# Saving the figure to ./bd_products\n",
    "figure.savefig(f\"{bd_products_dir}/snr_wavelength.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f4f6d",
   "metadata": {},
   "source": [
    "We can clearly see above that using more files in the co-add substantially increases SNR. This is especially prevalent in the grey highlighted section of the top plot, where we set `t = -1`. The number of files used with that threshold value were 6 files, whereas the default threshold value of `t = -50` used 12 files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a545ad",
   "metadata": {},
   "source": [
    "### Looking at Flux:\n",
    "We're going to create two diffrent plots to analyze our flux data: a standard flux vs wavelength plot, and a differential plot. We will also calculate the percent change in flux between the threshold values vs the default.\n",
    "\n",
    "A differential plot shows the absolute differences between two datasets; in our case, we will be seeing the flux difference at each wavelength between one threshold value's co-add and the default co-add. However, we will first need to interpolate the spectra to a common wavelength grid. Essentially, we will be adjusting the wavelength values so the two datasets can share the same wavelength points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds used that aren't the default\n",
    "nondefault_thresholds = [thresh for thresh in thresholds if thresh != \"-50\"]\n",
    "\n",
    "for i, thresh in enumerate(nondefault_thresholds):\n",
    "    # Getting the data for the co-add that uses default threshold of t = -50\n",
    "    default_path = f\"{bd_products_dir}/out-50/{bd_coadd_name}\"\n",
    "    default_hdul = fits.open(default_path)\n",
    "    thresh_data50 = default_hdul[1].data\n",
    "\n",
    "    wavelength50 = thresh_data50[\"WAVELENGTH\"]\n",
    "    flux50 = thresh_data50[\"FLUX\"]\n",
    "\n",
    "    # Getting data for the co-add that uses the current iteration's threshold\n",
    "    curr_path = f\"{bd_products_dir}/out{thresh}/{bd_coadd_name}\"\n",
    "    curr_hdul = fits.open(curr_path)\n",
    "    thresh_data_curr = curr_hdul[1].data\n",
    "\n",
    "    wavelength_curr = thresh_data_curr[\"WAVELENGTH\"]\n",
    "    flux_curr = thresh_data_curr[\"FLUX\"]\n",
    "\n",
    "    # Getting the number of files used in co-add, will put this in the plot\n",
    "    numfiles = len(fits.open(curr_path)[2].data[\"FILENAME\"])\n",
    "    numfiles_default = len(fits.open(default_path)[2].data[\"FILENAME\"])\n",
    "\n",
    "    # Minimum wavelength value in dataset\n",
    "    minwave = min(wavelength50[0].min(), wavelength_curr[0].min())\n",
    "\n",
    "    # Maximum wavelength value in dataset\n",
    "    maxwave = max(wavelength50[0].max(), wavelength_curr[0].max())\n",
    "\n",
    "    # Creating a common wavelength grid using shape of default wavelength axis\n",
    "    common_wavelength = np.arange(start=minwave,\n",
    "                                  stop=maxwave,\n",
    "                                  step=1)\n",
    "\n",
    "    # Interpolating the default + current threshold co-add onto new grid\n",
    "    interp_flux50 = interp1d(wavelength50[0],\n",
    "                             flux50,\n",
    "                             kind='linear',\n",
    "                             fill_value=\"extrapolate\")(common_wavelength)\n",
    "    \n",
    "    interp_flux_curr = interp1d(wavelength_curr[0],\n",
    "                                flux_curr,\n",
    "                                kind='linear',\n",
    "                                fill_value=\"extrapolate\")(common_wavelength)\n",
    "\n",
    "    # Creating two subplots, one flux vs wavelength and one differential plot\n",
    "    fig, [ax0, ax1] = plt.subplots(2, 1,\n",
    "                                   figsize=(10, 9))\n",
    "\n",
    "    # Plotting the top plot, a.k.a. the flux vs wavelength for t = -50\n",
    "    ax0.scatter(common_wavelength, interp_flux50,\n",
    "                label=f\"t = -50, {numfiles_default} files\",\n",
    "                color=\"black\",\n",
    "                s=1)\n",
    "\n",
    "    # Plotting flux vs wavelength on same plot for current co-add\n",
    "    ax0.scatter(common_wavelength, interp_flux_curr,\n",
    "                label=f\"t = {thresh}, {numfiles} files\",\n",
    "                color=colors[i],\n",
    "                s=1,\n",
    "                alpha=0.3)\n",
    "\n",
    "    # Calculating difference between current co-add and default flux values\n",
    "    flux_diff = interp_flux_curr - interp_flux50\n",
    "\n",
    "    # Plotting the differential plot\n",
    "    ax1.scatter(common_wavelength, flux_diff,\n",
    "                color=\"black\",\n",
    "                s=1)\n",
    "\n",
    "    # Calculating the percent difference and putting it on the plot\n",
    "    percent_difference = abs(interp_flux50 - interp_flux_curr) / ((interp_flux50 + interp_flux_curr) / 2) * 100\n",
    "\n",
    "    # Calculating the mean percent difference (ignoring NaNs)\n",
    "    percent_difference = round(np.nanmean(percent_difference), 2)\n",
    "\n",
    "    # Adding text box onto plot that displays newly calculated 5 difference\n",
    "    ax0.text(0.02, 0.9,\n",
    "             f\"Average percent difference: {str(percent_difference)}%\",\n",
    "             transform=ax0.transAxes,\n",
    "             weight=\"bold\",\n",
    "             bbox=dict(facecolor=colors[i],\n",
    "                       alpha=0.3))\n",
    "    \n",
    "    # Setting the y axis limits on both plots to be the same\n",
    "    ax0.set_ylim(0, 1e-12)\n",
    "    ax1.set_ylim(0, 1e-12)\n",
    "\n",
    "    # Adding formatting\n",
    "    ax0.set_title(f\"Flux vs Wavelength for t = {thresh}, -50\",\n",
    "                  weight=\"bold\")\n",
    "\n",
    "    ax0.set_xlabel(r'Wavelength [$\\AA$]')\n",
    "    ax0.set_ylabel(r'Flux [$erg\\ s^{-1}\\ cm^{-2}\\ \\AA^{-1}$]')\n",
    "\n",
    "    # Putting the legend on the flux plot\n",
    "    ax0.legend()\n",
    "\n",
    "    ax1.set_title(f\"Absolute Difference for t = {thresh}, -50\",\n",
    "                  weight=\"bold\")\n",
    "    \n",
    "    ax1.set_xlabel(r'Wavelength [$\\AA$]')\n",
    "    ax1.set_ylabel(r'Flux Difference [$erg\\ s^{-1}\\ cm^{-2}\\ \\AA^{-1}$]')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(f\"{bd_products_dir}/flux_differential.png\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    default_hdul.close()\n",
    "    curr_hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184adf4",
   "metadata": {},
   "source": [
    "# Congrats on completing the notebook!\n",
    "\n",
    "### There are more tutorial notebooks for custom co-addition cases in [this repo](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/HASP), check them out!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "551c86c8",
   "metadata": {},
   "source": [
    "## About this Notebook\n",
    "**Author:** Sierra Gomez (sigomez@stsci.edu)\n",
    "\n",
    "**Updated on:** 01/29/2024\n",
    "\n",
    "*This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b21e475",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "If you use the following packages for published research, please cite the authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `astropy`](https://docs.astropy.org/en/stable/index.html)\n",
    "\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/citing.html)\n",
    "\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/)\n",
    "\n",
    "* [Citing `scipy`](https://scipy.org/citing-scipy/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "164f5842",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
